{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"arithmetic_rnn.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPSuHHskcvJbnYX983dMC3b"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"gZI5NIQA4jPH"},"source":["# **Keras 예제 - Seq2Seq 로 사칙연산 구현**\n","\n","출처\n","- RNN 덧셈 예제 : https://github.com/keras-team/keras/blob/2.0.0/examples/addition_rnn.py\n","- 사칙연산 예제 : https://towardsdatascience.com/making-rnn-model-learn-arithmetic-operations-b016ec4d8388\n","- 텐서플로우 버전 : 2.1.0\n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IwKUl5cybwdb","executionInfo":{"status":"ok","timestamp":1630844463254,"user_tz":-540,"elapsed":36846,"user":{"displayName":"박아정","photoUrl":"","userId":"15223679537180029561"}},"outputId":"b0101103-664a-43d0-a5ae-98a840d7fb5b"},"source":["!pip uninstall tensorflow"],"execution_count":41,"outputs":[{"output_type":"stream","name":"stdout","text":["Found existing installation: tensorflow 2.6.0\n","Uninstalling tensorflow-2.6.0:\n","  Would remove:\n","    /usr/local/bin/estimator_ckpt_converter\n","    /usr/local/bin/import_pb_to_tensorboard\n","    /usr/local/bin/saved_model_cli\n","    /usr/local/bin/tensorboard\n","    /usr/local/bin/tf_upgrade_v2\n","    /usr/local/bin/tflite_convert\n","    /usr/local/bin/toco\n","    /usr/local/bin/toco_from_protos\n","    /usr/local/lib/python3.7/dist-packages/tensorflow-2.6.0.dist-info/*\n","    /usr/local/lib/python3.7/dist-packages/tensorflow/*\n","Proceed (y/n)? y\n","  Successfully uninstalled tensorflow-2.6.0\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"PmuWoVBib2Up","executionInfo":{"status":"ok","timestamp":1630844512085,"user_tz":-540,"elapsed":46869,"user":{"displayName":"박아정","photoUrl":"","userId":"15223679537180029561"}},"outputId":"e086eaa7-ec87-4158-8231-c4f3cd3be13f"},"source":["!pip install tensorflow==2.1.0"],"execution_count":42,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting tensorflow==2.1.0\n","  Downloading tensorflow-2.1.0-cp37-cp37m-manylinux2010_x86_64.whl (421.8 MB)\n","\u001b[K     |████████████████████████████████| 421.8 MB 25 kB/s \n","\u001b[?25hCollecting keras-applications>=1.0.8\n","  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n","\u001b[K     |████████████████████████████████| 50 kB 6.4 MB/s \n","\u001b[?25hRequirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.1.0) (3.17.3)\n","Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.1.0) (1.19.5)\n","Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.1.0) (1.39.0)\n","Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.1.0) (0.2.0)\n","Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.1.0) (0.8.1)\n","Collecting gast==0.2.2\n","  Downloading gast-0.2.2.tar.gz (10 kB)\n","Collecting tensorboard<2.2.0,>=2.1.0\n","  Downloading tensorboard-2.1.1-py3-none-any.whl (3.8 MB)\n","\u001b[K     |████████████████████████████████| 3.8 MB 61.8 MB/s \n","\u001b[?25hRequirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.1.0) (0.12.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.1.0) (3.3.0)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.1.0) (0.37.0)\n","Collecting tensorflow-estimator<2.2.0,>=2.1.0rc0\n","  Downloading tensorflow_estimator-2.1.0-py2.py3-none-any.whl (448 kB)\n","\u001b[K     |████████████████████████████████| 448 kB 50.5 MB/s \n","\u001b[?25hRequirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.1.0) (1.15.0)\n","Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.1.0) (1.1.2)\n","Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.1.0) (1.12.1)\n","Requirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.1.0) (1.4.1)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.1.0) (1.1.0)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow==2.1.0) (3.1.0)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (0.4.5)\n","Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.34.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.3.4)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (57.4.0)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.0.1)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (2.23.0)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (4.2.2)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (0.2.8)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (4.7.2)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.3.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (4.6.4)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (0.4.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (2021.5.30)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.1.1)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.8->tensorflow==2.1.0) (1.5.2)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.5.0)\n","Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.7.4.3)\n","Building wheels for collected packages: gast\n","  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gast: filename=gast-0.2.2-py3-none-any.whl size=7554 sha256=2545697a864965c678fa2a238ca847818a9679ff40e37916c098a34e4050123f\n","  Stored in directory: /root/.cache/pip/wheels/21/7f/02/420f32a803f7d0967b48dd823da3f558c5166991bfd204eef3\n","Successfully built gast\n","Installing collected packages: tensorflow-estimator, tensorboard, keras-applications, gast, tensorflow\n","  Attempting uninstall: tensorflow-estimator\n","    Found existing installation: tensorflow-estimator 2.6.0\n","    Uninstalling tensorflow-estimator-2.6.0:\n","      Successfully uninstalled tensorflow-estimator-2.6.0\n","  Attempting uninstall: tensorboard\n","    Found existing installation: tensorboard 2.6.0\n","    Uninstalling tensorboard-2.6.0:\n","      Successfully uninstalled tensorboard-2.6.0\n","  Attempting uninstall: gast\n","    Found existing installation: gast 0.4.0\n","    Uninstalling gast-0.4.0:\n","      Successfully uninstalled gast-0.4.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tensorflow-probability 0.13.0 requires gast>=0.3.2, but you have gast 0.2.2 which is incompatible.\u001b[0m\n","Successfully installed gast-0.2.2 keras-applications-1.0.8 tensorboard-2.1.1 tensorflow-2.1.0 tensorflow-estimator-2.1.0\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["gast","tensorboard","tensorflow"]}}},"metadata":{}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"90EcLzESwUyH","executionInfo":{"status":"ok","timestamp":1630842392445,"user_tz":-540,"elapsed":22570,"user":{"displayName":"박아정","photoUrl":"","userId":"15223679537180029561"}},"outputId":"8586c2c8-d47e-4e7f-de33-63f35acb59c6"},"source":["# from google.colab import drive\n","# drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":203},"id":"P5N5RDNI5Gpr","executionInfo":{"status":"ok","timestamp":1630836652126,"user_tz":-540,"elapsed":11,"user":{"displayName":"박아정","photoUrl":"","userId":"15223679537180029561"}},"outputId":"552607d9-05ac-419b-f477-78b8f6531044"},"source":["# -*- coding: utf-8 -*-\n","'''An implementation of sequence to sequence learning for performing addition\n","Input: \"535+61\"\n","Output: \"596\"\n","Padding is handled by using a repeated sentinel character (space)\n","Input may optionally be inverted, shown to increase performance in many tasks in:\n","\"Learning to Execute\"\n","http://arxiv.org/abs/1410.4615\n","and\n","\"Sequence to Sequence Learning with Neural Networks\"\n","http://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf\n","Theoretically it introduces shorter term dependencies between source and target.\n","Two digits inverted:\n","+ One layer LSTM (128 HN), 5k training examples = 99% train/test accuracy in 55 epochs\n","Three digits inverted:\n","+ One layer LSTM (128 HN), 50k training examples = 99% train/test accuracy in 100 epochs\n","Four digits inverted:\n","+ One layer LSTM (128 HN), 400k training examples = 99% train/test accuracy in 20 epochs\n","Five digits inverted:\n","+ One layer LSTM (128 HN), 550k training examples = 99% train/test accuracy in 30 epochs\n","'''"],"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'An implementation of sequence to sequence learning for performing addition\\nInput: \"535+61\"\\nOutput: \"596\"\\nPadding is handled by using a repeated sentinel character (space)\\nInput may optionally be inverted, shown to increase performance in many tasks in:\\n\"Learning to Execute\"\\nhttp://arxiv.org/abs/1410.4615\\nand\\n\"Sequence to Sequence Learning with Neural Networks\"\\nhttp://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf\\nTheoretically it introduces shorter term dependencies between source and target.\\nTwo digits inverted:\\n+ One layer LSTM (128 HN), 5k training examples = 99% train/test accuracy in 55 epochs\\nThree digits inverted:\\n+ One layer LSTM (128 HN), 50k training examples = 99% train/test accuracy in 100 epochs\\nFour digits inverted:\\n+ One layer LSTM (128 HN), 400k training examples = 99% train/test accuracy in 20 epochs\\nFive digits inverted:\\n+ One layer LSTM (128 HN), 550k training examples = 99% train/test accuracy in 30 epochs\\n'"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","metadata":{"id":"UalzhCNK5M8Q","executionInfo":{"status":"ok","timestamp":1630844525811,"user_tz":-540,"elapsed":2031,"user":{"displayName":"박아정","photoUrl":"","userId":"15223679537180029561"}}},"source":["from __future__ import print_function\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras import layers\n","import numpy as np\n","from six.moves import range\n","import matplotlib.pyplot as plt"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"21In4rWv5QdY","executionInfo":{"status":"ok","timestamp":1630844528879,"user_tz":-540,"elapsed":433,"user":{"displayName":"박아정","photoUrl":"","userId":"15223679537180029561"}}},"source":["class CharacterTable(object):\n","    \"\"\"Given a set of characters:\n","    + Encode them to a one hot integer representation\n","    + Decode the one hot integer representation to their character output\n","    + Decode a vector of probabilities to their character output\n","    \"\"\"\n","    # 초기화 : 사용되는 문자 집합이 주어지면 caharacter table 을 초기화한다.\n","    def __init__(self, chars):\n","        \"\"\"Initialize character table.\n","        # Arguments\n","            chars: Characters that can appear in the input.\n","        \"\"\"\n","        # 문자 집합이 주어지면 각 문자에 대한 인덱스를 매긴다.\n","        # char_indices : (문자, 인덱스), indices_char : (인덱스, 문자)\n","        self.chars = sorted(set(chars))\n","        self.char_indices = dict((c, i) for i, c in enumerate(self.chars))\n","        self.indices_char = dict((i, c) for i, c in enumerate(self.chars))\n","        print(self.char_indices)\n","        print(self.indices_char)\n","\n","    def encode(self, C, num_rows):\n","        \"\"\"One hot encode given string C.\n","        # Arguments\n","            num_rows: Number of rows in the returned one hot encoding. This is\n","                used to keep the # of rows for each data the same.\n","        \"\"\"\n","        x = np.zeros((num_rows, len(self.chars)))\n","        # 문장(C)의 문자에 해당하는 행렬 위치를 0->1 로 바꾼다.\n","        for i, c in enumerate(C):\n","            x[i, self.char_indices[c]] = 1    # 순서대로 i번째 행에 char_indices[c] 열에 1 대입\n","        return x\n","\n","    def decode(self, x, calc_argmax=True):\n","        if calc_argmax:\n","            x = x.argmax(axis=-1)\n","        return ''.join(self.indices_char[x] for x in x)"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"3qsppJcZ5TEb","executionInfo":{"status":"ok","timestamp":1630844530615,"user_tz":-540,"elapsed":4,"user":{"displayName":"박아정","photoUrl":"","userId":"15223679537180029561"}}},"source":["class colors:\n","    ok = '\\033[92m'\n","    fail = '\\033[91m'\n","    close = '\\033[0m'"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"aCQ2yF9_BWGG","executionInfo":{"status":"ok","timestamp":1630844532378,"user_tz":-540,"elapsed":4,"user":{"displayName":"박아정","photoUrl":"","userId":"15223679537180029561"}}},"source":["def weird_division(n, d):\n","    return n / d if d else 0"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5be_v6anHXE1","executionInfo":{"status":"ok","timestamp":1630844534747,"user_tz":-540,"elapsed":548,"user":{"displayName":"박아정","photoUrl":"","userId":"15223679537180029561"}},"outputId":"63b44204-a4d3-4143-8b82-f3add6a7f545"},"source":["# Parameters for the model and dataset.\n","TRAINING_SIZE = 50000\n","DIGITS = 3\n","INVERT = True\n","\n","# Maximum length of input is 'int + int' (e.g., '345+678'). Maximum length of\n","# int is DIGITS.\n","MAxLEN = DIGITS + 1 + DIGITS\n","\n","# All the numbers, plus sign and space for padding.\n","# ctable : 문자 집합에 대해 character table 을 만든 인스턴스(?)\n","chars = '0123456789+*/-. '\n","calc = '+*/-'\n","ctable = CharacterTable(chars)\n","\n","questions = []\n","expected = []\n","seen = set()\n","file_path = '/content/3digit_1arith.txt'\n","\n","print('Get data...from txt')\n","for line in open(file_path, 'r'):\n","        idx = line.find('_')\n","        questions.append(line[:idx][::-1])\n","        expected.append(line[idx+1:-1])\n","\n","# Generating Data...\n","# np.random.randint(1, 20) : 1~19까지 랜덤한 숫자 1개\n","# while len(questions) < TRAINING_SIZE:   #50000개 만듦\n","#     # f : 최대 3자리까지 랜덤한 숫자를 만든다.\n","#     f = lambda: int(''.join(np.random.choice(list('0123456789'))\n","#                     for i in range(np.random.randint(1, DIGITS + 1))))\n","#     a, b = f(), f()\n","\n","#     # Skip any addition questions we've already seen\n","#     # Also skip any such that x+Y == Y+x (hence the sorting).\n","#     key = tuple(sorted((a, b)))\n","#     if key in seen:\n","#         continue\n","#     seen.add(key)\n","\n","#     # Pad the data with spaces such that it is always MAxLEN.\n","#     q = str(a) + np.random.choice(list(calc)) + str(b)\n","#     # q = '{}+{}'.format(a, b)\n","#     query = q + ' ' * (MAxLEN - len(q)) # 전체 길이 - q 길이 만큼 padding 을 줘서 전체 길이가 맞춰지도록.\n","#     if '+' in q:\n","#       ans = str(a + b)\n","#     elif '-' in q:\n","#       ans = str(a - b)\n","#     elif '*' in q:\n","#       ans = str(a * b)\n","#     else:\n","#       res = weird_division(a, b)\n","#       ans = str(round(res,2))\n","  \n","#     # Answers can be of maximum size DIGITS + 1.\n","#     # answer 도 패딩을 맞춰준다. (answer가 될 수 있는 최대 길이에서 - 현재 나온 답의 길이 만큼)\n","#     # answer 의 최대 길이 : 6자리(999*999 = 998001)\n","#       ans += ' ' * (DIGITS + 3 - len(ans))\n","\n","#     # Input의 Reverse 여부\n","#     if INVERT:\n","#         # Reverse the query, e.g., '12+345  ' becomes '  543+21'. (Note the\n","#         # space used for padding.)\n","#         query = query[::-1] # Reverse\n","#     questions.append(query)\n","#     expected.append(ans)\n","# print('Total addition questions:', len(questions))\n"],"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["{' ': 0, '*': 1, '+': 2, '-': 3, '.': 4, '/': 5, '0': 6, '1': 7, '2': 8, '3': 9, '4': 10, '5': 11, '6': 12, '7': 13, '8': 14, '9': 15}\n","{0: ' ', 1: '*', 2: '+', 3: '-', 4: '.', 5: '/', 6: '0', 7: '1', 8: '2', 9: '3', 10: '4', 11: '5', 12: '6', 13: '7', 14: '8', 15: '9'}\n","Get data...from txt\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RWFfyC9oyq2C","executionInfo":{"status":"ok","timestamp":1630844542082,"user_tz":-540,"elapsed":448,"user":{"displayName":"박아정","photoUrl":"","userId":"15223679537180029561"}},"outputId":"a5500ac3-c312-4fa5-afeb-8324bcadc4e0"},"source":["# Reverse 해서 인풋이 거꾸로 출력됨.\n","print(questions[1] + '?' + expected[1])\n","print(questions[1][::-1])\n","print(expected[1])"],"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["  84*13?1488\n","31*48  \n","1488\n"]}]},{"cell_type":"code","metadata":{"id":"1L8-JRLuw-fN","executionInfo":{"status":"ok","timestamp":1630843463491,"user_tz":-540,"elapsed":416,"user":{"displayName":"박아정","photoUrl":"","userId":"15223679537180029561"}}},"source":["# f = open('3digit_1arith.txt', 'w')\n","# for i in range(len(questions)):\n","#     data = questions[i][::-1] + '_' + expected[i] + '\\n'\n","#     f.write(data)\n","# f.close()\n"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_ShaxkUDJ0K3","executionInfo":{"status":"ok","timestamp":1630844545365,"user_tz":-540,"elapsed":351,"user":{"displayName":"박아정","photoUrl":"","userId":"15223679537180029561"}},"outputId":"e57c5313-e732-473b-dfb8-cb67afc7754c"},"source":["print('Vectorization...')\n","# np.zeros(shape, dtype, order)\n","x = np.zeros((len(questions), MAxLEN, len(chars)), dtype=np.bool)\n","y = np.zeros((len(questions), DIGITS + 3, len(chars)), dtype=np.bool)\n","print(x.shape)\n","print(y.shape)"],"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Vectorization...\n","(50000, 7, 16)\n","(50000, 6, 16)\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TR73ZQDHJwv-","executionInfo":{"status":"ok","timestamp":1630844547848,"user_tz":-540,"elapsed":470,"user":{"displayName":"박아정","photoUrl":"","userId":"15223679537180029561"}},"outputId":"2031ae46-a7b1-4f61-bbf1-fb15d5482528"},"source":["print('Vectorization...')\n","# np.zeros(shape, dtype, order)\n","# x : (50000, 7, 15), y : (50000, 6, 15)\n","# 입력데이터를 Encode\n","x = np.zeros((len(questions), MAxLEN, len(chars)), dtype=np.bool)\n","y = np.zeros((len(questions), DIGITS + 3, len(chars)), dtype=np.bool)\n","for i, sentence in enumerate(questions):\n","    x[i] = ctable.encode(sentence, MAxLEN)\n","for i, sentence in enumerate(expected):\n","    y[i] = ctable.encode(sentence, DIGITS + 3)\n","\n","# Shuffle (x, y) in unison as the later parts of x will almost all be larger\n","# digits.\n","# x의 뒷부분이 더 커지기 때문에 (x, y) 를 섞는다. (???) -> 어쨋든 셔플\n","indices = np.arange(len(y))\n","np.random.shuffle(indices)\n","x = x[indices]\n","y = y[indices]\n","\n","# Explicitly set apart 10% for validation data that we never train over.\n","# Test Set : 0~45000, Validation Set : 45000~50000\n","split_at = len(x) - len(x) // 10\n","(x_train, x_val) = x[:split_at], x[split_at:]\n","(y_train, y_val) = y[:split_at], y[split_at:]\n","\n","print('Training Data:')\n","print(x_train.shape)\n","print(y_train.shape)\n","\n","print('Validation Data:')\n","print(x_val.shape)\n","print(y_val.shape)"],"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Vectorization...\n","Training Data:\n","(45000, 7, 16)\n","(45000, 6, 16)\n","Validation Data:\n","(5000, 7, 16)\n","(5000, 6, 16)\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T2ZFo7R_TC2U","executionInfo":{"status":"ok","timestamp":1630844551517,"user_tz":-540,"elapsed":955,"user":{"displayName":"박아정","photoUrl":"","userId":"15223679537180029561"}},"outputId":"1cc82c6e-1986-45e1-a1cf-39f1f0cfe91a"},"source":["# Try replacing GRU, or SimpleRNN.\n","RNN = layers.LSTM\n","HIDDEN_SIZE = 128\n","BATCH_SIZE = 128\n","LAYERS = 1\n","\n","print('Build model...')\n","model = Sequential()\n","\n","# \"Encode\" the input sequence using an RNN, producing an output of HIDDEN_SIZE.\n","# Note: In a situation where your input sequences have a variable length,\n","# use input_shape=(None, num_feature).\n","model.add(RNN(HIDDEN_SIZE, input_shape=(MAxLEN, len(chars))))\n","\n","# As the decoder RNN's input, repeatedly provide with the last hidden state of\n","# RNN for each time step. Repeat 'DIGITS + 1' times as that's the maximum\n","# length of output, e.g., when DIGITS=3, max output is 999+999=1998.\n","model.add(layers.RepeatVector(DIGITS + 3))\n","\n","# The decoder RNN could be multiple layers stacked or a single layer.\n","for _ in range(LAYERS):\n","    # By setting return_sequences to True, return not only the last output but\n","    # all the outputs so far in the form of (num_samples, timesteps,\n","    # output_dim). This is necessary as TimeDistributed in the below expects\n","    # the first dimension to be the timesteps.\n","    # return_sequences(시퀀스 출력 여부): True(각 시퀀스에서 출력, many-to-many 일 때)\n","    model.add(RNN(HIDDEN_SIZE, return_sequences=True))\n","\n","# Apply a dense layer to the every temporal slice of an input. For each of step\n","# of the output sequence, decide which character should be chosen.\n","# TimeDistributed :7개의 시간 단계 각각에 독립적으로 Dense 레이어를 적용\n","model.add(layers.TimeDistributed(layers.Dense(len(chars))))\n","model.add(layers.Activation('softmax'))\n","model.compile(loss='categorical_crossentropy',\n","              optimizer='adam',\n","              metrics=['accuracy'])\n","model.summary()"],"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Build model...\n","Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","lstm (LSTM)                  (None, 128)               74240     \n","_________________________________________________________________\n","repeat_vector (RepeatVector) (None, 6, 128)            0         \n","_________________________________________________________________\n","lstm_1 (LSTM)                (None, 6, 128)            131584    \n","_________________________________________________________________\n","time_distributed (TimeDistri (None, 6, 16)             2064      \n","_________________________________________________________________\n","activation (Activation)      (None, 6, 16)             0         \n","=================================================================\n","Total params: 207,888\n","Trainable params: 207,888\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"27aLlS854fJa","outputId":"5a72b93e-7ba0-45af-f967-7d97e95be703"},"source":["# Train the model each generation and show predictions against the validation\n","# dataset.\n","acc_list = []\n","for iteration in range(1, 200):\n","    print()\n","    print('-' * 50)\n","    print('Iteration', iteration)\n","    model.fit(x_train, y_train, batch_size=BATCH_SIZE, epochs=1,\n","              validation_data=(x_val, y_val))\n","    # Select samples from the validation set at random so we can visualize\n","    # errors.\n","    correct_num = 0\n","    for i in range(len(x_val)):\n","        rowx, rowy = x_val[np.array([i])], y_val[np.array([i])]\n","        # predict_classes : 0 or 1로 출력 (predict 와 약간 다름) --> 2.6버전에서 삭제됨\n","        preds = model.predict_classes(rowx, verbose=0)\n","        q = ctable.decode(rowx[0])\n","        correct = ctable.decode(rowy[0])\n","        guess = ctable.decode(preds[0], calc_argmax=False)\n","        \n","        if guess == correct:\n","          correct_num += 1\n","        else:\n","          correct_num += 0\n","        # print('guess: ', guess)\n","        # print('Q', q[::-1] if INVERT else q)\n","        # print('T', correct)\n","        # if correct == guess:\n","        #     print(colors.ok + '☑' + colors.close, end=\" \")\n","        # else:\n","        #     print(colors.fail + '☒' + colors.close, end=\" \")\n","        # print(guess)\n","        # print('---')\n","\n","    acc = float(correct_num) / len(x_val)\n","    acc_list.append(acc)\n","    print('검증 정확도 %.3f%%' % (acc * 100))\n","    if iteration == 100:\n","      print('100번째 정확도 : ', acc)\n","model.save('3digit_1arith.h5')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","--------------------------------------------------\n","Iteration 1\n","Train on 45000 samples, validate on 5000 samples\n","45000/45000 [==============================] - 15s 331us/sample - loss: 1.4405 - accuracy: 0.2402 - val_loss: 1.3092 - val_accuracy: 0.2372\n","검증 정확도 0.940%\n","\n","--------------------------------------------------\n","Iteration 2\n","Train on 45000 samples, validate on 5000 samples\n","45000/45000 [==============================] - 13s 278us/sample - loss: 1.2705 - accuracy: 0.2453 - val_loss: 1.2482 - val_accuracy: 0.2451\n","검증 정확도 1.320%\n","\n","--------------------------------------------------\n","Iteration 3\n","Train on 45000 samples, validate on 5000 samples\n","45000/45000 [==============================] - 12s 278us/sample - loss: 1.2311 - accuracy: 0.2540 - val_loss: 1.2116 - val_accuracy: 0.2524\n","검증 정확도 0.920%\n","\n","--------------------------------------------------\n","Iteration 4\n","Train on 45000 samples, validate on 5000 samples\n","45000/45000 [==============================] - 12s 278us/sample - loss: 1.2015 - accuracy: 0.2648 - val_loss: 1.1833 - val_accuracy: 0.2638\n","검증 정확도 1.740%\n","\n","--------------------------------------------------\n","Iteration 5\n","Train on 45000 samples, validate on 5000 samples\n","45000/45000 [==============================] - 16s 356us/sample - loss: 1.1737 - accuracy: 0.2759 - val_loss: 1.1564 - val_accuracy: 0.2777\n","검증 정확도 2.160%\n","\n","--------------------------------------------------\n","Iteration 6\n","Train on 45000 samples, validate on 5000 samples\n","45000/45000 [==============================] - 13s 278us/sample - loss: 1.1428 - accuracy: 0.2869 - val_loss: 1.1247 - val_accuracy: 0.2900\n","검증 정확도 2.500%\n","\n","--------------------------------------------------\n","Iteration 7\n","Train on 45000 samples, validate on 5000 samples\n","45000/45000 [==============================] - 13s 279us/sample - loss: 1.1055 - accuracy: 0.3004 - val_loss: 1.0807 - val_accuracy: 0.3066\n","검증 정확도 2.900%\n","\n","--------------------------------------------------\n","Iteration 8\n","Train on 45000 samples, validate on 5000 samples\n","45000/45000 [==============================] - 12s 277us/sample - loss: 1.0657 - accuracy: 0.3148 - val_loss: 1.0348 - val_accuracy: 0.3175\n","검증 정확도 3.240%\n","\n","--------------------------------------------------\n","Iteration 9\n","Train on 45000 samples, validate on 5000 samples\n","45000/45000 [==============================] - 13s 280us/sample - loss: 1.0102 - accuracy: 0.3305 - val_loss: 0.9815 - val_accuracy: 0.3335\n","검증 정확도 3.500%\n","\n","--------------------------------------------------\n","Iteration 10\n","Train on 45000 samples, validate on 5000 samples\n","45000/45000 [==============================] - 13s 280us/sample - loss: 0.9636 - accuracy: 0.3443 - val_loss: 0.9581 - val_accuracy: 0.3432\n","검증 정확도 4.020%\n","\n","--------------------------------------------------\n","Iteration 11\n","Train on 45000 samples, validate on 5000 samples\n","45000/45000 [==============================] - 13s 281us/sample - loss: 0.9330 - accuracy: 0.3533 - val_loss: 0.9176 - val_accuracy: 0.3495\n","검증 정확도 3.880%\n","\n","--------------------------------------------------\n","Iteration 12\n","Train on 45000 samples, validate on 5000 samples\n","45000/45000 [==============================] - 13s 279us/sample - loss: 0.9085 - accuracy: 0.3613 - val_loss: 0.9049 - val_accuracy: 0.3579\n","검증 정확도 4.220%\n","\n","--------------------------------------------------\n","Iteration 13\n","Train on 45000 samples, validate on 5000 samples\n","45000/45000 [==============================] - 13s 279us/sample - loss: 0.8851 - accuracy: 0.3698 - val_loss: 0.8849 - val_accuracy: 0.3601\n","검증 정확도 3.800%\n","\n","--------------------------------------------------\n","Iteration 14\n","Train on 45000 samples, validate on 5000 samples\n","45000/45000 [==============================] - 13s 282us/sample - loss: 0.8672 - accuracy: 0.3754 - val_loss: 0.8655 - val_accuracy: 0.3668\n","검증 정확도 4.500%\n","\n","--------------------------------------------------\n","Iteration 15\n","Train on 45000 samples, validate on 5000 samples\n","45000/45000 [==============================] - 13s 282us/sample - loss: 0.8505 - accuracy: 0.3815 - val_loss: 0.8500 - val_accuracy: 0.3738\n","검증 정확도 4.640%\n","\n","--------------------------------------------------\n","Iteration 16\n","Train on 45000 samples, validate on 5000 samples\n","45000/45000 [==============================] - 13s 280us/sample - loss: 0.8362 - accuracy: 0.3862 - val_loss: 0.8358 - val_accuracy: 0.3790\n","검증 정확도 5.120%\n","\n","--------------------------------------------------\n","Iteration 17\n","Train on 45000 samples, validate on 5000 samples\n","45000/45000 [==============================] - 13s 280us/sample - loss: 0.8162 - accuracy: 0.3939 - val_loss: 0.8276 - val_accuracy: 0.3810\n","검증 정확도 5.040%\n","\n","--------------------------------------------------\n","Iteration 18\n","Train on 45000 samples, validate on 5000 samples\n","45000/45000 [==============================] - 13s 281us/sample - loss: 0.8036 - accuracy: 0.3988 - val_loss: 0.8089 - val_accuracy: 0.3889\n","검증 정확도 5.040%\n","\n","--------------------------------------------------\n","Iteration 19\n","Train on 45000 samples, validate on 5000 samples\n","45000/45000 [==============================] - 13s 280us/sample - loss: 0.7888 - accuracy: 0.4039 - val_loss: 0.7957 - val_accuracy: 0.3901\n","검증 정확도 4.720%\n","\n","--------------------------------------------------\n","Iteration 20\n","Train on 45000 samples, validate on 5000 samples\n","45000/45000 [==============================] - 13s 284us/sample - loss: 0.7735 - accuracy: 0.4101 - val_loss: 0.7811 - val_accuracy: 0.4003\n","검증 정확도 5.900%\n","\n","--------------------------------------------------\n","Iteration 21\n","Train on 45000 samples, validate on 5000 samples\n","45000/45000 [==============================] - 13s 286us/sample - loss: 0.7604 - accuracy: 0.4151 - val_loss: 0.7758 - val_accuracy: 0.3973\n","검증 정확도 5.300%\n","\n","--------------------------------------------------\n","Iteration 22\n","Train on 45000 samples, validate on 5000 samples\n","45000/45000 [==============================] - 13s 284us/sample - loss: 0.7472 - accuracy: 0.4200 - val_loss: 0.7606 - val_accuracy: 0.4052\n","검증 정확도 5.920%\n","\n","--------------------------------------------------\n","Iteration 23\n","Train on 45000 samples, validate on 5000 samples\n","45000/45000 [==============================] - 13s 283us/sample - loss: 0.7341 - accuracy: 0.4247 - val_loss: 0.7504 - val_accuracy: 0.4059\n","검증 정확도 5.540%\n","\n","--------------------------------------------------\n","Iteration 24\n","Train on 45000 samples, validate on 5000 samples\n","45000/45000 [==============================] - 13s 285us/sample - loss: 0.7229 - accuracy: 0.4284 - val_loss: 0.7364 - val_accuracy: 0.4143\n","검증 정확도 6.300%\n","\n","--------------------------------------------------\n","Iteration 25\n","Train on 45000 samples, validate on 5000 samples\n","45000/45000 [==============================] - 13s 287us/sample - loss: 0.7131 - accuracy: 0.4326 - val_loss: 0.7385 - val_accuracy: 0.4144\n","검증 정확도 5.960%\n","\n","--------------------------------------------------\n","Iteration 26\n","Train on 45000 samples, validate on 5000 samples\n","45000/45000 [==============================] - 13s 285us/sample - loss: 0.7033 - accuracy: 0.4368 - val_loss: 0.7303 - val_accuracy: 0.4157\n","검증 정확도 6.360%\n","\n","--------------------------------------------------\n","Iteration 27\n","Train on 45000 samples, validate on 5000 samples\n","45000/45000 [==============================] - 13s 284us/sample - loss: 0.6941 - accuracy: 0.4408 - val_loss: 0.7231 - val_accuracy: 0.4169\n","검증 정확도 5.300%\n","\n","--------------------------------------------------\n","Iteration 28\n","Train on 45000 samples, validate on 5000 samples\n","45000/45000 [==============================] - 13s 283us/sample - loss: 0.6851 - accuracy: 0.4444 - val_loss: 0.7180 - val_accuracy: 0.4210\n","검증 정확도 6.040%\n","\n","--------------------------------------------------\n","Iteration 29\n","Train on 45000 samples, validate on 5000 samples\n","45000/45000 [==============================] - 13s 283us/sample - loss: 0.6755 - accuracy: 0.4489 - val_loss: 0.7077 - val_accuracy: 0.4270\n","검증 정확도 6.300%\n","\n","--------------------------------------------------\n","Iteration 30\n","Train on 45000 samples, validate on 5000 samples\n","45000/45000 [==============================] - 13s 286us/sample - loss: 0.6671 - accuracy: 0.4526 - val_loss: 0.7099 - val_accuracy: 0.4235\n","검증 정확도 5.740%\n","\n","--------------------------------------------------\n","Iteration 31\n","Train on 45000 samples, validate on 5000 samples\n","45000/45000 [==============================] - 13s 284us/sample - loss: 0.6588 - accuracy: 0.4556 - val_loss: 0.6937 - val_accuracy: 0.4295\n","검증 정확도 6.200%\n","\n","--------------------------------------------------\n","Iteration 32\n","Train on 45000 samples, validate on 5000 samples\n","45000/45000 [==============================] - 13s 283us/sample - loss: 0.6514 - accuracy: 0.4588 - val_loss: 0.6973 - val_accuracy: 0.4285\n","검증 정확도 5.780%\n","\n","--------------------------------------------------\n","Iteration 33\n","Train on 45000 samples, validate on 5000 samples\n","45000/45000 [==============================] - 13s 283us/sample - loss: 0.6428 - accuracy: 0.4629 - val_loss: 0.6890 - val_accuracy: 0.4302\n","검증 정확도 6.580%\n","\n","--------------------------------------------------\n","Iteration 34\n","Train on 45000 samples, validate on 5000 samples\n","45000/45000 [==============================] - 13s 284us/sample - loss: 0.6351 - accuracy: 0.4671 - val_loss: 0.6794 - val_accuracy: 0.4365\n","검증 정확도 6.200%\n","\n","--------------------------------------------------\n","Iteration 35\n","Train on 45000 samples, validate on 5000 samples\n","45000/45000 [==============================] - 13s 284us/sample - loss: 0.6256 - accuracy: 0.4701 - val_loss: 0.6724 - val_accuracy: 0.4397\n","검증 정확도 6.340%\n","\n","--------------------------------------------------\n","Iteration 36\n","Train on 45000 samples, validate on 5000 samples\n","45000/45000 [==============================] - 13s 286us/sample - loss: 0.6182 - accuracy: 0.4741 - val_loss: 0.6689 - val_accuracy: 0.4420\n"]}]},{"cell_type":"code","metadata":{"id":"vq0bijYVEuTf","executionInfo":{"status":"aborted","timestamp":1630841828246,"user_tz":-540,"elapsed":2,"user":{"displayName":"박아정","photoUrl":"","userId":"15223679537180029561"}}},"source":["# 그래프 그리기\n","x = np.arange(len(acc_list))\n","plt.plot(x, acc_list, marker='o')\n","plt.xlabel('에폭')\n","plt.ylabel('정확도')\n","plt.ylim(0, 1.0)\n","plt.show()"],"execution_count":null,"outputs":[]}]}