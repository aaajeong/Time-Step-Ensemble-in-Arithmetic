{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gZI5NIQA4jPH"
   },
   "source": [
    "# **Keras 예제 - Seq2Seq 로 사칙연산 구현**\n",
    "\n",
    "출처\n",
    "- RNN 덧셈 예제 : https://github.com/keras-team/keras/blob/2.0.0/examples/addition_rnn.py\n",
    "- 사칙연산 예제 : https://towardsdatascience.com/making-rnn-model-learn-arithmetic-operations-b016ec4d8388\n",
    "- 텐서플로우 버전 : 2.1.0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 36846,
     "status": "ok",
     "timestamp": 1630844463254,
     "user": {
      "displayName": "박아정",
      "photoUrl": "",
      "userId": "15223679537180029561"
     },
     "user_tz": -540
    },
    "id": "IwKUl5cybwdb",
    "outputId": "b0101103-664a-43d0-a5ae-98a840d7fb5b"
   },
   "outputs": [],
   "source": [
    "#!pip uninstall tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 46869,
     "status": "ok",
     "timestamp": 1630844512085,
     "user": {
      "displayName": "박아정",
      "photoUrl": "",
      "userId": "15223679537180029561"
     },
     "user_tz": -540
    },
    "id": "PmuWoVBib2Up",
    "outputId": "e086eaa7-ec87-4158-8231-c4f3cd3be13f"
   },
   "outputs": [],
   "source": [
    "#!pip install tensorflow==2.1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22570,
     "status": "ok",
     "timestamp": 1630842392445,
     "user": {
      "displayName": "박아정",
      "photoUrl": "",
      "userId": "15223679537180029561"
     },
     "user_tz": -540
    },
    "id": "90EcLzESwUyH",
    "outputId": "8586c2c8-d47e-4e7f-de33-63f35acb59c6"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 203
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1630836652126,
     "user": {
      "displayName": "박아정",
      "photoUrl": "",
      "userId": "15223679537180029561"
     },
     "user_tz": -540
    },
    "id": "P5N5RDNI5Gpr",
    "outputId": "552607d9-05ac-419b-f477-78b8f6531044"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'An implementation of sequence to sequence learning for performing addition\\nInput: \"535+61\"\\nOutput: \"596\"\\nPadding is handled by using a repeated sentinel character (space)\\nInput may optionally be inverted, shown to increase performance in many tasks in:\\n\"Learning to Execute\"\\nhttp://arxiv.org/abs/1410.4615\\nand\\n\"Sequence to Sequence Learning with Neural Networks\"\\nhttp://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf\\nTheoretically it introduces shorter term dependencies between source and target.\\nTwo digits inverted:\\n+ One layer LSTM (128 HN), 5k training examples = 99% train/test accuracy in 55 epochs\\nThree digits inverted:\\n+ One layer LSTM (128 HN), 50k training examples = 99% train/test accuracy in 100 epochs\\nFour digits inverted:\\n+ One layer LSTM (128 HN), 400k training examples = 99% train/test accuracy in 20 epochs\\nFive digits inverted:\\n+ One layer LSTM (128 HN), 550k training examples = 99% train/test accuracy in 30 epochs\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "'''An implementation of sequence to sequence learning for performing addition\n",
    "Input: \"535+61\"\n",
    "Output: \"596\"\n",
    "Padding is handled by using a repeated sentinel character (space)\n",
    "Input may optionally be inverted, shown to increase performance in many tasks in:\n",
    "\"Learning to Execute\"\n",
    "http://arxiv.org/abs/1410.4615\n",
    "and\n",
    "\"Sequence to Sequence Learning with Neural Networks\"\n",
    "http://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf\n",
    "Theoretically it introduces shorter term dependencies between source and target.\n",
    "Two digits inverted:\n",
    "+ One layer LSTM (128 HN), 5k training examples = 99% train/test accuracy in 55 epochs\n",
    "Three digits inverted:\n",
    "+ One layer LSTM (128 HN), 50k training examples = 99% train/test accuracy in 100 epochs\n",
    "Four digits inverted:\n",
    "+ One layer LSTM (128 HN), 400k training examples = 99% train/test accuracy in 20 epochs\n",
    "Five digits inverted:\n",
    "+ One layer LSTM (128 HN), 550k training examples = 99% train/test accuracy in 30 epochs\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 2031,
     "status": "ok",
     "timestamp": 1630844525811,
     "user": {
      "displayName": "박아정",
      "photoUrl": "",
      "userId": "15223679537180029561"
     },
     "user_tz": -540
    },
    "id": "UalzhCNK5M8Q"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "from six.moves import range\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 11713832530882908259,\n",
       " name: \"/device:XLA_CPU:0\"\n",
       " device_type: \"XLA_CPU\"\n",
       " memory_limit: 17179869184\n",
       " locality {\n",
       " }\n",
       " incarnation: 7623136659000824616\n",
       " physical_device_desc: \"device: XLA_CPU device\",\n",
       " name: \"/device:GPU:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 10699354944\n",
       " locality {\n",
       "   bus_id: 4\n",
       "   numa_node: 3\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 3275962689833204913\n",
       " physical_device_desc: \"device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:07:00.0, compute capability: 7.5\",\n",
       " name: \"/device:GPU:1\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 10699354944\n",
       " locality {\n",
       "   bus_id: 2\n",
       "   numa_node: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 2112464463467643493\n",
       " physical_device_desc: \"device: 1, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:41:00.0, compute capability: 7.5\",\n",
       " name: \"/device:XLA_GPU:0\"\n",
       " device_type: \"XLA_GPU\"\n",
       " memory_limit: 17179869184\n",
       " locality {\n",
       " }\n",
       " incarnation: 1229243280111400505\n",
       " physical_device_desc: \"device: XLA_GPU device\",\n",
       " name: \"/device:XLA_GPU:1\"\n",
       " device_type: \"XLA_GPU\"\n",
       " memory_limit: 17179869184\n",
       " locality {\n",
       " }\n",
       " incarnation: 2809484220716768122\n",
       " physical_device_desc: \"device: XLA_GPU device\"]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 433,
     "status": "ok",
     "timestamp": 1630844528879,
     "user": {
      "displayName": "박아정",
      "photoUrl": "",
      "userId": "15223679537180029561"
     },
     "user_tz": -540
    },
    "id": "21In4rWv5QdY"
   },
   "outputs": [],
   "source": [
    "class CharacterTable(object):\n",
    "    \"\"\"Given a set of characters:\n",
    "    + Encode them to a one hot integer representation\n",
    "    + Decode the one hot integer representation to their character output\n",
    "    + Decode a vector of probabilities to their character output\n",
    "    \"\"\"\n",
    "    # 초기화 : 사용되는 문자 집합이 주어지면 caharacter table 을 초기화한다.\n",
    "    def __init__(self, chars):\n",
    "        \"\"\"Initialize character table.\n",
    "        # Arguments\n",
    "            chars: Characters that can appear in the input.\n",
    "        \"\"\"\n",
    "        # 문자 집합이 주어지면 각 문자에 대한 인덱스를 매긴다.\n",
    "        # char_indices : (문자, 인덱스), indices_char : (인덱스, 문자)\n",
    "        self.chars = sorted(set(chars))\n",
    "        self.char_indices = dict((c, i) for i, c in enumerate(self.chars))\n",
    "        self.indices_char = dict((i, c) for i, c in enumerate(self.chars))\n",
    "        print(self.char_indices)\n",
    "        print(self.indices_char)\n",
    "\n",
    "    def encode(self, C, num_rows):\n",
    "        \"\"\"One hot encode given string C.\n",
    "        # Arguments\n",
    "            num_rows: Number of rows in the returned one hot encoding. This is\n",
    "                used to keep the # of rows for each data the same.\n",
    "        \"\"\"\n",
    "        x = np.zeros((num_rows, len(self.chars)))\n",
    "        # 문장(C)의 문자에 해당하는 행렬 위치를 0->1 로 바꾼다.\n",
    "        for i, c in enumerate(C):\n",
    "            x[i, self.char_indices[c]] = 1    # 순서대로 i번째 행에 char_indices[c] 열에 1 대입\n",
    "        return x\n",
    "\n",
    "    def decode(self, x, calc_argmax=True):\n",
    "        if calc_argmax:\n",
    "            x = x.argmax(axis=-1)\n",
    "        return ''.join(self.indices_char[x] for x in x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1630844530615,
     "user": {
      "displayName": "박아정",
      "photoUrl": "",
      "userId": "15223679537180029561"
     },
     "user_tz": -540
    },
    "id": "3qsppJcZ5TEb"
   },
   "outputs": [],
   "source": [
    "class colors:\n",
    "    ok = '\\033[92m'\n",
    "    fail = '\\033[91m'\n",
    "    close = '\\033[0m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1630844532378,
     "user": {
      "displayName": "박아정",
      "photoUrl": "",
      "userId": "15223679537180029561"
     },
     "user_tz": -540
    },
    "id": "aCQ2yF9_BWGG"
   },
   "outputs": [],
   "source": [
    "def weird_division(n, d):\n",
    "    return n / d if d else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 548,
     "status": "ok",
     "timestamp": 1630844534747,
     "user": {
      "displayName": "박아정",
      "photoUrl": "",
      "userId": "15223679537180029561"
     },
     "user_tz": -540
    },
    "id": "5be_v6anHXE1",
    "outputId": "63b44204-a4d3-4143-8b82-f3add6a7f545"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{' ': 0, '*': 1, '+': 2, '-': 3, '.': 4, '/': 5, '0': 6, '1': 7, '2': 8, '3': 9, '4': 10, '5': 11, '6': 12, '7': 13, '8': 14, '9': 15}\n",
      "{0: ' ', 1: '*', 2: '+', 3: '-', 4: '.', 5: '/', 6: '0', 7: '1', 8: '2', 9: '3', 10: '4', 11: '5', 12: '6', 13: '7', 14: '8', 15: '9'}\n",
      "Get data...from txt\n"
     ]
    }
   ],
   "source": [
    "# Parameters for the model and dataset.\n",
    "TRAINING_SIZE = 50000\n",
    "DIGITS = 3\n",
    "INVERT = True\n",
    "\n",
    "# Maximum length of input is 'int + int' (e.g., '345+678'). Maximum length of\n",
    "# int is DIGITS.\n",
    "MAxLEN = DIGITS + 1 + DIGITS\n",
    "\n",
    "# All the numbers, plus sign and space for padding.\n",
    "# ctable : 문자 집합에 대해 character table 을 만든 인스턴스(?)\n",
    "chars = '0123456789+*/-. '\n",
    "calc = '+*/-'\n",
    "ctable = CharacterTable(chars)\n",
    "\n",
    "questions = []\n",
    "expected = []\n",
    "seen = set()\n",
    "file_path = 'dataset/3digit_1arith.txt'\n",
    "\n",
    "print('Get data...from txt')\n",
    "for line in open(file_path, 'r'):\n",
    "        idx = line.find('_')\n",
    "        questions.append(line[:idx][::-1])\n",
    "        expected.append(line[idx+1:-1])\n",
    "\n",
    "# Generating Data...\n",
    "# np.random.randint(1, 20) : 1~19까지 랜덤한 숫자 1개\n",
    "# while len(questions) < TRAINING_SIZE:   #50000개 만듦\n",
    "#     # f : 최대 3자리까지 랜덤한 숫자를 만든다.\n",
    "#     f = lambda: int(''.join(np.random.choice(list('0123456789'))\n",
    "#                     for i in range(np.random.randint(1, DIGITS + 1))))\n",
    "#     a, b = f(), f()\n",
    "\n",
    "#     # Skip any addition questions we've already seen\n",
    "#     # Also skip any such that x+Y == Y+x (hence the sorting).\n",
    "#     key = tuple(sorted((a, b)))\n",
    "#     if key in seen:\n",
    "#         continue\n",
    "#     seen.add(key)\n",
    "\n",
    "#     # Pad the data with spaces such that it is always MAxLEN.\n",
    "#     q = str(a) + np.random.choice(list(calc)) + str(b)\n",
    "#     # q = '{}+{}'.format(a, b)\n",
    "#     query = q + ' ' * (MAxLEN - len(q)) # 전체 길이 - q 길이 만큼 padding 을 줘서 전체 길이가 맞춰지도록.\n",
    "#     if '+' in q:\n",
    "#       ans = str(a + b)\n",
    "#     elif '-' in q:\n",
    "#       ans = str(a - b)\n",
    "#     elif '*' in q:\n",
    "#       ans = str(a * b)\n",
    "#     else:\n",
    "#       res = weird_division(a, b)\n",
    "#       ans = str(round(res,2))\n",
    "  \n",
    "#     # Answers can be of maximum size DIGITS + 1.\n",
    "#     # answer 도 패딩을 맞춰준다. (answer가 될 수 있는 최대 길이에서 - 현재 나온 답의 길이 만큼)\n",
    "#     # answer 의 최대 길이 : 6자리(999*999 = 998001)\n",
    "#       ans += ' ' * (DIGITS + 3 - len(ans))\n",
    "\n",
    "#     # Input의 Reverse 여부\n",
    "#     if INVERT:\n",
    "#         # Reverse the query, e.g., '12+345  ' becomes '  543+21'. (Note the\n",
    "#         # space used for padding.)\n",
    "#         query = query[::-1] # Reverse\n",
    "#     questions.append(query)\n",
    "#     expected.append(ans)\n",
    "# print('Total addition questions:', len(questions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 448,
     "status": "ok",
     "timestamp": 1630844542082,
     "user": {
      "displayName": "박아정",
      "photoUrl": "",
      "userId": "15223679537180029561"
     },
     "user_tz": -540
    },
    "id": "RWFfyC9oyq2C",
    "outputId": "a5500ac3-c312-4fa5-afeb-8324bcadc4e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  84*13?1488\n",
      "31*48  \n",
      "1488\n"
     ]
    }
   ],
   "source": [
    "# Reverse 해서 인풋이 거꾸로 출력됨.\n",
    "print(questions[1] + '?' + expected[1])\n",
    "print(questions[1][::-1])\n",
    "print(expected[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 416,
     "status": "ok",
     "timestamp": 1630843463491,
     "user": {
      "displayName": "박아정",
      "photoUrl": "",
      "userId": "15223679537180029561"
     },
     "user_tz": -540
    },
    "id": "1L8-JRLuw-fN"
   },
   "outputs": [],
   "source": [
    "# f = open('3digit_1arith.txt', 'w')\n",
    "# for i in range(len(questions)):\n",
    "#     data = questions[i][::-1] + '_' + expected[i] + '\\n'\n",
    "#     f.write(data)\n",
    "# f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 351,
     "status": "ok",
     "timestamp": 1630844545365,
     "user": {
      "displayName": "박아정",
      "photoUrl": "",
      "userId": "15223679537180029561"
     },
     "user_tz": -540
    },
    "id": "_ShaxkUDJ0K3",
    "outputId": "e57c5313-e732-473b-dfb8-cb67afc7754c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorization...\n",
      "(50000, 7, 16)\n",
      "(50000, 6, 16)\n"
     ]
    }
   ],
   "source": [
    "print('Vectorization...')\n",
    "# np.zeros(shape, dtype, order)\n",
    "x = np.zeros((len(questions), MAxLEN, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(questions), DIGITS + 3, len(chars)), dtype=np.bool)\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 470,
     "status": "ok",
     "timestamp": 1630844547848,
     "user": {
      "displayName": "박아정",
      "photoUrl": "",
      "userId": "15223679537180029561"
     },
     "user_tz": -540
    },
    "id": "TR73ZQDHJwv-",
    "outputId": "2031ae46-a7b1-4f61-bbf1-fb15d5482528"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorization...\n",
      "Training Data:\n",
      "(45000, 7, 16)\n",
      "(45000, 6, 16)\n",
      "Validation Data:\n",
      "(5000, 7, 16)\n",
      "(5000, 6, 16)\n"
     ]
    }
   ],
   "source": [
    "print('Vectorization...')\n",
    "# np.zeros(shape, dtype, order)\n",
    "# x : (50000, 7, 15), y : (50000, 6, 15)\n",
    "# 입력데이터를 Encode\n",
    "x = np.zeros((len(questions), MAxLEN, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(questions), DIGITS + 3, len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(questions):\n",
    "    x[i] = ctable.encode(sentence, MAxLEN)\n",
    "for i, sentence in enumerate(expected):\n",
    "    y[i] = ctable.encode(sentence, DIGITS + 3)\n",
    "\n",
    "# Shuffle (x, y) in unison as the later parts of x will almost all be larger\n",
    "# digits.\n",
    "# x의 뒷부분이 더 커지기 때문에 (x, y) 를 섞는다. (???) -> 어쨋든 셔플\n",
    "indices = np.arange(len(y))\n",
    "np.random.shuffle(indices)\n",
    "x = x[indices]\n",
    "y = y[indices]\n",
    "\n",
    "# Explicitly set apart 10% for validation data that we never train over.\n",
    "# Test Set : 0~45000, Validation Set : 45000~50000\n",
    "split_at = len(x) - len(x) // 10\n",
    "(x_train, x_val) = x[:split_at], x[split_at:]\n",
    "(y_train, y_val) = y[:split_at], y[split_at:]\n",
    "\n",
    "print('Training Data:')\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print('Validation Data:')\n",
    "print(x_val.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 955,
     "status": "ok",
     "timestamp": 1630844551517,
     "user": {
      "displayName": "박아정",
      "photoUrl": "",
      "userId": "15223679537180029561"
     },
     "user_tz": -540
    },
    "id": "T2ZFo7R_TC2U",
    "outputId": "1cc82c6e-1986-45e1-a1cf-39f1f0cfe91a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 128)               74240     \n",
      "_________________________________________________________________\n",
      "repeat_vector (RepeatVector) (None, 6, 128)            0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 6, 128)            131584    \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, 6, 16)             2064      \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 6, 16)             0         \n",
      "=================================================================\n",
      "Total params: 207,888\n",
      "Trainable params: 207,888\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Try replacing GRU, or SimpleRNN.\n",
    "RNN = layers.LSTM\n",
    "HIDDEN_SIZE = 128\n",
    "BATCH_SIZE = 128\n",
    "LAYERS = 1\n",
    "\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "\n",
    "# \"Encode\" the input sequence using an RNN, producing an output of HIDDEN_SIZE.\n",
    "# Note: In a situation where your input sequences have a variable length,\n",
    "# use input_shape=(None, num_feature).\n",
    "model.add(RNN(HIDDEN_SIZE, input_shape=(MAxLEN, len(chars))))\n",
    "\n",
    "# As the decoder RNN's input, repeatedly provide with the last hidden state of\n",
    "# RNN for each time step. Repeat 'DIGITS + 1' times as that's the maximum\n",
    "# length of output, e.g., when DIGITS=3, max output is 999+999=1998.\n",
    "model.add(layers.RepeatVector(DIGITS + 3))\n",
    "\n",
    "# The decoder RNN could be multiple layers stacked or a single layer.\n",
    "for _ in range(LAYERS):\n",
    "    # By setting return_sequences to True, return not only the last output but\n",
    "    # all the outputs so far in the form of (num_samples, timesteps,\n",
    "    # output_dim). This is necessary as TimeDistributed in the below expects\n",
    "    # the first dimension to be the timesteps.\n",
    "    # return_sequences(시퀀스 출력 여부): True(각 시퀀스에서 출력, many-to-many 일 때)\n",
    "    model.add(RNN(HIDDEN_SIZE, return_sequences=True))\n",
    "\n",
    "# Apply a dense layer to the every temporal slice of an input. For each of step\n",
    "# of the output sequence, decide which character should be chosen.\n",
    "# TimeDistributed :7개의 시간 단계 각각에 독립적으로 Dense 레이어를 적용\n",
    "model.add(layers.TimeDistributed(layers.Dense(len(chars))))\n",
    "model.add(layers.Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "27aLlS854fJa",
    "outputId": "5a72b93e-7ba0-45af-f967-7d97e95be703"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 1.4460 - accuracy: 0.2426 - val_loss: 1.3204 - val_accuracy: 0.2385\n",
      "WARNING:tensorflow:From <ipython-input-16-75a82d20c71a>:16: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "검증 정확도 0.640%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 1.2711 - accuracy: 0.2457 - val_loss: 1.2422 - val_accuracy: 0.2501\n",
      "검증 정확도 1.200%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 3\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 1.2268 - accuracy: 0.2558 - val_loss: 1.2327 - val_accuracy: 0.2569\n",
      "검증 정확도 2.000%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 4\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 1.1978 - accuracy: 0.2648 - val_loss: 1.1916 - val_accuracy: 0.2673\n",
      "검증 정확도 2.460%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 5\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 1.1683 - accuracy: 0.2751 - val_loss: 1.1709 - val_accuracy: 0.2755\n",
      "검증 정확도 2.240%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 6\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 1.1350 - accuracy: 0.2881 - val_loss: 1.1200 - val_accuracy: 0.2915\n",
      "검증 정확도 3.280%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 7\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 1.0813 - accuracy: 0.3048 - val_loss: 1.0582 - val_accuracy: 0.3097\n",
      "검증 정확도 3.400%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 8\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 1.0239 - accuracy: 0.3221 - val_loss: 1.0147 - val_accuracy: 0.3216\n",
      "검증 정확도 3.880%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 9\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.9830 - accuracy: 0.3350 - val_loss: 0.9705 - val_accuracy: 0.3401\n",
      "검증 정확도 3.920%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 10\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.9472 - accuracy: 0.3476 - val_loss: 0.9447 - val_accuracy: 0.3467\n",
      "검증 정확도 4.380%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 11\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.9178 - accuracy: 0.3580 - val_loss: 0.9204 - val_accuracy: 0.3539\n",
      "검증 정확도 3.640%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 12\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.8927 - accuracy: 0.3668 - val_loss: 0.8931 - val_accuracy: 0.3614\n",
      "검증 정확도 3.860%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 13\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.8709 - accuracy: 0.3750 - val_loss: 0.8726 - val_accuracy: 0.3681\n",
      "검증 정확도 4.300%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 14\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.8512 - accuracy: 0.3814 - val_loss: 0.8609 - val_accuracy: 0.3742\n",
      "검증 정확도 5.160%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 15\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.8335 - accuracy: 0.3872 - val_loss: 0.8437 - val_accuracy: 0.3784\n",
      "검증 정확도 4.180%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 16\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.8162 - accuracy: 0.3933 - val_loss: 0.8218 - val_accuracy: 0.3862\n",
      "검증 정확도 4.360%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 17\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.8016 - accuracy: 0.3978 - val_loss: 0.8093 - val_accuracy: 0.3928\n",
      "검증 정확도 5.260%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 18\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.7861 - accuracy: 0.4034 - val_loss: 0.8026 - val_accuracy: 0.3924\n",
      "검증 정확도 3.980%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 19\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.7727 - accuracy: 0.4085 - val_loss: 0.7886 - val_accuracy: 0.3984\n",
      "검증 정확도 5.160%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 20\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.7601 - accuracy: 0.4142 - val_loss: 0.7777 - val_accuracy: 0.4050\n",
      "검증 정확도 5.020%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 21\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.7468 - accuracy: 0.4196 - val_loss: 0.7686 - val_accuracy: 0.4046\n",
      "검증 정확도 4.980%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 22\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.7357 - accuracy: 0.4245 - val_loss: 0.7548 - val_accuracy: 0.4122\n",
      "검증 정확도 5.600%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 23\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.7245 - accuracy: 0.4289 - val_loss: 0.7505 - val_accuracy: 0.4151\n",
      "검증 정확도 5.760%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 24\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.7143 - accuracy: 0.4335 - val_loss: 0.7350 - val_accuracy: 0.4199\n",
      "검증 정확도 5.320%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 25\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.7051 - accuracy: 0.4371 - val_loss: 0.7306 - val_accuracy: 0.4190\n",
      "검증 정확도 5.900%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 26\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.6969 - accuracy: 0.4396 - val_loss: 0.7373 - val_accuracy: 0.4175\n",
      "검증 정확도 5.380%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 27\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.6860 - accuracy: 0.4455 - val_loss: 0.7139 - val_accuracy: 0.4293\n",
      "검증 정확도 5.880%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 28\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.6760 - accuracy: 0.4502 - val_loss: 0.7101 - val_accuracy: 0.4313\n",
      "검증 정확도 6.120%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 29\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.6662 - accuracy: 0.4559 - val_loss: 0.7015 - val_accuracy: 0.4328\n",
      "검증 정확도 5.900%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 30\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.6561 - accuracy: 0.4601 - val_loss: 0.6946 - val_accuracy: 0.4374\n",
      "검증 정확도 6.060%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 31\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.6437 - accuracy: 0.4662 - val_loss: 0.6839 - val_accuracy: 0.4438\n",
      "검증 정확도 6.440%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 32\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.6312 - accuracy: 0.4724 - val_loss: 0.6776 - val_accuracy: 0.4496\n",
      "검증 정확도 6.580%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 33\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.6220 - accuracy: 0.4770 - val_loss: 0.6670 - val_accuracy: 0.4508\n",
      "검증 정확도 5.760%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 34\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.6100 - accuracy: 0.4834 - val_loss: 0.6572 - val_accuracy: 0.4584\n",
      "검증 정확도 6.520%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 35\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.5980 - accuracy: 0.4880 - val_loss: 0.6507 - val_accuracy: 0.4606\n",
      "검증 정확도 6.100%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 36\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.5889 - accuracy: 0.4922 - val_loss: 0.6308 - val_accuracy: 0.4708\n",
      "검증 정확도 6.460%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 37\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.5729 - accuracy: 0.4995 - val_loss: 0.6292 - val_accuracy: 0.4688\n",
      "검증 정확도 6.440%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 38\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.5604 - accuracy: 0.5043 - val_loss: 0.6106 - val_accuracy: 0.4800\n",
      "검증 정확도 6.640%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 39\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.5483 - accuracy: 0.5101 - val_loss: 0.6069 - val_accuracy: 0.4799\n",
      "검증 정확도 6.660%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 40\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.5368 - accuracy: 0.5142 - val_loss: 0.5928 - val_accuracy: 0.4847\n",
      "검증 정확도 6.580%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 41\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.5240 - accuracy: 0.5204 - val_loss: 0.5906 - val_accuracy: 0.4890\n",
      "검증 정확도 6.080%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 42\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.5147 - accuracy: 0.5242 - val_loss: 0.5781 - val_accuracy: 0.4934\n",
      "검증 정확도 6.040%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 43\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.5034 - accuracy: 0.5283 - val_loss: 0.5660 - val_accuracy: 0.4989\n",
      "검증 정확도 6.640%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 44\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.4944 - accuracy: 0.5319 - val_loss: 0.5620 - val_accuracy: 0.5001\n",
      "검증 정확도 6.800%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 45\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.4837 - accuracy: 0.5368 - val_loss: 0.5497 - val_accuracy: 0.5056\n",
      "검증 정확도 7.180%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 46\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.4743 - accuracy: 0.5400 - val_loss: 0.5428 - val_accuracy: 0.5071\n",
      "검증 정확도 6.540%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 47\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.4653 - accuracy: 0.5431 - val_loss: 0.5384 - val_accuracy: 0.5082\n",
      "검증 정확도 6.800%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 48\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.4591 - accuracy: 0.5453 - val_loss: 0.5386 - val_accuracy: 0.5101\n",
      "검증 정확도 6.940%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 49\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.4496 - accuracy: 0.5503 - val_loss: 0.5283 - val_accuracy: 0.5149\n",
      "검증 정확도 7.020%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 50\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.4418 - accuracy: 0.5523 - val_loss: 0.5205 - val_accuracy: 0.5161\n",
      "검증 정확도 6.660%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 51\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.4355 - accuracy: 0.5548 - val_loss: 0.5189 - val_accuracy: 0.5186\n",
      "검증 정확도 6.620%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 52\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.4302 - accuracy: 0.5572 - val_loss: 0.5151 - val_accuracy: 0.5191\n",
      "검증 정확도 6.900%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 53\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.4239 - accuracy: 0.5596 - val_loss: 0.5114 - val_accuracy: 0.5226\n",
      "검증 정확도 6.960%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 54\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.4176 - accuracy: 0.5617 - val_loss: 0.5093 - val_accuracy: 0.5230\n",
      "검증 정확도 6.700%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 55\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.4109 - accuracy: 0.5644 - val_loss: 0.5069 - val_accuracy: 0.5242\n",
      "검증 정확도 6.980%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 56\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.4060 - accuracy: 0.5662 - val_loss: 0.4988 - val_accuracy: 0.5263\n",
      "검증 정확도 6.760%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 57\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.4002 - accuracy: 0.5684 - val_loss: 0.4995 - val_accuracy: 0.5241\n",
      "검증 정확도 6.940%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 58\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.3956 - accuracy: 0.5703 - val_loss: 0.4954 - val_accuracy: 0.5271\n",
      "검증 정확도 6.920%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 59\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.3917 - accuracy: 0.5720 - val_loss: 0.4995 - val_accuracy: 0.5279\n",
      "검증 정확도 6.800%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 60\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.3865 - accuracy: 0.5741 - val_loss: 0.4899 - val_accuracy: 0.5317\n",
      "검증 정확도 6.880%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 61\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.3821 - accuracy: 0.5758 - val_loss: 0.4880 - val_accuracy: 0.5319\n",
      "검증 정확도 7.060%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 62\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.3764 - accuracy: 0.5782 - val_loss: 0.4879 - val_accuracy: 0.5310\n",
      "검증 정확도 6.960%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 63\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.3746 - accuracy: 0.5787 - val_loss: 0.4954 - val_accuracy: 0.5306\n",
      "검증 정확도 6.960%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 64\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.3705 - accuracy: 0.5805 - val_loss: 0.4838 - val_accuracy: 0.5329\n",
      "검증 정확도 6.860%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 65\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.3665 - accuracy: 0.5819 - val_loss: 0.4841 - val_accuracy: 0.5324\n",
      "검증 정확도 6.920%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 66\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.3622 - accuracy: 0.5835 - val_loss: 0.4835 - val_accuracy: 0.5333\n",
      "검증 정확도 6.740%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 67\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.3583 - accuracy: 0.5853 - val_loss: 0.4826 - val_accuracy: 0.5339\n",
      "검증 정확도 7.280%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 68\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.3535 - accuracy: 0.5870 - val_loss: 0.4812 - val_accuracy: 0.5363\n",
      "검증 정확도 7.180%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 69\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.3512 - accuracy: 0.5876 - val_loss: 0.4796 - val_accuracy: 0.5357\n",
      "검증 정확도 6.840%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 70\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.3489 - accuracy: 0.5883 - val_loss: 0.4794 - val_accuracy: 0.5390\n",
      "검증 정확도 7.320%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 71\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.3464 - accuracy: 0.5895 - val_loss: 0.4794 - val_accuracy: 0.5365\n",
      "검증 정확도 6.940%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 72\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.3400 - accuracy: 0.5926 - val_loss: 0.4818 - val_accuracy: 0.5349\n",
      "검증 정확도 7.240%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 73\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.3378 - accuracy: 0.5931 - val_loss: 0.4816 - val_accuracy: 0.5350\n",
      "검증 정확도 6.520%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 74\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.3356 - accuracy: 0.5942 - val_loss: 0.4748 - val_accuracy: 0.5392\n",
      "검증 정확도 6.920%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 75\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.3331 - accuracy: 0.5945 - val_loss: 0.4839 - val_accuracy: 0.5373\n",
      "검증 정확도 6.980%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 76\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "352/352 [==============================] - 2s 6ms/step - loss: 0.3308 - accuracy: 0.5952 - val_loss: 0.4770 - val_accuracy: 0.5405\n",
      "검증 정확도 7.160%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 77\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.3252 - accuracy: 0.5977 - val_loss: 0.4782 - val_accuracy: 0.5400\n",
      "검증 정확도 7.020%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 78\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.3242 - accuracy: 0.5979 - val_loss: 0.4940 - val_accuracy: 0.5350\n",
      "검증 정확도 7.300%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 79\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.3219 - accuracy: 0.5991 - val_loss: 0.4794 - val_accuracy: 0.5420\n",
      "검증 정확도 6.880%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 80\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.3169 - accuracy: 0.6012 - val_loss: 0.4825 - val_accuracy: 0.5389\n",
      "검증 정확도 7.100%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 81\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.3145 - accuracy: 0.6016 - val_loss: 0.4836 - val_accuracy: 0.5394\n",
      "검증 정확도 7.120%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 82\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.3145 - accuracy: 0.6015 - val_loss: 0.4852 - val_accuracy: 0.5390\n",
      "검증 정확도 7.040%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 83\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.3090 - accuracy: 0.6043 - val_loss: 0.4808 - val_accuracy: 0.5404\n",
      "검증 정확도 7.040%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 84\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.3094 - accuracy: 0.6035 - val_loss: 0.4789 - val_accuracy: 0.5408\n",
      "검증 정확도 6.820%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 85\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.3057 - accuracy: 0.6053 - val_loss: 0.4826 - val_accuracy: 0.5411\n",
      "검증 정확도 6.800%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 86\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.3002 - accuracy: 0.6079 - val_loss: 0.4984 - val_accuracy: 0.5386\n",
      "검증 정확도 7.340%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 87\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.3002 - accuracy: 0.6076 - val_loss: 0.4902 - val_accuracy: 0.5413\n",
      "검증 정확도 7.120%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 88\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.3001 - accuracy: 0.6071 - val_loss: 0.4898 - val_accuracy: 0.5425\n",
      "검증 정확도 7.060%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 89\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.2939 - accuracy: 0.6100 - val_loss: 0.4857 - val_accuracy: 0.5413\n",
      "검증 정확도 7.360%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 90\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.2938 - accuracy: 0.6098 - val_loss: 0.5036 - val_accuracy: 0.5383\n",
      "검증 정확도 7.200%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 91\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.2899 - accuracy: 0.6112 - val_loss: 0.4858 - val_accuracy: 0.5435\n",
      "검증 정확도 7.160%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 92\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.2881 - accuracy: 0.6120 - val_loss: 0.4868 - val_accuracy: 0.5435\n",
      "검증 정확도 7.540%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 93\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.2858 - accuracy: 0.6125 - val_loss: 0.4889 - val_accuracy: 0.5427\n",
      "검증 정확도 6.880%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 94\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.2836 - accuracy: 0.6135 - val_loss: 0.5021 - val_accuracy: 0.5398\n",
      "검증 정확도 7.320%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 95\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.2860 - accuracy: 0.6126 - val_loss: 0.4880 - val_accuracy: 0.5444\n",
      "검증 정확도 7.400%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 96\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.2762 - accuracy: 0.6170 - val_loss: 0.4907 - val_accuracy: 0.5439\n",
      "검증 정확도 6.900%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 97\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.2775 - accuracy: 0.6163 - val_loss: 0.4931 - val_accuracy: 0.5441\n",
      "검증 정확도 7.560%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 98\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.2727 - accuracy: 0.6179 - val_loss: 0.4977 - val_accuracy: 0.5431\n",
      "검증 정확도 7.480%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 99\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.2720 - accuracy: 0.6178 - val_loss: 0.5022 - val_accuracy: 0.5419\n",
      "검증 정확도 7.300%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 100\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.2742 - accuracy: 0.6172 - val_loss: 0.5128 - val_accuracy: 0.5401\n",
      "검증 정확도 6.880%\n",
      "100번째 정확도 :  0.0688\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 101\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.2677 - accuracy: 0.6198 - val_loss: 0.5012 - val_accuracy: 0.5440\n",
      "검증 정확도 7.200%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 102\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.2638 - accuracy: 0.6218 - val_loss: 0.4968 - val_accuracy: 0.5449\n",
      "검증 정확도 7.320%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 103\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.2623 - accuracy: 0.6221 - val_loss: 0.5136 - val_accuracy: 0.5413\n",
      "검증 정확도 7.060%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 104\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.2643 - accuracy: 0.6209 - val_loss: 0.5168 - val_accuracy: 0.5417\n",
      "검증 정확도 7.100%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 105\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.2601 - accuracy: 0.6228 - val_loss: 0.5159 - val_accuracy: 0.5419\n",
      "검증 정확도 7.180%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 106\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.2582 - accuracy: 0.6236 - val_loss: 0.5103 - val_accuracy: 0.5434\n",
      "검증 정확도 7.140%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 107\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.2570 - accuracy: 0.6237 - val_loss: 0.5145 - val_accuracy: 0.5424\n",
      "검증 정확도 6.920%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 108\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.2595 - accuracy: 0.6229 - val_loss: 0.5318 - val_accuracy: 0.5392\n",
      "검증 정확도 7.160%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 109\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.2522 - accuracy: 0.6259 - val_loss: 0.5177 - val_accuracy: 0.5448\n",
      "검증 정확도 7.260%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 110\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.2475 - accuracy: 0.6282 - val_loss: 0.5249 - val_accuracy: 0.5432\n",
      "검증 정확도 7.340%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 111\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.2470 - accuracy: 0.6280 - val_loss: 0.5280 - val_accuracy: 0.5426\n",
      "검증 정확도 7.240%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 112\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.2465 - accuracy: 0.6283 - val_loss: 0.5353 - val_accuracy: 0.5411\n",
      "검증 정확도 7.140%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 113\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.2419 - accuracy: 0.6300 - val_loss: 0.5247 - val_accuracy: 0.5427\n",
      "검증 정확도 7.240%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 114\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.2458 - accuracy: 0.6280 - val_loss: 0.5308 - val_accuracy: 0.5407\n",
      "검증 정확도 7.080%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 115\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "352/352 [==============================] - 2s 6ms/step - loss: 0.2405 - accuracy: 0.6304 - val_loss: 0.5301 - val_accuracy: 0.5418\n",
      "검증 정확도 6.940%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 116\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.2423 - accuracy: 0.6299 - val_loss: 0.5328 - val_accuracy: 0.5432\n",
      "검증 정확도 7.220%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 117\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.2358 - accuracy: 0.6327 - val_loss: 0.5294 - val_accuracy: 0.5427\n",
      "검증 정확도 7.200%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 118\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.2375 - accuracy: 0.6321 - val_loss: 0.5452 - val_accuracy: 0.5421\n",
      "검증 정확도 6.960%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 119\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.2315 - accuracy: 0.6340 - val_loss: 0.5494 - val_accuracy: 0.5383\n",
      "검증 정확도 7.140%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 120\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.2289 - accuracy: 0.6354 - val_loss: 0.5529 - val_accuracy: 0.5418\n",
      "검증 정확도 7.200%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 121\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.2276 - accuracy: 0.6359 - val_loss: 0.5478 - val_accuracy: 0.5430\n",
      "검증 정확도 7.380%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 122\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.2354 - accuracy: 0.6322 - val_loss: 0.5612 - val_accuracy: 0.5388\n",
      "검증 정확도 7.420%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 123\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.2277 - accuracy: 0.6354 - val_loss: 0.5481 - val_accuracy: 0.5420\n",
      "검증 정확도 7.060%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 124\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.2202 - accuracy: 0.6390 - val_loss: 0.5476 - val_accuracy: 0.5426\n",
      "검증 정확도 7.180%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 125\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.2239 - accuracy: 0.6368 - val_loss: 0.5611 - val_accuracy: 0.5401\n",
      "검증 정확도 7.140%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 126\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.2214 - accuracy: 0.6381 - val_loss: 0.5611 - val_accuracy: 0.5431\n",
      "검증 정확도 7.320%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 127\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.2190 - accuracy: 0.6386 - val_loss: 0.5624 - val_accuracy: 0.5415\n",
      "검증 정확도 7.200%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 128\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.2144 - accuracy: 0.6407 - val_loss: 0.5645 - val_accuracy: 0.5404\n",
      "검증 정확도 7.260%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 129\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.2139 - accuracy: 0.6412 - val_loss: 0.5649 - val_accuracy: 0.5418\n",
      "검증 정확도 7.320%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 130\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.2175 - accuracy: 0.6391 - val_loss: 0.5955 - val_accuracy: 0.5364\n",
      "검증 정확도 7.060%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 131\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.2168 - accuracy: 0.6392 - val_loss: 0.5735 - val_accuracy: 0.5409\n",
      "검증 정확도 7.340%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 132\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.2068 - accuracy: 0.6439 - val_loss: 0.5896 - val_accuracy: 0.5376\n",
      "검증 정확도 7.240%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 133\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.2126 - accuracy: 0.6412 - val_loss: 0.5835 - val_accuracy: 0.5381\n",
      "검증 정확도 7.020%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 134\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.2047 - accuracy: 0.6445 - val_loss: 0.5937 - val_accuracy: 0.5380\n",
      "검증 정확도 6.920%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 135\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.2018 - accuracy: 0.6456 - val_loss: 0.5827 - val_accuracy: 0.5411\n",
      "검증 정확도 7.080%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 136\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.2031 - accuracy: 0.6450 - val_loss: 0.5981 - val_accuracy: 0.5391\n",
      "검증 정확도 7.380%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 137\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.2023 - accuracy: 0.6454 - val_loss: 0.5941 - val_accuracy: 0.5391\n",
      "검증 정확도 6.980%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 138\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.2051 - accuracy: 0.6438 - val_loss: 0.6066 - val_accuracy: 0.5379\n",
      "검증 정확도 7.000%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 139\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.1987 - accuracy: 0.6464 - val_loss: 0.5906 - val_accuracy: 0.5417\n",
      "검증 정확도 7.480%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 140\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.1939 - accuracy: 0.6489 - val_loss: 0.6035 - val_accuracy: 0.5387\n",
      "검증 정확도 7.080%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 141\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.1939 - accuracy: 0.6484 - val_loss: 0.6133 - val_accuracy: 0.5371\n",
      "검증 정확도 6.940%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 142\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.2038 - accuracy: 0.6444 - val_loss: 0.6066 - val_accuracy: 0.5383\n",
      "검증 정확도 7.220%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 143\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.1915 - accuracy: 0.6494 - val_loss: 0.6151 - val_accuracy: 0.5388\n",
      "검증 정확도 7.060%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 144\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.1880 - accuracy: 0.6511 - val_loss: 0.6183 - val_accuracy: 0.5370\n",
      "검증 정확도 7.200%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 145\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.1871 - accuracy: 0.6511 - val_loss: 0.6189 - val_accuracy: 0.5367\n",
      "검증 정확도 7.020%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 146\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.1930 - accuracy: 0.6484 - val_loss: 0.6238 - val_accuracy: 0.5399\n",
      "검증 정확도 7.160%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 147\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.1852 - accuracy: 0.6519 - val_loss: 0.6235 - val_accuracy: 0.5389\n",
      "검증 정확도 7.220%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 148\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.1829 - accuracy: 0.6528 - val_loss: 0.6323 - val_accuracy: 0.5372\n",
      "검증 정확도 7.180%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 149\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.1849 - accuracy: 0.6516 - val_loss: 0.6331 - val_accuracy: 0.5359\n",
      "검증 정확도 6.840%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 150\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.1825 - accuracy: 0.6527 - val_loss: 0.6375 - val_accuracy: 0.5355\n",
      "검증 정확도 6.920%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 151\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.1796 - accuracy: 0.6538 - val_loss: 0.6411 - val_accuracy: 0.5366\n",
      "검증 정확도 6.900%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 152\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.1769 - accuracy: 0.6557 - val_loss: 0.6579 - val_accuracy: 0.5351\n",
      "검증 정확도 7.060%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 153\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.1776 - accuracy: 0.6549 - val_loss: 0.6562 - val_accuracy: 0.5350\n",
      "검증 정확도 6.920%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "352/352 [==============================] - 2s 6ms/step - loss: 0.1743 - accuracy: 0.6565 - val_loss: 0.6454 - val_accuracy: 0.5364\n",
      "검증 정확도 7.040%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 155\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.1760 - accuracy: 0.6553 - val_loss: 0.6631 - val_accuracy: 0.5356\n",
      "검증 정확도 6.680%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 156\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.1710 - accuracy: 0.6576 - val_loss: 0.6668 - val_accuracy: 0.5357\n",
      "검증 정확도 6.540%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 157\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.1678 - accuracy: 0.6584 - val_loss: 0.6675 - val_accuracy: 0.5355\n",
      "검증 정확도 7.140%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 158\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.1708 - accuracy: 0.6575 - val_loss: 0.6722 - val_accuracy: 0.5358\n",
      "검증 정확도 6.780%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 159\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.1679 - accuracy: 0.6587 - val_loss: 0.6709 - val_accuracy: 0.5341\n",
      "검증 정확도 6.720%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 160\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.1645 - accuracy: 0.6599 - val_loss: 0.6762 - val_accuracy: 0.5356\n",
      "검증 정확도 6.720%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 161\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.1657 - accuracy: 0.6594 - val_loss: 0.6784 - val_accuracy: 0.5339\n",
      "검증 정확도 7.060%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 162\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.1697 - accuracy: 0.6573 - val_loss: 0.6814 - val_accuracy: 0.5342\n",
      "검증 정확도 6.880%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 163\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.1598 - accuracy: 0.6619 - val_loss: 0.6929 - val_accuracy: 0.5325\n",
      "검증 정확도 6.720%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 164\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.1626 - accuracy: 0.6602 - val_loss: 0.7050 - val_accuracy: 0.5309\n",
      "검증 정확도 6.620%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 165\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.1693 - accuracy: 0.6575 - val_loss: 0.6900 - val_accuracy: 0.5332\n",
      "검증 정확도 6.760%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 166\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.1550 - accuracy: 0.6636 - val_loss: 0.6930 - val_accuracy: 0.5365\n",
      "검증 정확도 6.860%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 167\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.1527 - accuracy: 0.6644 - val_loss: 0.6899 - val_accuracy: 0.5355\n",
      "검증 정확도 6.840%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 168\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.1490 - accuracy: 0.6661 - val_loss: 0.7022 - val_accuracy: 0.5346\n",
      "검증 정확도 6.760%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 169\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.1529 - accuracy: 0.6642 - val_loss: 0.7134 - val_accuracy: 0.5325\n",
      "검증 정확도 6.740%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 170\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.1584 - accuracy: 0.6617 - val_loss: 0.7303 - val_accuracy: 0.5293\n",
      "검증 정확도 6.700%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 171\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.1539 - accuracy: 0.6637 - val_loss: 0.7214 - val_accuracy: 0.5331\n",
      "검증 정확도 6.920%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 172\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.1459 - accuracy: 0.6668 - val_loss: 0.7071 - val_accuracy: 0.5345\n",
      "검증 정확도 6.880%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 173\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.1437 - accuracy: 0.6678 - val_loss: 0.7236 - val_accuracy: 0.5318\n",
      "검증 정확도 6.820%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 174\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.1478 - accuracy: 0.6664 - val_loss: 0.7336 - val_accuracy: 0.5313\n",
      "검증 정확도 6.520%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 175\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.1530 - accuracy: 0.6640 - val_loss: 0.7407 - val_accuracy: 0.5297\n",
      "검증 정확도 6.660%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 176\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.1454 - accuracy: 0.6669 - val_loss: 0.7459 - val_accuracy: 0.5309\n",
      "검증 정확도 6.720%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 177\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.1477 - accuracy: 0.6661 - val_loss: 0.7421 - val_accuracy: 0.5303\n",
      "검증 정확도 6.800%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 178\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.1391 - accuracy: 0.6695 - val_loss: 0.7394 - val_accuracy: 0.5315\n",
      "검증 정확도 6.720%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 179\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.1385 - accuracy: 0.6695 - val_loss: 0.7503 - val_accuracy: 0.5327\n",
      "검증 정확도 6.860%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 180\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.1394 - accuracy: 0.6695 - val_loss: 0.7501 - val_accuracy: 0.5320\n",
      "검증 정확도 6.620%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 181\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.1344 - accuracy: 0.6712 - val_loss: 0.7697 - val_accuracy: 0.5295\n",
      "검증 정확도 6.460%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 182\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.1358 - accuracy: 0.6706 - val_loss: 0.7746 - val_accuracy: 0.5296\n",
      "검증 정확도 6.680%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 183\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.1385 - accuracy: 0.6693 - val_loss: 0.7644 - val_accuracy: 0.5278\n",
      "검증 정확도 6.360%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 184\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.1404 - accuracy: 0.6681 - val_loss: 0.7764 - val_accuracy: 0.5285\n",
      "검증 정확도 6.420%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 185\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.1424 - accuracy: 0.6674 - val_loss: 0.7654 - val_accuracy: 0.5306\n",
      "검증 정확도 6.700%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 186\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.1256 - accuracy: 0.6752 - val_loss: 0.7757 - val_accuracy: 0.5296\n",
      "검증 정확도 6.920%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 187\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.1233 - accuracy: 0.6760 - val_loss: 0.7802 - val_accuracy: 0.5315\n",
      "검증 정확도 6.900%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 188\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.1274 - accuracy: 0.6737 - val_loss: 0.7984 - val_accuracy: 0.5306\n",
      "검증 정확도 6.540%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 189\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.1387 - accuracy: 0.6692 - val_loss: 0.7965 - val_accuracy: 0.5290\n",
      "검증 정확도 6.340%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 190\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.1284 - accuracy: 0.6737 - val_loss: 0.7900 - val_accuracy: 0.5288\n",
      "검증 정확도 6.500%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 191\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.1208 - accuracy: 0.6767 - val_loss: 0.8108 - val_accuracy: 0.5288\n",
      "검증 정확도 6.540%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 192\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.1244 - accuracy: 0.6749 - val_loss: 0.8069 - val_accuracy: 0.5291\n",
      "검증 정확도 6.620%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 193\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "352/352 [==============================] - 2s 6ms/step - loss: 0.1258 - accuracy: 0.6743 - val_loss: 0.8111 - val_accuracy: 0.5270\n",
      "검증 정확도 6.680%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 194\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.1302 - accuracy: 0.6722 - val_loss: 0.8086 - val_accuracy: 0.5284\n",
      "검증 정확도 6.840%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 195\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.1199 - accuracy: 0.6766 - val_loss: 0.8291 - val_accuracy: 0.5306\n",
      "검증 정확도 6.660%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 196\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.1194 - accuracy: 0.6770 - val_loss: 0.8211 - val_accuracy: 0.5291\n",
      "검증 정확도 6.520%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 197\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.1231 - accuracy: 0.6749 - val_loss: 0.8127 - val_accuracy: 0.5304\n",
      "검증 정확도 6.780%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 198\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.1118 - accuracy: 0.6802 - val_loss: 0.8269 - val_accuracy: 0.5301\n",
      "검증 정확도 6.800%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 199\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.1123 - accuracy: 0.6795 - val_loss: 0.8449 - val_accuracy: 0.5283\n",
      "검증 정확도 6.400%\n"
     ]
    }
   ],
   "source": [
    "# Train the model each generation and show predictions against the validation\n",
    "# dataset.\n",
    "acc_list = []\n",
    "history_list = []\n",
    "\n",
    "for iteration in range(1, 200):\n",
    "    print()\n",
    "    print('-' * 50)\n",
    "    print('Iteration', iteration)\n",
    "    history = model.fit(x_train, y_train, batch_size=BATCH_SIZE, verbose = 1, epochs=1,\n",
    "              validation_data=(x_val, y_val))\n",
    "    # Select samples from the validation set at random so we can visualize\n",
    "    # errors.\n",
    "    history_list.append(history.history.get('val_accuracy')[0])\n",
    "    \n",
    "    correct_num = 0\n",
    "    for i in range(len(x_val)):\n",
    "        rowx, rowy = x_val[np.array([i])], y_val[np.array([i])]\n",
    "        # predict_classes : 0 or 1로 출력 (predict 와 약간 다름) --> 2.6버전에서 삭제됨\n",
    "        preds = model.predict_classes(rowx, verbose=0)\n",
    "        q = ctable.decode(rowx[0])\n",
    "        correct = ctable.decode(rowy[0])\n",
    "        guess = ctable.decode(preds[0], calc_argmax=False)\n",
    "        \n",
    "        if guess == correct:\n",
    "          correct_num += 1\n",
    "        else:\n",
    "          correct_num += 0\n",
    "        # print('guess: ', guess)\n",
    "        # print('Q', q[::-1] if INVERT else q)\n",
    "        # print('T', correct)\n",
    "        # if correct == guess:\n",
    "        #     print(colors.ok + '☑' + colors.close, end=\" \")\n",
    "        # else:\n",
    "        #     print(colors.fail + '☒' + colors.close, end=\" \")\n",
    "        # print(guess)\n",
    "        # print('---')\n",
    "\n",
    "    acc = float(correct_num) / len(x_val)\n",
    "    acc_list.append(acc)\n",
    "    print('검증 정확도 %.3f%%' % (acc * 100))\n",
    "    if iteration == 100:\n",
    "      print('100번째 정확도 : ', acc)\n",
    "model.save('3digit_1arith.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0064, 0.012, 0.02, 0.0246, 0.0224, 0.0328, 0.034, 0.0388, 0.0392, 0.0438, 0.0364, 0.0386, 0.043, 0.0516, 0.0418, 0.0436, 0.0526, 0.0398, 0.0516, 0.0502, 0.0498, 0.056, 0.0576, 0.0532, 0.059, 0.0538, 0.0588, 0.0612, 0.059, 0.0606, 0.0644, 0.0658, 0.0576, 0.0652, 0.061, 0.0646, 0.0644, 0.0664, 0.0666, 0.0658, 0.0608, 0.0604, 0.0664, 0.068, 0.0718, 0.0654, 0.068, 0.0694, 0.0702, 0.0666, 0.0662, 0.069, 0.0696, 0.067, 0.0698, 0.0676, 0.0694, 0.0692, 0.068, 0.0688, 0.0706, 0.0696, 0.0696, 0.0686, 0.0692, 0.0674, 0.0728, 0.0718, 0.0684, 0.0732, 0.0694, 0.0724, 0.0652, 0.0692, 0.0698, 0.0716, 0.0702, 0.073, 0.0688, 0.071, 0.0712, 0.0704, 0.0704, 0.0682, 0.068, 0.0734, 0.0712, 0.0706, 0.0736, 0.072, 0.0716, 0.0754, 0.0688, 0.0732, 0.074, 0.069, 0.0756, 0.0748, 0.073, 0.0688, 0.072, 0.0732, 0.0706, 0.071, 0.0718, 0.0714, 0.0692, 0.0716, 0.0726, 0.0734, 0.0724, 0.0714, 0.0724, 0.0708, 0.0694, 0.0722, 0.072, 0.0696, 0.0714, 0.072, 0.0738, 0.0742, 0.0706, 0.0718, 0.0714, 0.0732, 0.072, 0.0726, 0.0732, 0.0706, 0.0734, 0.0724, 0.0702, 0.0692, 0.0708, 0.0738, 0.0698, 0.07, 0.0748, 0.0708, 0.0694, 0.0722, 0.0706, 0.072, 0.0702, 0.0716, 0.0722, 0.0718, 0.0684, 0.0692, 0.069, 0.0706, 0.0692, 0.0704, 0.0668, 0.0654, 0.0714, 0.0678, 0.0672, 0.0672, 0.0706, 0.0688, 0.0672, 0.0662, 0.0676, 0.0686, 0.0684, 0.0676, 0.0674, 0.067, 0.0692, 0.0688, 0.0682, 0.0652, 0.0666, 0.0672, 0.068, 0.0672, 0.0686, 0.0662, 0.0646, 0.0668, 0.0636, 0.0642, 0.067, 0.0692, 0.069, 0.0654, 0.0634, 0.065, 0.0654, 0.0662, 0.0668, 0.0684, 0.0666, 0.0652, 0.0678, 0.068, 0.064]\n"
     ]
    }
   ],
   "source": [
    "print(acc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "aborted",
     "timestamp": 1630841828246,
     "user": {
      "displayName": "박아정",
      "photoUrl": "",
      "userId": "15223679537180029561"
     },
     "user_tz": -540
    },
    "id": "vq0bijYVEuTf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tako/.local/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:238: RuntimeWarning: Glyph 50640 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/home/tako/.local/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:238: RuntimeWarning: Glyph 54253 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/home/tako/.local/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:238: RuntimeWarning: Glyph 51221 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/home/tako/.local/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:238: RuntimeWarning: Glyph 54869 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/home/tako/.local/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:238: RuntimeWarning: Glyph 46020 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/home/tako/.local/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:201: RuntimeWarning: Glyph 50640 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/home/tako/.local/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:201: RuntimeWarning: Glyph 54253 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/home/tako/.local/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:201: RuntimeWarning: Glyph 51221 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/home/tako/.local/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:201: RuntimeWarning: Glyph 54869 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/home/tako/.local/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:201: RuntimeWarning: Glyph 46020 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 그래프 그리기\n",
    "x = np.arange(len(acc_list))\n",
    "plt.plot(x, acc_list, marker='o')\n",
    "plt.xlabel('에폭')\n",
    "plt.ylabel('정확도')\n",
    "plt.ylim(0, 1.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그래프 그리기\n",
    "v = np.arange(len(history_list))\n",
    "plt.plot(v, history_list, marker='o')\n",
    "plt.xlabel('에폭')\n",
    "plt.ylabel('정확도')\n",
    "plt.ylim(0, 1.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "## summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation)."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPSuHHskcvJbnYX983dMC3b",
   "collapsed_sections": [],
   "name": "arithmetic_rnn.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
