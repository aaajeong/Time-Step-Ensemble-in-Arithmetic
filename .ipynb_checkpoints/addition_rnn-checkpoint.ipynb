{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gZI5NIQA4jPH"
   },
   "source": [
    "# **Keras 예제 - Seq2Seq 로 덧셈 구현**\n",
    "\n",
    "출처 : https://github.com/keras-team/keras/blob/2.0.0/examples/addition_rnn.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "executionInfo": {
     "elapsed": 527,
     "status": "ok",
     "timestamp": 1630824563355,
     "user": {
      "displayName": "박아정",
      "photoUrl": "",
      "userId": "15223679537180029561"
     },
     "user_tz": -540
    },
    "id": "P5N5RDNI5Gpr",
    "outputId": "3f503f2c-c7a9-4663-991a-9035d3cc2914"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'An implementation of sequence to sequence learning for performing addition\\nInput: \"535+61\"\\nOutput: \"596\"\\nPadding is handled by using a repeated sentinel character (space)\\nInput may optionally be inverted, shown to increase performance in many tasks in:\\n\"Learning to Execute\"\\nhttp://arxiv.org/abs/1410.4615\\nand\\n\"Sequence to Sequence Learning with Neural Networks\"\\nhttp://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf\\nTheoretically it introduces shorter term dependencies between source and target.\\nTwo digits inverted:\\n+ One layer LSTM (128 HN), 5k training examples = 99% train/test accuracy in 55 epochs\\nThree digits inverted:\\n+ One layer LSTM (128 HN), 50k training examples = 99% train/test accuracy in 100 epochs\\nFour digits inverted:\\n+ One layer LSTM (128 HN), 400k training examples = 99% train/test accuracy in 20 epochs\\nFive digits inverted:\\n+ One layer LSTM (128 HN), 550k training examples = 99% train/test accuracy in 30 epochs\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "'''An implementation of sequence to sequence learning for performing addition\n",
    "Input: \"535+61\"\n",
    "Output: \"596\"\n",
    "Padding is handled by using a repeated sentinel character (space)\n",
    "Input may optionally be inverted, shown to increase performance in many tasks in:\n",
    "\"Learning to Execute\"\n",
    "http://arxiv.org/abs/1410.4615\n",
    "and\n",
    "\"Sequence to Sequence Learning with Neural Networks\"\n",
    "http://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf\n",
    "Theoretically it introduces shorter term dependencies between source and target.\n",
    "Two digits inverted:\n",
    "+ One layer LSTM (128 HN), 5k training examples = 99% train/test accuracy in 55 epochs\n",
    "Three digits inverted:\n",
    "+ One layer LSTM (128 HN), 50k training examples = 99% train/test accuracy in 100 epochs\n",
    "Four digits inverted:\n",
    "+ One layer LSTM (128 HN), 400k training examples = 99% train/test accuracy in 20 epochs\n",
    "Five digits inverted:\n",
    "+ One layer LSTM (128 HN), 550k training examples = 99% train/test accuracy in 30 epochs\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1630824563356,
     "user": {
      "displayName": "박아정",
      "photoUrl": "",
      "userId": "15223679537180029561"
     },
     "user_tz": -540
    },
    "id": "UalzhCNK5M8Q"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "from six.moves import range\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 2185181035200956306,\n",
       " name: \"/device:XLA_CPU:0\"\n",
       " device_type: \"XLA_CPU\"\n",
       " memory_limit: 17179869184\n",
       " locality {\n",
       " }\n",
       " incarnation: 1955697916297964158\n",
       " physical_device_desc: \"device: XLA_CPU device\",\n",
       " name: \"/device:GPU:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 10992173056\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 2902826110624767260\n",
       " physical_device_desc: \"device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:03:00.0, compute capability: 6.1\",\n",
       " name: \"/device:GPU:1\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 10992173056\n",
       " locality {\n",
       "   bus_id: 2\n",
       "   numa_node: 1\n",
       "   links {\n",
       "     link {\n",
       "       device_id: 2\n",
       "       type: \"StreamExecutor\"\n",
       "       strength: 1\n",
       "     }\n",
       "     link {\n",
       "       device_id: 3\n",
       "       type: \"StreamExecutor\"\n",
       "       strength: 1\n",
       "     }\n",
       "     link {\n",
       "       device_id: 4\n",
       "       type: \"StreamExecutor\"\n",
       "       strength: 1\n",
       "     }\n",
       "   }\n",
       " }\n",
       " incarnation: 4996073574755712215\n",
       " physical_device_desc: \"device: 1, name: GeForce GTX 1080 Ti, pci bus id: 0000:83:00.0, compute capability: 6.1\",\n",
       " name: \"/device:GPU:2\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 10992173056\n",
       " locality {\n",
       "   bus_id: 2\n",
       "   numa_node: 1\n",
       "   links {\n",
       "     link {\n",
       "       device_id: 1\n",
       "       type: \"StreamExecutor\"\n",
       "       strength: 1\n",
       "     }\n",
       "     link {\n",
       "       device_id: 3\n",
       "       type: \"StreamExecutor\"\n",
       "       strength: 1\n",
       "     }\n",
       "     link {\n",
       "       device_id: 4\n",
       "       type: \"StreamExecutor\"\n",
       "       strength: 1\n",
       "     }\n",
       "   }\n",
       " }\n",
       " incarnation: 1848386504123169255\n",
       " physical_device_desc: \"device: 2, name: GeForce GTX 1080 Ti, pci bus id: 0000:84:00.0, compute capability: 6.1\",\n",
       " name: \"/device:GPU:3\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 10992173056\n",
       " locality {\n",
       "   bus_id: 2\n",
       "   numa_node: 1\n",
       "   links {\n",
       "     link {\n",
       "       device_id: 1\n",
       "       type: \"StreamExecutor\"\n",
       "       strength: 1\n",
       "     }\n",
       "     link {\n",
       "       device_id: 2\n",
       "       type: \"StreamExecutor\"\n",
       "       strength: 1\n",
       "     }\n",
       "     link {\n",
       "       device_id: 4\n",
       "       type: \"StreamExecutor\"\n",
       "       strength: 1\n",
       "     }\n",
       "   }\n",
       " }\n",
       " incarnation: 15608292480658808985\n",
       " physical_device_desc: \"device: 3, name: GeForce GTX 1080 Ti, pci bus id: 0000:87:00.0, compute capability: 6.1\",\n",
       " name: \"/device:GPU:4\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 10992173056\n",
       " locality {\n",
       "   bus_id: 2\n",
       "   numa_node: 1\n",
       "   links {\n",
       "     link {\n",
       "       device_id: 1\n",
       "       type: \"StreamExecutor\"\n",
       "       strength: 1\n",
       "     }\n",
       "     link {\n",
       "       device_id: 2\n",
       "       type: \"StreamExecutor\"\n",
       "       strength: 1\n",
       "     }\n",
       "     link {\n",
       "       device_id: 3\n",
       "       type: \"StreamExecutor\"\n",
       "       strength: 1\n",
       "     }\n",
       "   }\n",
       " }\n",
       " incarnation: 2417326536720628953\n",
       " physical_device_desc: \"device: 4, name: GeForce GTX 1080 Ti, pci bus id: 0000:88:00.0, compute capability: 6.1\",\n",
       " name: \"/device:XLA_GPU:0\"\n",
       " device_type: \"XLA_GPU\"\n",
       " memory_limit: 17179869184\n",
       " locality {\n",
       " }\n",
       " incarnation: 15994998763337924206\n",
       " physical_device_desc: \"device: XLA_GPU device\",\n",
       " name: \"/device:XLA_GPU:1\"\n",
       " device_type: \"XLA_GPU\"\n",
       " memory_limit: 17179869184\n",
       " locality {\n",
       " }\n",
       " incarnation: 12435008073255509019\n",
       " physical_device_desc: \"device: XLA_GPU device\",\n",
       " name: \"/device:XLA_GPU:2\"\n",
       " device_type: \"XLA_GPU\"\n",
       " memory_limit: 17179869184\n",
       " locality {\n",
       " }\n",
       " incarnation: 11306100100640605829\n",
       " physical_device_desc: \"device: XLA_GPU device\",\n",
       " name: \"/device:XLA_GPU:3\"\n",
       " device_type: \"XLA_GPU\"\n",
       " memory_limit: 17179869184\n",
       " locality {\n",
       " }\n",
       " incarnation: 1576016488064676687\n",
       " physical_device_desc: \"device: XLA_GPU device\",\n",
       " name: \"/device:XLA_GPU:4\"\n",
       " device_type: \"XLA_GPU\"\n",
       " memory_limit: 17179869184\n",
       " locality {\n",
       " }\n",
       " incarnation: 7780742336353649558\n",
       " physical_device_desc: \"device: XLA_GPU device\"]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1630824563357,
     "user": {
      "displayName": "박아정",
      "photoUrl": "",
      "userId": "15223679537180029561"
     },
     "user_tz": -540
    },
    "id": "21In4rWv5QdY"
   },
   "outputs": [],
   "source": [
    "class CharacterTable(object):\n",
    "    \"\"\"Given a set of characters:\n",
    "    + Encode them to a one hot integer representation\n",
    "    + Decode the one hot integer representation to their character output\n",
    "    + Decode a vector of probabilities to their character output\n",
    "    \"\"\"\n",
    "    # 초기화 : 사용되는 문자 집합이 주어지면 caharacter table 을 초기화한다.\n",
    "    def __init__(self, chars):\n",
    "        \"\"\"Initialize character table.\n",
    "        # Arguments\n",
    "            chars: Characters that can appear in the input.\n",
    "        \"\"\"\n",
    "        # 문자 집합이 주어지면 각 문자에 대한 인덱스를 매긴다.\n",
    "        # char_indices : (문자, 인덱스), indices_char : (인덱스, 문자)\n",
    "        self.chars = sorted(set(chars))\n",
    "        self.char_indices = dict((c, i) for i, c in enumerate(self.chars))\n",
    "        self.indices_char = dict((i, c) for i, c in enumerate(self.chars))\n",
    "\n",
    "    def encode(self, C, num_rows):\n",
    "        \"\"\"One hot encode given string C.\n",
    "        # Arguments\n",
    "            num_rows: Number of rows in the returned one hot encoding. This is\n",
    "                used to keep the # of rows for each data the same.\n",
    "        \"\"\"\n",
    "        x = np.zeros((num_rows, len(self.chars)))\n",
    "        # 문장(C)의 문자에 해당하는 행렬 위치를 0->1 로 바꾼다.\n",
    "        for i, c in enumerate(C):\n",
    "            x[i, self.char_indices[c]] = 1    # 순서대로 i번째 행에 char_indices[c] 열에 1 대입\n",
    "        return x\n",
    "\n",
    "    def decode(self, x, calc_argmax=True):\n",
    "        if calc_argmax:\n",
    "            x = x.argmax(axis=-1)\n",
    "        return ''.join(self.indices_char[x] for x in x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1630824563357,
     "user": {
      "displayName": "박아정",
      "photoUrl": "",
      "userId": "15223679537180029561"
     },
     "user_tz": -540
    },
    "id": "3qsppJcZ5TEb"
   },
   "outputs": [],
   "source": [
    "class colors:\n",
    "    ok = '\\033[92m'\n",
    "    fail = '\\033[91m'\n",
    "    close = '\\033[0m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7341,
     "status": "ok",
     "timestamp": 1630824570690,
     "user": {
      "displayName": "박아정",
      "photoUrl": "",
      "userId": "15223679537180029561"
     },
     "user_tz": -540
    },
    "id": "5be_v6anHXE1",
    "outputId": "3442529f-6006-4f3a-d282-dcb3605c1e71"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get data...from txt\n",
      "Total addition questions: 50000\n"
     ]
    }
   ],
   "source": [
    "# Parameters for the model and dataset.\n",
    "TRAINING_SIZE = 50000\n",
    "DIGITS = 3\n",
    "INVERT = True\n",
    "\n",
    "# Maximum length of input is 'int + int' (e.g., '345+678'). Maximum length of\n",
    "# int is DIGITS.\n",
    "MAxLEN = DIGITS + 1 + DIGITS\n",
    "\n",
    "# All the numbers, plus sign and space for padding.\n",
    "# ctable : 문자 집합에 대해 character table 을 만든 인스턴스(?)\n",
    "chars = '0123456789+ '\n",
    "ctable = CharacterTable(chars)\n",
    "\n",
    "questions = []\n",
    "expected = []\n",
    "seen = set()\n",
    "file_path = 'dataset/addition.txt'\n",
    "\n",
    "print('Get data...from txt')\n",
    "for line in open(file_path, 'r'):\n",
    "        idx = line.find('_')\n",
    "        questions.append(line[:idx][::-1])\n",
    "        expected.append(line[idx+1:-1])\n",
    "        \n",
    "#print('Generating data...')\n",
    "# np.random.randint(1, 20) : 1~19까지 랜덤한 숫자 1개\n",
    "#while len(questions) < TRAINING_SIZE:\n",
    "#    # f : 최대 3자리까지 랜덤한 숫자를 만든다.\n",
    "#    f = lambda: int(''.join(np.random.choice(list('0123456789'))\n",
    "#                    for i in range(np.random.randint(1, DIGITS + 1))))\n",
    "#    a, b = f(), f()\n",
    "\n",
    "#    # Skip any addition questions we've already seen\n",
    "#    # Also skip any such that x+Y == Y+x (hence the sorting).\n",
    "#    key = tuple(sorted((a, b)))\n",
    "#    if key in seen:\n",
    "#        continue\n",
    "#    seen.add(key)\n",
    "\n",
    "#    # Pad the data with spaces such that it is always MAxLEN.\n",
    "#    q = '{}+{}'.format(a, b)\n",
    "#    query = q + ' ' * (MAxLEN - len(q)) # 전체 길이 - q 길이 만큼 padding 을 줘서 전체 길이가 맞춰지도록.\n",
    "#    ans = str(a + b)\n",
    "\n",
    "#    # Answers can be of maximum size DIGITS + 1.\n",
    "#    # answer 도 패딩을 맞춰준다. (answer가 될 수 있는 최대 길이에서 - 현재 나온 답의 길이 만큼)\n",
    "#    ans += ' ' * (DIGITS + 1 - len(ans))\n",
    "\n",
    "#    # Input의 Reverse 여부\n",
    "#    if INVERT:\n",
    "#        # Reverse the query, e.g., '12+345  ' becomes '  543+21'. (Note the\n",
    "#        # space used for padding.)\n",
    "#        query = query[::-1] # Reverse\n",
    "#    questions.append(query)\n",
    "#    expected.append(ans)\n",
    "print('Total addition questions:', len(questions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1630824570690,
     "user": {
      "displayName": "박아정",
      "photoUrl": "",
      "userId": "15223679537180029561"
     },
     "user_tz": -540
    },
    "id": "_ShaxkUDJ0K3",
    "outputId": "e7d5a263-e79f-43e6-88ea-4f72f0572391"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorization...\n",
      "(50000, 7, 12)\n",
      "(50000, 4, 12)\n"
     ]
    }
   ],
   "source": [
    "print('Vectorization...')\n",
    "# np.zeros(shape, dtype, order)\n",
    "x = np.zeros((len(questions), MAxLEN, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(questions), DIGITS + 1, len(chars)), dtype=np.bool)\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  57+61\n",
      "91  \n"
     ]
    }
   ],
   "source": [
    "print(questions[0])\n",
    "print(expected[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 585,
     "status": "ok",
     "timestamp": 1630824571266,
     "user": {
      "displayName": "박아정",
      "photoUrl": "",
      "userId": "15223679537180029561"
     },
     "user_tz": -540
    },
    "id": "TR73ZQDHJwv-",
    "outputId": "6c7ede23-04c7-43c6-e81c-a28726e20e02"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorization...\n",
      "Training Data:\n",
      "(45000, 7, 12)\n",
      "(45000, 4, 12)\n",
      "Validation Data:\n",
      "(5000, 7, 12)\n",
      "(5000, 4, 12)\n"
     ]
    }
   ],
   "source": [
    "print('Vectorization...')\n",
    "# np.zeros(shape, dtype, order)\n",
    "# x : (50000, 7, 12), y : (50000, 4, 12)\n",
    "# 입력데이터를 Encode\n",
    "x = np.zeros((len(questions), MAxLEN, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(questions), DIGITS + 1, len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(questions):\n",
    "    x[i] = ctable.encode(sentence, MAxLEN)\n",
    "for i, sentence in enumerate(expected):\n",
    "    y[i] = ctable.encode(sentence, DIGITS + 1)\n",
    "\n",
    "# Shuffle (x, y) in unison as the later parts of x will almost all be larger\n",
    "# digits.\n",
    "# x의 뒷부분이 더 커지기 때문에 (x, y) 를 섞는다. (???) -> 어쨋든 셔플\n",
    "indices = np.arange(len(y))\n",
    "np.random.shuffle(indices)\n",
    "x = x[indices]\n",
    "y = y[indices]\n",
    "\n",
    "# Explicitly set apart 10% for validation data that we never train over.\n",
    "# Test Set : 0~45000, Validation Set : 45000~50000\n",
    "split_at = len(x) - len(x) // 10\n",
    "(x_train, x_val) = x[:split_at], x[split_at:]\n",
    "(y_train, y_val) = y[:split_at], y[split_at:]\n",
    "\n",
    "print('Training Data:')\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print('Validation Data:')\n",
    "print(x_val.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2211,
     "status": "ok",
     "timestamp": 1630824573472,
     "user": {
      "displayName": "박아정",
      "photoUrl": "",
      "userId": "15223679537180029561"
     },
     "user_tz": -540
    },
    "id": "T2ZFo7R_TC2U",
    "outputId": "334d27d2-94e0-4d6e-961f-c6cca19ef462"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 128)               72192     \n",
      "_________________________________________________________________\n",
      "repeat_vector (RepeatVector) (None, 4, 128)            0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 4, 128)            131584    \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, 4, 12)             1548      \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 4, 12)             0         \n",
      "=================================================================\n",
      "Total params: 205,324\n",
      "Trainable params: 205,324\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Try replacing GRU, or SimpleRNN.\n",
    "RNN = layers.LSTM\n",
    "HIDDEN_SIZE = 128\n",
    "BATCH_SIZE = 128\n",
    "LAYERS = 1\n",
    "\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "\n",
    "# \"Encode\" the input sequence using an RNN, producing an output of HIDDEN_SIZE.\n",
    "# Note: In a situation where your input sequences have a variable length,\n",
    "# use input_shape=(None, num_feature).\n",
    "model.add(RNN(HIDDEN_SIZE, input_shape=(MAxLEN, len(chars))))\n",
    "\n",
    "# As the decoder RNN's input, repeatedly provide with the last hidden state of\n",
    "# RNN for each time step. Repeat 'DIGITS + 1' times as that's the maximum\n",
    "# length of output, e.g., when DIGITS=3, max output is 999+999=1998.\n",
    "model.add(layers.RepeatVector(DIGITS + 1))\n",
    "\n",
    "# The decoder RNN could be multiple layers stacked or a single layer.\n",
    "for _ in range(LAYERS):\n",
    "    # By setting return_sequences to True, return not only the last output but\n",
    "    # all the outputs so far in the form of (num_samples, timesteps,\n",
    "    # output_dim). This is necessary as TimeDistributed in the below expects\n",
    "    # the first dimension to be the timesteps.\n",
    "    # return_sequences(시퀀스 출력 여부): True(각 시퀀스에서 출력, many-to-many 일 때)\n",
    "    model.add(RNN(HIDDEN_SIZE, return_sequences=True))\n",
    "\n",
    "# Apply a dense layer to the every temporal slice of an input. For each of step\n",
    "# of the output sequence, decide which character should be chosen.\n",
    "# TimeDistributed :7개의 시간 단계 각각에 독립적으로 Dense 레이어를 적용\n",
    "model.add(layers.TimeDistributed(layers.Dense(len(chars))))\n",
    "model.add(layers.Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 23470,
     "status": "error",
     "timestamp": 1630824596933,
     "user": {
      "displayName": "박아정",
      "photoUrl": "",
      "userId": "15223679537180029561"
     },
     "user_tz": -540
    },
    "id": "27aLlS854fJa",
    "outputId": "918a660d-c8c5-4cdd-c5f3-54ed3a8f4771"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 16s - loss: 1.8776 - accuracy: 0.3242 - val_loss: 1.7830 - val_accuracy: 0.3424\n",
      "검증 정확도 0.160%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 1.7302 - accuracy: 0.3604 - val_loss: 1.6643 - val_accuracy: 0.3810\n",
      "검증 정확도 0.180%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 3\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 1.6041 - accuracy: 0.4013 - val_loss: 1.5414 - val_accuracy: 0.4182\n",
      "검증 정확도 0.500%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 4\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 1.4794 - accuracy: 0.4473 - val_loss: 1.4025 - val_accuracy: 0.4782\n",
      "검증 정확도 1.160%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 5\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 1.3394 - accuracy: 0.5024 - val_loss: 1.2789 - val_accuracy: 0.5204\n",
      "검증 정확도 1.960%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 6\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 1.2091 - accuracy: 0.5533 - val_loss: 1.1474 - val_accuracy: 0.5788\n",
      "검증 정확도 3.660%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 7\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 1.0908 - accuracy: 0.6023 - val_loss: 1.0330 - val_accuracy: 0.6249\n",
      "검증 정확도 5.420%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 8\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 0.9799 - accuracy: 0.6479 - val_loss: 0.9390 - val_accuracy: 0.6536\n",
      "검증 정확도 8.640%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 9\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 0.8355 - accuracy: 0.7043 - val_loss: 0.7464 - val_accuracy: 0.7362\n",
      "검증 정확도 24.060%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 10\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 0.6492 - accuracy: 0.7837 - val_loss: 0.5647 - val_accuracy: 0.8262\n",
      "검증 정확도 44.960%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 11\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 0.5005 - accuracy: 0.8541 - val_loss: 0.4526 - val_accuracy: 0.8677\n",
      "검증 정확도 55.300%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 12\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 0.4009 - accuracy: 0.8950 - val_loss: 0.3538 - val_accuracy: 0.9187\n",
      "검증 정확도 71.700%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 13\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 0.3215 - accuracy: 0.9248 - val_loss: 0.2847 - val_accuracy: 0.9387\n",
      "검증 정확도 77.960%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 14\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 0.2623 - accuracy: 0.9430 - val_loss: 0.2345 - val_accuracy: 0.9533\n",
      "검증 정확도 83.220%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 15\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 0.2100 - accuracy: 0.9595 - val_loss: 0.2078 - val_accuracy: 0.9545\n",
      "검증 정확도 83.060%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 16\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 0.1773 - accuracy: 0.9653 - val_loss: 0.1854 - val_accuracy: 0.9556\n",
      "검증 정확도 83.960%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 17\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 0.1481 - accuracy: 0.9722 - val_loss: 0.1292 - val_accuracy: 0.9790\n",
      "검증 정확도 92.020%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 18\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 0.1267 - accuracy: 0.9765 - val_loss: 0.1192 - val_accuracy: 0.9780\n",
      "검증 정확도 91.740%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 19\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 0.1055 - accuracy: 0.9818 - val_loss: 0.0951 - val_accuracy: 0.9848\n",
      "검증 정확도 94.120%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 20\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 0.0906 - accuracy: 0.9848 - val_loss: 0.0853 - val_accuracy: 0.9847\n",
      "검증 정확도 94.080%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 21\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 0.0822 - accuracy: 0.9850 - val_loss: 0.1026 - val_accuracy: 0.9750\n",
      "검증 정확도 90.640%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 22\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 0.0734 - accuracy: 0.9866 - val_loss: 0.0676 - val_accuracy: 0.9877\n",
      "검증 정확도 95.220%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 23\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 0.0539 - accuracy: 0.9925 - val_loss: 0.0818 - val_accuracy: 0.9779\n",
      "검증 정확도 91.400%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 24\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 0.0737 - accuracy: 0.9840 - val_loss: 0.0497 - val_accuracy: 0.9919\n",
      "검증 정확도 96.840%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 25\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 0.0391 - accuracy: 0.9956 - val_loss: 0.0456 - val_accuracy: 0.9929\n",
      "검증 정확도 97.200%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 26\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 0.0683 - accuracy: 0.9840 - val_loss: 0.1016 - val_accuracy: 0.9694\n",
      "검증 정확도 88.540%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 27\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 0.0359 - accuracy: 0.9953 - val_loss: 0.0326 - val_accuracy: 0.9960\n",
      "검증 정확도 98.440%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 28\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 0.0270 - accuracy: 0.9974 - val_loss: 0.0318 - val_accuracy: 0.9955\n",
      "검증 정확도 98.340%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 29\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 0.0262 - accuracy: 0.9969 - val_loss: 0.0286 - val_accuracy: 0.9957\n",
      "검증 정확도 98.320%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 30\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 0.0651 - accuracy: 0.9818 - val_loss: 0.0351 - val_accuracy: 0.9937\n",
      "검증 정확도 97.520%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 31\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 0.0210 - accuracy: 0.9979 - val_loss: 0.0220 - val_accuracy: 0.9970\n",
      "검증 정확도 98.840%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 32\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 0.0170 - accuracy: 0.9985 - val_loss: 0.0200 - val_accuracy: 0.9971\n",
      "검증 정확도 98.840%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 33\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 0.0373 - accuracy: 0.9909 - val_loss: 0.0602 - val_accuracy: 0.9814\n",
      "검증 정확도 93.180%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 34\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 0.0364 - accuracy: 0.9909 - val_loss: 0.0166 - val_accuracy: 0.9984\n",
      "검증 정확도 99.380%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 35\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 0.0129 - accuracy: 0.9991 - val_loss: 0.0150 - val_accuracy: 0.9980\n",
      "검증 정확도 99.200%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 36\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 0.0124 - accuracy: 0.9988 - val_loss: 0.0160 - val_accuracy: 0.9973\n",
      "검증 정확도 98.940%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 37\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 0.0180 - accuracy: 0.9967 - val_loss: 0.2551 - val_accuracy: 0.9180\n",
      "검증 정확도 69.860%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 38\n",
      "Train on 45000 samples, validate on 5000 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45000/45000 - 3s - loss: 0.0382 - accuracy: 0.9896 - val_loss: 0.0143 - val_accuracy: 0.9980\n",
      "검증 정확도 99.220%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 39\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 0.0095 - accuracy: 0.9993 - val_loss: 0.0125 - val_accuracy: 0.9981\n",
      "검증 정확도 99.280%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 40\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 0.0090 - accuracy: 0.9992 - val_loss: 0.0127 - val_accuracy: 0.9973\n",
      "검증 정확도 98.940%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 41\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 0.0496 - accuracy: 0.9857 - val_loss: 0.0702 - val_accuracy: 0.9781\n",
      "검증 정확도 91.860%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 42\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 0.0160 - accuracy: 0.9972 - val_loss: 0.0108 - val_accuracy: 0.9987\n",
      "검증 정확도 99.500%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 43\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 0.0074 - accuracy: 0.9995 - val_loss: 0.0096 - val_accuracy: 0.9988\n",
      "검증 정확도 99.540%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 44\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 0.0073 - accuracy: 0.9993 - val_loss: 0.0110 - val_accuracy: 0.9979\n",
      "검증 정확도 99.180%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 45\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 0.0072 - accuracy: 0.9992 - val_loss: 0.0137 - val_accuracy: 0.9969\n",
      "검증 정확도 98.780%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 46\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 0.0506 - accuracy: 0.9847 - val_loss: 0.0744 - val_accuracy: 0.9769\n",
      "검증 정확도 91.800%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 47\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 0.0100 - accuracy: 0.9985 - val_loss: 0.0079 - val_accuracy: 0.9990\n",
      "검증 정확도 99.620%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 48\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 0.0053 - accuracy: 0.9996 - val_loss: 0.0078 - val_accuracy: 0.9988\n",
      "검증 정확도 99.540%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 49\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 0.0059 - accuracy: 0.9994 - val_loss: 0.0254 - val_accuracy: 0.9926\n",
      "검증 정확도 97.260%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 50\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 0.0514 - accuracy: 0.9844 - val_loss: 0.0104 - val_accuracy: 0.9983\n",
      "검증 정확도 99.340%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 51\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 0.0054 - accuracy: 0.9997 - val_loss: 0.0064 - val_accuracy: 0.9993\n",
      "검증 정확도 99.720%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 52\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 0.0043 - accuracy: 0.9998 - val_loss: 0.0058 - val_accuracy: 0.9994\n",
      "검증 정확도 99.760%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 53\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 0.0042 - accuracy: 0.9996 - val_loss: 0.0064 - val_accuracy: 0.9987\n",
      "검증 정확도 99.520%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 54\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 0.0040 - accuracy: 0.9996 - val_loss: 0.0056 - val_accuracy: 0.9993\n",
      "검증 정확도 99.740%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 55\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 0.0380 - accuracy: 0.9881 - val_loss: 0.0688 - val_accuracy: 0.9759\n",
      "검증 정확도 91.060%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 56\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 0.0188 - accuracy: 0.9950 - val_loss: 0.0071 - val_accuracy: 0.9988\n",
      "검증 정확도 99.540%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 57\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 0.0038 - accuracy: 0.9998 - val_loss: 0.0054 - val_accuracy: 0.9991\n",
      "검증 정확도 99.620%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 58\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 0.0035 - accuracy: 0.9997 - val_loss: 0.0053 - val_accuracy: 0.9991\n",
      "검증 정확도 99.640%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 59\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 0.0188 - accuracy: 0.9944 - val_loss: 0.0852 - val_accuracy: 0.9693\n",
      "검증 정확도 88.360%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 60\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 0.0171 - accuracy: 0.9955 - val_loss: 0.0057 - val_accuracy: 0.9991\n",
      "검증 정확도 99.680%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 61\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 0.0032 - accuracy: 0.9998 - val_loss: 0.0047 - val_accuracy: 0.9994\n",
      "검증 정확도 99.760%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 62\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 0.0029 - accuracy: 0.9998 - val_loss: 0.0043 - val_accuracy: 0.9995\n",
      "검증 정확도 99.820%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 63\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 0.0027 - accuracy: 0.9998 - val_loss: 0.0041 - val_accuracy: 0.9995\n",
      "검증 정확도 99.800%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 64\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 0.0369 - accuracy: 0.9889 - val_loss: 0.0757 - val_accuracy: 0.9750\n",
      "검증 정확도 90.580%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 65\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 0.0105 - accuracy: 0.9977 - val_loss: 0.0050 - val_accuracy: 0.9991\n",
      "검증 정확도 99.700%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 66\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 0.0028 - accuracy: 0.9998 - val_loss: 0.0051 - val_accuracy: 0.9990\n",
      "검증 정확도 99.640%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 67\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 0.0024 - accuracy: 0.9999 - val_loss: 0.0042 - val_accuracy: 0.9993\n",
      "검증 정확도 99.740%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 68\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 0.0024 - accuracy: 0.9998 - val_loss: 0.0043 - val_accuracy: 0.9992\n",
      "검증 정확도 99.700%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 69\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 0.0219 - accuracy: 0.9936 - val_loss: 0.1698 - val_accuracy: 0.9445\n",
      "검증 정확도 80.400%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 70\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 0.0245 - accuracy: 0.9929 - val_loss: 0.0052 - val_accuracy: 0.9992\n",
      "검증 정확도 99.680%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 71\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 0.0027 - accuracy: 0.9999 - val_loss: 0.0038 - val_accuracy: 0.9997\n",
      "검증 정확도 99.880%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 72\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 0.0022 - accuracy: 0.9999 - val_loss: 0.0034 - val_accuracy: 0.9995\n",
      "검증 정확도 99.820%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 73\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 0.0020 - accuracy: 0.9998 - val_loss: 0.0031 - val_accuracy: 0.9997\n",
      "검증 정확도 99.900%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 74\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 0.0019 - accuracy: 0.9998 - val_loss: 0.0036 - val_accuracy: 0.9995\n",
      "검증 정확도 99.800%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 75\n",
      "Train on 45000 samples, validate on 5000 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45000/45000 - 3s - loss: 0.0078 - accuracy: 0.9981 - val_loss: 0.1553 - val_accuracy: 0.9497\n",
      "검증 정확도 81.060%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 76\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 0.0299 - accuracy: 0.9909 - val_loss: 0.0043 - val_accuracy: 0.9992\n",
      "검증 정확도 99.720%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 77\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 0.0021 - accuracy: 0.9999 - val_loss: 0.0033 - val_accuracy: 0.9997\n",
      "검증 정확도 99.920%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 78\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 0.0017 - accuracy: 0.9999 - val_loss: 0.0030 - val_accuracy: 0.9995\n",
      "검증 정확도 99.860%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 79\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 0.0019 - accuracy: 0.9998 - val_loss: 0.0059 - val_accuracy: 0.9988\n",
      "검증 정확도 99.620%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 80\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 0.0017 - accuracy: 0.9998 - val_loss: 0.0038 - val_accuracy: 0.9995\n",
      "검증 정확도 99.820%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 81\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 0.0536 - accuracy: 0.9846 - val_loss: 0.0186 - val_accuracy: 0.9944\n",
      "검증 정확도 97.820%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 82\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 0.0044 - accuracy: 0.9993 - val_loss: 0.0033 - val_accuracy: 0.9995\n",
      "검증 정확도 99.840%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 83\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 0.0018 - accuracy: 0.9999 - val_loss: 0.0029 - val_accuracy: 0.9995\n",
      "검증 정확도 99.820%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 84\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 0.9995\n",
      "검증 정확도 99.840%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 85\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 0.0014 - accuracy: 0.9999 - val_loss: 0.0027 - val_accuracy: 0.9996\n",
      "검증 정확도 99.860%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 86\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 0.0027 - accuracy: 0.9995 - val_loss: 0.0201 - val_accuracy: 0.9938\n",
      "검증 정확도 97.660%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 87\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 0.0380 - accuracy: 0.9883 - val_loss: 0.0045 - val_accuracy: 0.9992\n",
      "검증 정확도 99.720%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 88\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 0.0020 - accuracy: 0.9999 - val_loss: 0.0038 - val_accuracy: 0.9991\n",
      "검증 정확도 99.660%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 89\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 0.0016 - accuracy: 0.9999 - val_loss: 0.0031 - val_accuracy: 0.9995\n",
      "검증 정확도 99.820%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 90\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 0.0014 - accuracy: 0.9999 - val_loss: 0.0028 - val_accuracy: 0.9995\n",
      "검증 정확도 99.840%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 91\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 0.0013 - accuracy: 0.9999 - val_loss: 0.0024 - val_accuracy: 0.9998\n",
      "검증 정확도 99.920%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 92\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 0.0012 - accuracy: 0.9999 - val_loss: 0.0024 - val_accuracy: 0.9995\n",
      "검증 정확도 99.820%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 93\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 0.0453 - accuracy: 0.9875 - val_loss: 0.0341 - val_accuracy: 0.9884\n",
      "검증 정확도 95.580%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 94\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 0.0049 - accuracy: 0.9992 - val_loss: 0.0038 - val_accuracy: 0.9994\n",
      "검증 정확도 99.780%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 95\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 0.9995\n",
      "검증 정확도 99.820%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 96\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 0.9995\n",
      "검증 정확도 99.800%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 97\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 0.0012 - accuracy: 0.9999 - val_loss: 0.0023 - val_accuracy: 0.9997\n",
      "검증 정확도 99.880%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 98\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 0.0011 - accuracy: 0.9999 - val_loss: 0.0030 - val_accuracy: 0.9994\n",
      "검증 정확도 99.780%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 99\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 0.0254 - accuracy: 0.9926 - val_loss: 0.0694 - val_accuracy: 0.9766\n",
      "검증 정확도 91.460%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 100\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 0.0082 - accuracy: 0.9979 - val_loss: 0.0040 - val_accuracy: 0.9992\n",
      "검증 정확도 99.700%\n",
      "100번째 정확도 :  0.997\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 101\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 0.9995\n",
      "검증 정확도 99.820%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 102\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 0.9997\n",
      "검증 정확도 99.880%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 103\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 9.6106e-04 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 0.9995\n",
      "검증 정확도 99.800%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 104\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 9.4191e-04 - accuracy: 0.9999 - val_loss: 0.0022 - val_accuracy: 0.9997\n",
      "검증 정확도 99.880%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 105\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 0.0071 - accuracy: 0.9980 - val_loss: 0.2167 - val_accuracy: 0.9372\n",
      "검증 정확도 78.020%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 106\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 0.0362 - accuracy: 0.9888 - val_loss: 0.0035 - val_accuracy: 0.9997\n",
      "검증 정확도 99.880%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 107\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 0.9998\n",
      "검증 정확도 99.960%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 108\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 0.9998\n",
      "검증 정확도 99.940%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 109\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 8.9302e-04 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 0.9997\n",
      "검증 정확도 99.900%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 110\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 9.2694e-04 - accuracy: 0.9999 - val_loss: 0.0018 - val_accuracy: 0.9998\n",
      "검증 정확도 99.940%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 111\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 0.0010 - accuracy: 0.9999 - val_loss: 0.0021 - val_accuracy: 0.9996\n",
      "검증 정확도 99.860%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 112\n",
      "Train on 45000 samples, validate on 5000 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45000/45000 - 3s - loss: 9.5339e-04 - accuracy: 0.9999 - val_loss: 0.0027 - val_accuracy: 0.9993\n",
      "검증 정확도 99.740%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 113\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 0.0460 - accuracy: 0.9865 - val_loss: 0.0080 - val_accuracy: 0.9984\n",
      "검증 정확도 99.440%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 114\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 0.0018 - accuracy: 0.9999 - val_loss: 0.0025 - val_accuracy: 0.9995\n",
      "검증 정확도 99.780%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 115\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 9.7326e-04 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 0.9998\n",
      "검증 정확도 99.920%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 116\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 8.4033e-04 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 0.9998\n",
      "검증 정확도 99.920%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 117\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 7.6914e-04 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 0.9998\n",
      "검증 정확도 99.920%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 118\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 8.5029e-04 - accuracy: 0.9999 - val_loss: 0.0019 - val_accuracy: 0.9997\n",
      "검증 정확도 99.880%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 119\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 7.2740e-04 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 0.9995\n",
      "검증 정확도 99.820%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 120\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 0.0364 - accuracy: 0.9894 - val_loss: 0.0060 - val_accuracy: 0.9985\n",
      "검증 정확도 99.440%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 121\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 0.0020 - accuracy: 0.9998 - val_loss: 0.0026 - val_accuracy: 0.9997\n",
      "검증 정확도 99.860%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 122\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 9.7428e-04 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 0.9997\n",
      "검증 정확도 99.860%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 123\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 7.5886e-04 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 0.9998\n",
      "검증 정확도 99.920%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 124\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 6.8912e-04 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 0.9998\n",
      "검증 정확도 99.900%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 125\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 8.2006e-04 - accuracy: 0.9999 - val_loss: 0.0081 - val_accuracy: 0.9978\n",
      "검증 정확도 99.120%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 126\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 0.0370 - accuracy: 0.9900 - val_loss: 0.0028 - val_accuracy: 0.9997\n",
      "검증 정확도 99.880%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 127\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 0.9997\n",
      "검증 정확도 99.900%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 128\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 8.1060e-04 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 0.9997\n",
      "검증 정확도 99.900%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 129\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 7.4342e-04 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 0.9997\n",
      "검증 정확도 99.900%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 130\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 6.2662e-04 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 0.9998\n",
      "검증 정확도 99.920%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 131\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 6.6228e-04 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 0.9998\n",
      "검증 정확도 99.920%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 132\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 0.0281 - accuracy: 0.9916 - val_loss: 0.0481 - val_accuracy: 0.9843\n",
      "검증 정확도 94.100%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 133\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 0.0047 - accuracy: 0.9990 - val_loss: 0.0023 - val_accuracy: 0.9997\n",
      "검증 정확도 99.880%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 134\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 0.0010 - accuracy: 0.9999 - val_loss: 0.0020 - val_accuracy: 0.9997\n",
      "검증 정확도 99.860%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 135\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 7.4934e-04 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 0.9996\n",
      "검증 정확도 99.840%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 136\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 6.8686e-04 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 0.9998\n",
      "검증 정확도 99.920%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 137\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 6.4619e-04 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 0.9996\n",
      "검증 정확도 99.860%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 138\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 5.4070e-04 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 0.9997\n",
      "검증 정확도 99.880%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 139\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 0.0302 - accuracy: 0.9913 - val_loss: 0.0111 - val_accuracy: 0.9970\n",
      "검증 정확도 98.860%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 140\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 0.0022 - accuracy: 0.9997 - val_loss: 0.0025 - val_accuracy: 0.9995\n",
      "검증 정확도 99.800%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 141\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 8.0371e-04 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 0.9998\n",
      "검증 정확도 99.900%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 142\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 6.2213e-04 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 0.9998\n",
      "검증 정확도 99.920%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 143\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 5.9408e-04 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 0.9998\n",
      "검증 정확도 99.900%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 144\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 6.4981e-04 - accuracy: 0.9999 - val_loss: 0.0018 - val_accuracy: 0.9996\n",
      "검증 정확도 99.840%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 145\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 0.0294 - accuracy: 0.9912 - val_loss: 0.0203 - val_accuracy: 0.9932\n",
      "검증 정확도 97.320%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 146\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 0.0029 - accuracy: 0.9995 - val_loss: 0.0022 - val_accuracy: 0.9998\n",
      "검증 정확도 99.900%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 147\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 8.3715e-04 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 0.9998\n",
      "검증 정확도 99.940%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 148\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 5.8964e-04 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 0.9998\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검증 정확도 99.920%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 149\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 5.3686e-04 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 0.9998\n",
      "검증 정확도 99.940%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 150\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 6.5746e-04 - accuracy: 0.9999 - val_loss: 0.0022 - val_accuracy: 0.9997\n",
      "검증 정확도 99.900%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 151\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 0.0319 - accuracy: 0.9912 - val_loss: 0.0210 - val_accuracy: 0.9938\n",
      "검증 정확도 97.740%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 152\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 0.0039 - accuracy: 0.9993 - val_loss: 0.0023 - val_accuracy: 0.9997\n",
      "검증 정확도 99.860%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 153\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 7.5228e-04 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 0.9998\n",
      "검증 정확도 99.920%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 154\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 5.9226e-04 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 0.9998\n",
      "검증 정확도 99.920%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 155\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 5.2301e-04 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 0.9998\n",
      "검증 정확도 99.940%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 156\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 4.5885e-04 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 0.9999\n",
      "검증 정확도 99.960%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 157\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 4.3775e-04 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 0.9999\n",
      "검증 정확도 99.960%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 158\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 7.6013e-04 - accuracy: 0.9999 - val_loss: 0.0029 - val_accuracy: 0.9995\n",
      "검증 정확도 99.780%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 159\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 0.0328 - accuracy: 0.9910 - val_loss: 0.0029 - val_accuracy: 0.9996\n",
      "검증 정확도 99.860%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 160\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 8.0243e-04 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 0.9997\n",
      "검증 정확도 99.880%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 161\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 5.7088e-04 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 0.9997\n",
      "검증 정확도 99.880%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 162\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 4.9512e-04 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 0.9998\n",
      "검증 정확도 99.940%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 163\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 4.9482e-04 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 0.9997\n",
      "검증 정확도 99.860%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 164\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 5.8480e-04 - accuracy: 0.9999 - val_loss: 0.0017 - val_accuracy: 0.9997\n",
      "검증 정확도 99.860%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 165\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 4.2205e-04 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 0.9998\n",
      "검증 정확도 99.920%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 166\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 4.4465e-04 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 0.9998\n",
      "검증 정확도 99.920%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 167\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 0.0308 - accuracy: 0.9914 - val_loss: 0.0055 - val_accuracy: 0.9988\n",
      "검증 정확도 99.560%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 168\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 0.0049 - accuracy: 0.9989 - val_loss: 0.0019 - val_accuracy: 0.9997\n",
      "검증 정확도 99.880%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 169\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 6.8010e-04 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 0.9998\n",
      "검증 정확도 99.920%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 170\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 4.9187e-04 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 0.9998\n",
      "검증 정확도 99.940%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 171\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 4.2737e-04 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 0.9998\n",
      "검증 정확도 99.940%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 172\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 3.8620e-04 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 0.9999\n",
      "검증 정확도 99.960%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 173\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 3.5064e-04 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 0.9999\n",
      "검증 정확도 99.960%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 174\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 3.5319e-04 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 0.9999\n",
      "검증 정확도 99.960%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 175\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 4.0683e-04 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 0.9993\n",
      "검증 정확도 99.720%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 176\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 0.0336 - accuracy: 0.9906 - val_loss: 0.0051 - val_accuracy: 0.9987\n",
      "검증 정확도 99.480%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 177\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 0.0014 - accuracy: 0.9998 - val_loss: 0.0029 - val_accuracy: 0.9993\n",
      "검증 정확도 99.720%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 178\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 6.4666e-04 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 0.9999\n",
      "검증 정확도 99.980%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 179\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 4.4296e-04 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 0.9999\n",
      "검증 정확도 99.980%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 180\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 3.9509e-04 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 0.9999\n",
      "검증 정확도 99.980%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 181\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 3.8362e-04 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 0.9999\n",
      "검증 정확도 99.980%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 182\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 3.1870e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 0.9999\n",
      "검증 정확도 99.980%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 183\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 2.9682e-04 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 0.9999\n",
      "검증 정확도 99.960%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 184\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 0.0367 - accuracy: 0.9900 - val_loss: 0.0122 - val_accuracy: 0.9959\n",
      "검증 정확도 98.400%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 185\n",
      "Train on 45000 samples, validate on 5000 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45000/45000 - 3s - loss: 0.0024 - accuracy: 0.9996 - val_loss: 0.0028 - val_accuracy: 0.9996\n",
      "검증 정확도 99.860%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 186\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 8.5389e-04 - accuracy: 0.9999 - val_loss: 0.0019 - val_accuracy: 0.9997\n",
      "검증 정확도 99.900%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 187\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 4.9584e-04 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 0.9998\n",
      "검증 정확도 99.960%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 188\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 4.0844e-04 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 0.9999\n",
      "검증 정확도 99.980%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 189\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 3.5976e-04 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 0.9999\n",
      "검증 정확도 99.980%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 190\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 3.2544e-04 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 0.9999\n",
      "검증 정확도 99.980%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 191\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 2.9441e-04 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 0.9999\n",
      "검증 정확도 99.960%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 192\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 2.7065e-04 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 0.9999\n",
      "검증 정확도 99.980%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 193\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 0.0320 - accuracy: 0.9911 - val_loss: 0.0323 - val_accuracy: 0.9895\n",
      "검증 정확도 96.200%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 194\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 0.0095 - accuracy: 0.9974 - val_loss: 0.0091 - val_accuracy: 0.9973\n",
      "검증 정확도 98.920%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 195\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.0019 - val_accuracy: 0.9998\n",
      "검증 정확도 99.920%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 196\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 4.7393e-04 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 0.9998\n",
      "검증 정확도 99.940%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 197\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 3.6977e-04 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 0.9998\n",
      "검증 정확도 99.940%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 198\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 3.2908e-04 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 0.9998\n",
      "검증 정확도 99.940%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 199\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "45000/45000 - 3s - loss: 3.0121e-04 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 0.9998\n",
      "검증 정확도 99.940%\n"
     ]
    }
   ],
   "source": [
    "# Train the model each generation and show predictions against the validation\n",
    "# dataset.\n",
    "acc_list = []\n",
    "history_list = []\n",
    "\n",
    "for iteration in range(1, 200):\n",
    "    print()\n",
    "    print('-' * 50)\n",
    "    print('Iteration', iteration)\n",
    "    history = model.fit(x_train, y_train, batch_size=BATCH_SIZE, verbose = 2, epochs=1,\n",
    "              validation_data=(x_val, y_val))\n",
    "    # Select 10 samples from the validation set at random so we can visualize\n",
    "    # errors.\n",
    "    history_list.append(history.history.get('val_accuracy')[0])\n",
    "    \n",
    "    correct_num = 0\n",
    "    for i in range(len(x_val)):\n",
    "        rowx, rowy = x_val[np.array([i])], y_val[np.array([i])]\n",
    "        # predict_classes : 0 or 1로 출력 (predict 와 약간 다름) --> 2.6버전에서 삭제됨\n",
    "        preds = model.predict_classes(rowx, verbose=0)\n",
    "        q = ctable.decode(rowx[0])\n",
    "        correct = ctable.decode(rowy[0])\n",
    "        guess = ctable.decode(preds[0], calc_argmax=False)\n",
    "        \n",
    "        if guess == correct:\n",
    "          correct_num += 1\n",
    "        else:\n",
    "          correct_num += 0\n",
    "        \n",
    "#        if correct == guess:\n",
    "#            print(colors.ok + '☑' + colors.close, end=\" \")\n",
    "#        else:\n",
    "#            print(colors.fail + '☒' + colors.close, end=\" \")\n",
    "#        print(guess)\n",
    "#        print('---')\n",
    "    acc = float(correct_num) / len(x_val)\n",
    "    acc_list.append(acc)\n",
    "    print('검증 정확도 %.3f%%' % (acc * 100))\n",
    "    if iteration == 100:\n",
    "      print('100번째 정확도 : ', acc)\n",
    "    \n",
    "model.save('addition.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gpuadmin/anaconda3/envs/ahjeong/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:238: RuntimeWarning: Glyph 50640 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/home/gpuadmin/anaconda3/envs/ahjeong/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:238: RuntimeWarning: Glyph 54253 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/home/gpuadmin/anaconda3/envs/ahjeong/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:238: RuntimeWarning: Glyph 51221 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/home/gpuadmin/anaconda3/envs/ahjeong/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:238: RuntimeWarning: Glyph 54869 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/home/gpuadmin/anaconda3/envs/ahjeong/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:238: RuntimeWarning: Glyph 46020 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/home/gpuadmin/anaconda3/envs/ahjeong/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:201: RuntimeWarning: Glyph 50640 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/home/gpuadmin/anaconda3/envs/ahjeong/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:201: RuntimeWarning: Glyph 54253 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/home/gpuadmin/anaconda3/envs/ahjeong/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:201: RuntimeWarning: Glyph 51221 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/home/gpuadmin/anaconda3/envs/ahjeong/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:201: RuntimeWarning: Glyph 54869 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/home/gpuadmin/anaconda3/envs/ahjeong/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:201: RuntimeWarning: Glyph 46020 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 그래프 그리기\n",
    "x = np.arange(len(acc_list))\n",
    "plt.plot(x, acc_list, marker='o')\n",
    "plt.xlabel('에폭')\n",
    "plt.ylabel('정확도')\n",
    "plt.ylim(0, 1.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gpuadmin/anaconda3/envs/ahjeong/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:238: RuntimeWarning: Glyph 50640 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/home/gpuadmin/anaconda3/envs/ahjeong/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:238: RuntimeWarning: Glyph 54253 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/home/gpuadmin/anaconda3/envs/ahjeong/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:238: RuntimeWarning: Glyph 51221 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/home/gpuadmin/anaconda3/envs/ahjeong/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:238: RuntimeWarning: Glyph 54869 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/home/gpuadmin/anaconda3/envs/ahjeong/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:238: RuntimeWarning: Glyph 46020 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/home/gpuadmin/anaconda3/envs/ahjeong/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:201: RuntimeWarning: Glyph 50640 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/home/gpuadmin/anaconda3/envs/ahjeong/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:201: RuntimeWarning: Glyph 54253 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/home/gpuadmin/anaconda3/envs/ahjeong/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:201: RuntimeWarning: Glyph 51221 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/home/gpuadmin/anaconda3/envs/ahjeong/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:201: RuntimeWarning: Glyph 54869 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/home/gpuadmin/anaconda3/envs/ahjeong/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:201: RuntimeWarning: Glyph 46020 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 그래프 그리기\n",
    "v = np.arange(len(history_list))\n",
    "plt.plot(v, history_list, marker='o')\n",
    "plt.xlabel('에폭')\n",
    "plt.ylabel('정확도')\n",
    "plt.ylim(0, 1.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## summarize history for accuracy\n",
    "#plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history.get('val_accuracy'))\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "## summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9998]\n"
     ]
    }
   ],
   "source": [
    "print(history.history.get('val_accuracy'))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPu6zVPEeBQCRO6+m0CicPX",
   "collapsed_sections": [],
   "name": "addition_rnn.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
