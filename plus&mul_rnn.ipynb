{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gZI5NIQA4jPH"
   },
   "source": [
    "# **Keras 예제 - Seq2Seq 로 덧셈/곱셈 구현**\n",
    "\n",
    "출처\n",
    "- RNN 덧셈 예제 : https://github.com/keras-team/keras/blob/2.0.0/examples/addition_rnn.py\n",
    "- 사칙연산 예제 : https://towardsdatascience.com/making-rnn-model-learn-arithmetic-operations-b016ec4d8388\n",
    "- 텐서플로우 버전 : 2.6\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 252,
     "status": "ok",
     "timestamp": 1631883145432,
     "user": {
      "displayName": "박아정",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "15223679537180029561"
     },
     "user_tz": -540
    },
    "id": "90EcLzESwUyH"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 203
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1631883145433,
     "user": {
      "displayName": "박아정",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "15223679537180029561"
     },
     "user_tz": -540
    },
    "id": "P5N5RDNI5Gpr",
    "outputId": "49c5dc10-ac7a-4cd2-8073-0dd3fe58cf2f"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'An implementation of sequence to sequence learning for performing addition\\nInput: \"535+61\"\\nOutput: \"596\"\\nPadding is handled by using a repeated sentinel character (space)\\nInput may optionally be inverted, shown to increase performance in many tasks in:\\n\"Learning to Execute\"\\nhttp://arxiv.org/abs/1410.4615\\nand\\n\"Sequence to Sequence Learning with Neural Networks\"\\nhttp://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf\\nTheoretically it introduces shorter term dependencies between source and target.\\nTwo digits inverted:\\n+ One layer LSTM (128 HN), 5k training examples = 99% train/test accuracy in 55 epochs\\nThree digits inverted:\\n+ One layer LSTM (128 HN), 50k training examples = 99% train/test accuracy in 100 epochs\\nFour digits inverted:\\n+ One layer LSTM (128 HN), 400k training examples = 99% train/test accuracy in 20 epochs\\nFive digits inverted:\\n+ One layer LSTM (128 HN), 550k training examples = 99% train/test accuracy in 30 epochs\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "'''An implementation of sequence to sequence learning for performing addition\n",
    "Input: \"535+61\"\n",
    "Output: \"596\"\n",
    "Padding is handled by using a repeated sentinel character (space)\n",
    "Input may optionally be inverted, shown to increase performance in many tasks in:\n",
    "\"Learning to Execute\"\n",
    "http://arxiv.org/abs/1410.4615\n",
    "and\n",
    "\"Sequence to Sequence Learning with Neural Networks\"\n",
    "http://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf\n",
    "Theoretically it introduces shorter term dependencies between source and target.\n",
    "Two digits inverted:\n",
    "+ One layer LSTM (128 HN), 5k training examples = 99% train/test accuracy in 55 epochs\n",
    "Three digits inverted:\n",
    "+ One layer LSTM (128 HN), 50k training examples = 99% train/test accuracy in 100 epochs\n",
    "Four digits inverted:\n",
    "+ One layer LSTM (128 HN), 400k training examples = 99% train/test accuracy in 20 epochs\n",
    "Five digits inverted:\n",
    "+ One layer LSTM (128 HN), 550k training examples = 99% train/test accuracy in 30 epochs\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 2171,
     "status": "ok",
     "timestamp": 1631883147596,
     "user": {
      "displayName": "박아정",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "15223679537180029561"
     },
     "user_tz": -540
    },
    "id": "UalzhCNK5M8Q"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "from six.moves import range\n",
    "import matplotlib.pyplot as plt\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1631883147597,
     "user": {
      "displayName": "박아정",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "15223679537180029561"
     },
     "user_tz": -540
    },
    "id": "9wj-3hnDQdyW"
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1631883147597,
     "user": {
      "displayName": "박아정",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "15223679537180029561"
     },
     "user_tz": -540
    },
    "id": "21In4rWv5QdY"
   },
   "outputs": [],
   "source": [
    "class CharacterTable(object):\n",
    "    \"\"\"Given a set of characters:\n",
    "    + Encode them to a one hot integer representation\n",
    "    + Decode the one hot integer representation to their character output\n",
    "    + Decode a vector of probabilities to their character output\n",
    "    \"\"\"\n",
    "    # 초기화 : 사용되는 문자 집합이 주어지면 caharacter table 을 초기화한다.\n",
    "    def __init__(self, chars):\n",
    "        \"\"\"Initialize character table.\n",
    "        # Arguments\n",
    "            chars: Characters that can appear in the input.\n",
    "        \"\"\"\n",
    "        # 문자 집합이 주어지면 각 문자에 대한 인덱스를 매긴다.\n",
    "        # char_indices : (문자, 인덱스), indices_char : (인덱스, 문자)\n",
    "        self.chars = sorted(set(chars))\n",
    "        self.char_indices = dict((c, i) for i, c in enumerate(self.chars))\n",
    "        self.indices_char = dict((i, c) for i, c in enumerate(self.chars))\n",
    "        print('char_indices:',  self.char_indices)\n",
    "        print('indeces_char: ', self.indices_char)\n",
    "\n",
    "    def encode(self, C, num_rows):\n",
    "        \"\"\"One hot encode given string C.\n",
    "        # Arguments\n",
    "            num_rows: Number of rows in the returned one hot encoding. This is\n",
    "                used to keep the # of rows for each data the same.\n",
    "        \"\"\"\n",
    "        x = np.zeros((num_rows, len(self.chars)))\n",
    "        # 문장(C)의 문자에 해당하는 행렬 위치를 0->1 로 바꾼다.\n",
    "        for i, c in enumerate(C):\n",
    "            x[i, self.char_indices[c]] = 1    # 순서대로 i번째 행에 char_indices[c] 열에 1 대입\n",
    "        return x\n",
    "\n",
    "    def decode(self, x, calc_argmax=True):\n",
    "        # print('decode 할 x: ', x)\n",
    "        if calc_argmax:\n",
    "            x = x.argmax(axis=-1) # decode 할 x가 들어오면, \n",
    "            # print('x.argmax: ', x)\n",
    "        return ''.join(self.indices_char[x] for x in x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1631883147599,
     "user": {
      "displayName": "박아정",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "15223679537180029561"
     },
     "user_tz": -540
    },
    "id": "3qsppJcZ5TEb"
   },
   "outputs": [],
   "source": [
    "class colors:\n",
    "    ok = '\\033[92m'\n",
    "    fail = '\\033[91m'\n",
    "    close = '\\033[0m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1631883147599,
     "user": {
      "displayName": "박아정",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "15223679537180029561"
     },
     "user_tz": -540
    },
    "id": "aCQ2yF9_BWGG"
   },
   "outputs": [],
   "source": [
    "def weird_division(n, d):\n",
    "    return n / d if d else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1631883147600,
     "user": {
      "displayName": "박아정",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "15223679537180029561"
     },
     "user_tz": -540
    },
    "id": "5be_v6anHXE1",
    "outputId": "c548eb09-5e5f-41f4-eedf-a1fa87c54a11"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "char_indices: {' ': 0, '*': 1, '+': 2, '0': 3, '1': 4, '2': 5, '3': 6, '4': 7, '5': 8, '6': 9, '7': 10, '8': 11, '9': 12}\n",
      "indeces_char:  {0: ' ', 1: '*', 2: '+', 3: '0', 4: '1', 5: '2', 6: '3', 7: '4', 8: '5', 9: '6', 10: '7', 11: '8', 12: '9'}\n",
      "Get data...from txt\n"
     ]
    }
   ],
   "source": [
    "# Parameters for the model and dataset.\n",
    "TRAINING_SIZE = 50000\n",
    "DIGITS = 3\n",
    "INVERT = True\n",
    "\n",
    "# Maximum length of input is 'int + int' (e.g., '345+678'). Maximum length of\n",
    "# int is DIGITS.\n",
    "MAxLEN = DIGITS + 1 + DIGITS\n",
    "\n",
    "# All the numbers, plus sign and space for padding.\n",
    "# ctable : 문자 집합에 대해 character table 을 만든 인스턴스(?)\n",
    "chars = '0123456789+* '\n",
    "calc = '+*'\n",
    "ctable = CharacterTable(chars)\n",
    "\n",
    "questions = []\n",
    "expected = []\n",
    "seen = set()\n",
    "file_path = './dataset/3digit_plusmul.txt'\n",
    "\n",
    "print('Get data...from txt')\n",
    "for line in open(file_path, 'r'):\n",
    "        idx = line.find('_')\n",
    "        questions.append(line[:idx][::-1])\n",
    "        expected.append(line[idx+1:-1])\n",
    "\n",
    "# Generating Data...\n",
    "# np.random.randint(1, 20) : 1~19까지 랜덤한 숫자 1개\n",
    "# while len(questions) < TRAINING_SIZE:   #50000개 만듦\n",
    "#     # f : 최대 3자리까지 랜덤한 숫자를 만든다.\n",
    "#     f = lambda: int(''.join(np.random.choice(list('0123456789'))\n",
    "#                     for i in range(np.random.randint(1, DIGITS + 1))))\n",
    "#     a, b = f(), f()\n",
    "\n",
    "#     # Skip any addition questions we've already seen\n",
    "#     # Also skip any such that x+Y == Y+x (hence the sorting).\n",
    "#     key = tuple(sorted((a, b)))\n",
    "#     if key in seen:\n",
    "#         continue\n",
    "#     seen.add(key)\n",
    "\n",
    "#     # Pad the data with spaces such that it is always MAxLEN.\n",
    "#     q = str(a) + np.random.choice(list(calc)) + str(b)\n",
    "#     # q = '{}+{}'.format(a, b)\n",
    "#     query = q + ' ' * (MAxLEN - len(q)) # 전체 길이 - q 길이 만큼 padding 을 줘서 전체 길이가 맞춰지도록.\n",
    "#     if '+' in q:\n",
    "#       ans = str(a + b)\n",
    "#     else:\n",
    "#       ans = str(a * b)\n",
    "  \n",
    "#     # Answers can be of maximum size DIGITS + 1.\n",
    "#     # answer 도 패딩을 맞춰준다. (answer가 될 수 있는 최대 길이에서 - 현재 나온 답의 길이 만큼)\n",
    "#     # answer 의 최대 길이 : 6자리(999*999 = 998001)\n",
    "#     ans += ' ' * (DIGITS + 3 - len(ans))\n",
    "\n",
    "#     # Input의 Reverse 여부\n",
    "#     if INVERT:\n",
    "#         # Reverse the query, e.g., '12+345  ' becomes '  543+21'. (Note the\n",
    "#         # space used for padding.)\n",
    "#         query = query[::-1] # Reverse\n",
    "#     questions.append(query)\n",
    "#     expected.append(ans)\n",
    "# print('Total addition questions:', len(questions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1631883147600,
     "user": {
      "displayName": "박아정",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "15223679537180029561"
     },
     "user_tz": -540
    },
    "id": "RWFfyC9oyq2C",
    "outputId": "72f9236b-eb04-45ff-a7ed-747d2532e300"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  9*084?4320  \n",
      "480*9  \n",
      "4320  \n",
      "4320  ?\n"
     ]
    }
   ],
   "source": [
    "# Reverse 해서 인풋이 거꾸로 출력됨.\n",
    "print(questions[1] + '?' + expected[1])\n",
    "print(questions[1][::-1])\n",
    "print(expected[1])\n",
    "print(expected[1] + '?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1631883147601,
     "user": {
      "displayName": "박아정",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "15223679537180029561"
     },
     "user_tz": -540
    },
    "id": "1L8-JRLuw-fN"
   },
   "outputs": [],
   "source": [
    "# f = open('plusmul.txt', 'w')\n",
    "# for i in range(len(questions)):\n",
    "# #     data = questions[i][::-1] + '_' + expected[i] + '\\n'\n",
    "#     data = questions[i] + '_' + expected[i] + '\\n'\n",
    "#     f.write(data)\n",
    "# f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1631883147948,
     "user": {
      "displayName": "박아정",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "15223679537180029561"
     },
     "user_tz": -540
    },
    "id": "_ShaxkUDJ0K3"
   },
   "outputs": [],
   "source": [
    "# print('Vectorization...')\n",
    "# # np.zeros(shape, dtype, order)\n",
    "# x = np.zeros((len(questions), MAxLEN, len(chars)), dtype=np.bool)\n",
    "# y = np.zeros((len(questions), DIGITS + 3, len(chars)), dtype=np.bool)\n",
    "# print(x.shape)\n",
    "# print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 263,
     "status": "ok",
     "timestamp": 1631883148207,
     "user": {
      "displayName": "박아정",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "15223679537180029561"
     },
     "user_tz": -540
    },
    "id": "TR73ZQDHJwv-",
    "outputId": "1ee024c8-bf8f-4fdb-ed71-6d80763b3659"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorization...\n",
      "Training Data:\n",
      "(45000, 7, 13)\n",
      "(45000, 6, 13)\n",
      "Validation Data:\n",
      "(5000, 7, 13)\n",
      "(5000, 6, 13)\n"
     ]
    }
   ],
   "source": [
    "print('Vectorization...')\n",
    "# np.zeros(shape, dtype, order)\n",
    "# x : (50000, 7, 15), y : (50000, 6, 15)\n",
    "# 입력데이터를 Encode\n",
    "# 일단 x, y 를 0으로 초기화\n",
    "x = np.zeros((len(questions), MAxLEN, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(questions), DIGITS + 3, len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(questions):\n",
    "    x[i] = ctable.encode(sentence, MAxLEN)\n",
    "for i, sentence in enumerate(expected):\n",
    "    y[i] = ctable.encode(sentence, DIGITS + 3)\n",
    "\n",
    "# print('x[1]: ', x[1])\n",
    "# print('y[1]: ', y[1])\n",
    "\n",
    "# Shuffle (x, y) in unison as the later parts of x will almost all be larger\n",
    "# digits.\n",
    "# x의 뒷부분이 더 커지기 때문에 (x, y) 를 섞는다. (???) -> 어쨋든 셔플\n",
    "# x[indices] : 50,000개의 데이터가 셔플 되는 것 같음\n",
    "# indices = np.arange(len(y))\n",
    "# np.random.shuffle(indices)\n",
    "# x = x[indices]\n",
    "# y = y[indices]\n",
    "\n",
    "# print('shuffle x: ', x)\n",
    "# print('shuffle y: ', y)\n",
    "\n",
    "# Explicitly set apart 10% for validation data that we never train over.\n",
    "# Test Set : 0~45000, Validation Set : 45000~50000\n",
    "split_at = len(x) - len(x) // 10\n",
    "(x_train, x_val) = x[:split_at], x[split_at:]\n",
    "(y_train, y_val) = y[:split_at], y[split_at:]\n",
    "\n",
    "print('Training Data:')\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print('Validation Data:')\n",
    "print(x_val.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6156,
     "status": "ok",
     "timestamp": 1631883154360,
     "user": {
      "displayName": "박아정",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "15223679537180029561"
     },
     "user_tz": -540
    },
    "id": "T2ZFo7R_TC2U",
    "outputId": "514d5004-5fe0-4879-fa45-cfccbb045bd0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 128)               72704     \n",
      "_________________________________________________________________\n",
      "repeat_vector (RepeatVector) (None, 6, 128)            0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 6, 128)            131584    \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, 6, 13)             1677      \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 6, 13)             0         \n",
      "=================================================================\n",
      "Total params: 205,965\n",
      "Trainable params: 205,965\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Try replacing GRU, or SimpleRNN.\n",
    "RNN = layers.LSTM\n",
    "HIDDEN_SIZE = 128\n",
    "BATCH_SIZE = 128\n",
    "LAYERS = 1\n",
    "\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "\n",
    "# \"Encode\" the input sequence using an RNN, producing an output of HIDDEN_SIZE.\n",
    "# Note: In a situation where your input sequences have a variable length,\n",
    "# use input_shape=(None, num_feature).\n",
    "model.add(RNN(HIDDEN_SIZE, input_shape=(MAxLEN, len(chars))))\n",
    "\n",
    "# As the decoder RNN's input, repeatedly provide with the last hidden state of\n",
    "# RNN for each time step. Repeat 'DIGITS + 1' times as that's the maximum\n",
    "# length of output, e.g., when DIGITS=3, max output is 999+999=1998.\n",
    "model.add(layers.RepeatVector(DIGITS + 3))\n",
    "\n",
    "# The decoder RNN could be multiple layers stacked or a single layer.\n",
    "for _ in range(LAYERS):\n",
    "    # By setting return_sequences to True, return not only the last output but\n",
    "    # all the outputs so far in the form of (num_samples, timesteps,\n",
    "    # output_dim). This is necessary as TimeDistributed in the below expects\n",
    "    # the first dimension to be the timesteps.\n",
    "    # return_sequences(시퀀스 출력 여부): True(각 시퀀스에서 출력, many-to-many 일 때)\n",
    "    model.add(RNN(HIDDEN_SIZE, return_sequences=True))\n",
    "\n",
    "# Apply a dense layer to the every temporal slice of an input. For each of step\n",
    "# of the output sequence, decide which character should be chosen.\n",
    "# TimeDistributed :7개의 시간 단계 각각에 독립적으로 Dense 레이어를 적용\n",
    "model.add(layers.TimeDistributed(layers.Dense(len(chars))))\n",
    "model.add(layers.Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "27aLlS854fJa",
    "outputId": "a91751bd-e499-4d73-9971-c004a58703bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1\n",
      "352/352 [==============================] - 12s 13ms/step - loss: 1.6209 - accuracy: 0.4275 - val_loss: 1.6132 - val_accuracy: 0.4068\n"
     ]
    }
   ],
   "source": [
    "# Train the model each generation and show predictions against the validation\n",
    "# dataset.\n",
    "acc_list = []\n",
    "valacc_list = []\n",
    "trainacc_list = []\n",
    "val_loss_list = []\n",
    "train_loss_list = []\n",
    "\n",
    "for iteration in range(1, 200):\n",
    "    print()\n",
    "    print('-' * 50)\n",
    "    print('Iteration', iteration)\n",
    "    history = model.fit(x_train, y_train, batch_size=BATCH_SIZE, verbose = 1, epochs=1,\n",
    "              validation_data=(x_val, y_val))\n",
    "    # Select samples from the validation set at random so we can visualize\n",
    "    # errors.\n",
    "    valacc_list.append(history.history.get('val_accuracy')[0])\n",
    "    trainacc_list.append(history.history.get('accuracy')[0])\n",
    "    val_loss_list.append(history.history.get('val_loss')[0])\n",
    "    train_loss_list.append(history.history.get('loss')[0])\n",
    "        \n",
    "    correct_num = 0\n",
    "    # sys.stdout = open('output.txt','w')\n",
    "    for i in range(len(x_val)):\n",
    "        rowx, rowy = x_val[np.array([i])], y_val[np.array([i])]\n",
    "\n",
    "        # predict_classes : 0 or 1로 출력 (predict 와 약간 다름) --> 2.6버전에서 삭제됨\n",
    "        # 모델이 예측(확률로 출력)\n",
    "        predict_x=model.predict(rowx) \n",
    "        # (axis: 0->x축, 1-> y축, 2-> z축) -> 중요\n",
    "        classes_x=np.argmax(predict_x,axis=2)\n",
    "        q = ctable.decode(rowx[0])\n",
    "        correct = ctable.decode(rowy[0])\n",
    "        guess = ctable.decode(classes_x[0], calc_argmax=False)\n",
    "        \n",
    "        print('guess: ', guess)\n",
    "        print('Q', q[::-1] if INVERT else q)\n",
    "        print('T', correct)\n",
    "        if correct == guess:\n",
    "            # print(colors.ok + '☑' + colors.close, end=\" \")\n",
    "            correct_num += 1\n",
    "        else:\n",
    "            # print(colors.fail + '☒' + colors.close, end=\" \")\n",
    "            correct_num += 0\n",
    "        # print(guess)\n",
    "        print('---')\n",
    "    acc = float(correct_num) / len(x_val)\n",
    "    acc_list.append(acc)\n",
    "    print('검증 정확도 %.3f%%' % (acc * 100))\n",
    "    if iteration == 100:\n",
    "      print('100번째 정확도 : ', acc)\n",
    "model.save('./model/plusmul.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vq0bijYVEuTf"
   },
   "outputs": [],
   "source": [
    "# train loss 그래프 그리기\n",
    "x = np.arange(len(acc_list))\n",
    "plt.plot(x, acc_list, marker='o')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.ylim(0, 1.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "obrFvjzCQdyf"
   },
   "outputs": [],
   "source": [
    "# validation accuracy 그래프 그리기\n",
    "v = np.arange(len(valacc_list))\n",
    "plt.plot(v, valacc_list, marker='o')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('val_accuracy')\n",
    "plt.ylim(0, 1.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o_GRZ28HQdyg"
   },
   "outputs": [],
   "source": [
    "# validation loss 그래프 그리기\n",
    "v = np.arange(len(val_loss_list))\n",
    "plt.plot(v, val_loss_list, marker='o')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('val_loss')\n",
    "plt.ylim(0, 1.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vzn8246TQdyg"
   },
   "outputs": [],
   "source": [
    "# train loss 그래프 그리기\n",
    "v = np.arange(len(train_loss_list))\n",
    "plt.plot(v, train_loss_list, marker='o')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('train_loss')\n",
    "plt.ylim(0, 1.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8R5i0-sMQdyh"
   },
   "outputs": [],
   "source": [
    "## summarize history for accuracy\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "## summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aj_CqHtSQdyh"
   },
   "outputs": [],
   "source": [
    "# Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation)."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "plus&mul_rnn.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
