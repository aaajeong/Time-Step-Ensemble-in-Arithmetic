{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gZI5NIQA4jPH"
   },
   "source": [
    "# **Keras 예제 - Seq2Seq 로 덧셈 구현**\n",
    "\n",
    "출처 : https://github.com/keras-team/keras/blob/2.0.0/examples/addition_rnn.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "executionInfo": {
     "elapsed": 527,
     "status": "ok",
     "timestamp": 1630824563355,
     "user": {
      "displayName": "박아정",
      "photoUrl": "",
      "userId": "15223679537180029561"
     },
     "user_tz": -540
    },
    "id": "P5N5RDNI5Gpr",
    "outputId": "3f503f2c-c7a9-4663-991a-9035d3cc2914"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'An implementation of sequence to sequence learning for performing addition\\nInput: \"535+61\"\\nOutput: \"596\"\\nPadding is handled by using a repeated sentinel character (space)\\nInput may optionally be inverted, shown to increase performance in many tasks in:\\n\"Learning to Execute\"\\nhttp://arxiv.org/abs/1410.4615\\nand\\n\"Sequence to Sequence Learning with Neural Networks\"\\nhttp://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf\\nTheoretically it introduces shorter term dependencies between source and target.\\nTwo digits inverted:\\n+ One layer LSTM (128 HN), 5k training examples = 99% train/test accuracy in 55 epochs\\nThree digits inverted:\\n+ One layer LSTM (128 HN), 50k training examples = 99% train/test accuracy in 100 epochs\\nFour digits inverted:\\n+ One layer LSTM (128 HN), 400k training examples = 99% train/test accuracy in 20 epochs\\nFive digits inverted:\\n+ One layer LSTM (128 HN), 550k training examples = 99% train/test accuracy in 30 epochs\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "'''An implementation of sequence to sequence learning for performing addition\n",
    "Input: \"535+61\"\n",
    "Output: \"596\"\n",
    "Padding is handled by using a repeated sentinel character (space)\n",
    "Input may optionally be inverted, shown to increase performance in many tasks in:\n",
    "\"Learning to Execute\"\n",
    "http://arxiv.org/abs/1410.4615\n",
    "and\n",
    "\"Sequence to Sequence Learning with Neural Networks\"\n",
    "http://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf\n",
    "Theoretically it introduces shorter term dependencies between source and target.\n",
    "Two digits inverted:\n",
    "+ One layer LSTM (128 HN), 5k training examples = 99% train/test accuracy in 55 epochs\n",
    "Three digits inverted:\n",
    "+ One layer LSTM (128 HN), 50k training examples = 99% train/test accuracy in 100 epochs\n",
    "Four digits inverted:\n",
    "+ One layer LSTM (128 HN), 400k training examples = 99% train/test accuracy in 20 epochs\n",
    "Five digits inverted:\n",
    "+ One layer LSTM (128 HN), 550k training examples = 99% train/test accuracy in 30 epochs\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1630824563356,
     "user": {
      "displayName": "박아정",
      "photoUrl": "",
      "userId": "15223679537180029561"
     },
     "user_tz": -540
    },
    "id": "UalzhCNK5M8Q"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "from six.moves import range\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 8615866945685663249,\n",
       " name: \"/device:XLA_CPU:0\"\n",
       " device_type: \"XLA_CPU\"\n",
       " memory_limit: 17179869184\n",
       " locality {\n",
       " }\n",
       " incarnation: 10256944797237994698\n",
       " physical_device_desc: \"device: XLA_CPU device\",\n",
       " name: \"/device:GPU:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 10699354944\n",
       " locality {\n",
       "   bus_id: 4\n",
       "   numa_node: 3\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 12108414743068228523\n",
       " physical_device_desc: \"device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:07:00.0, compute capability: 7.5\",\n",
       " name: \"/device:GPU:1\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 10699354944\n",
       " locality {\n",
       "   bus_id: 2\n",
       "   numa_node: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 3858110411458758383\n",
       " physical_device_desc: \"device: 1, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:41:00.0, compute capability: 7.5\",\n",
       " name: \"/device:XLA_GPU:0\"\n",
       " device_type: \"XLA_GPU\"\n",
       " memory_limit: 17179869184\n",
       " locality {\n",
       " }\n",
       " incarnation: 14499990565694586789\n",
       " physical_device_desc: \"device: XLA_GPU device\",\n",
       " name: \"/device:XLA_GPU:1\"\n",
       " device_type: \"XLA_GPU\"\n",
       " memory_limit: 17179869184\n",
       " locality {\n",
       " }\n",
       " incarnation: 9674798652838182355\n",
       " physical_device_desc: \"device: XLA_GPU device\"]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1630824563357,
     "user": {
      "displayName": "박아정",
      "photoUrl": "",
      "userId": "15223679537180029561"
     },
     "user_tz": -540
    },
    "id": "21In4rWv5QdY"
   },
   "outputs": [],
   "source": [
    "class CharacterTable(object):\n",
    "    \"\"\"Given a set of characters:\n",
    "    + Encode them to a one hot integer representation\n",
    "    + Decode the one hot integer representation to their character output\n",
    "    + Decode a vector of probabilities to their character output\n",
    "    \"\"\"\n",
    "    # 초기화 : 사용되는 문자 집합이 주어지면 caharacter table 을 초기화한다.\n",
    "    def __init__(self, chars):\n",
    "        \"\"\"Initialize character table.\n",
    "        # Arguments\n",
    "            chars: Characters that can appear in the input.\n",
    "        \"\"\"\n",
    "        # 문자 집합이 주어지면 각 문자에 대한 인덱스를 매긴다.\n",
    "        # char_indices : (문자, 인덱스), indices_char : (인덱스, 문자)\n",
    "        self.chars = sorted(set(chars))\n",
    "        self.char_indices = dict((c, i) for i, c in enumerate(self.chars))\n",
    "        self.indices_char = dict((i, c) for i, c in enumerate(self.chars))\n",
    "\n",
    "    def encode(self, C, num_rows):\n",
    "        \"\"\"One hot encode given string C.\n",
    "        # Arguments\n",
    "            num_rows: Number of rows in the returned one hot encoding. This is\n",
    "                used to keep the # of rows for each data the same.\n",
    "        \"\"\"\n",
    "        x = np.zeros((num_rows, len(self.chars)))\n",
    "        # 문장(C)의 문자에 해당하는 행렬 위치를 0->1 로 바꾼다.\n",
    "        for i, c in enumerate(C):\n",
    "            x[i, self.char_indices[c]] = 1    # 순서대로 i번째 행에 char_indices[c] 열에 1 대입\n",
    "        return x\n",
    "\n",
    "    def decode(self, x, calc_argmax=True):\n",
    "        if calc_argmax:\n",
    "            x = x.argmax(axis=-1)\n",
    "        return ''.join(self.indices_char[x] for x in x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1630824563357,
     "user": {
      "displayName": "박아정",
      "photoUrl": "",
      "userId": "15223679537180029561"
     },
     "user_tz": -540
    },
    "id": "3qsppJcZ5TEb"
   },
   "outputs": [],
   "source": [
    "class colors:\n",
    "    ok = '\\033[92m'\n",
    "    fail = '\\033[91m'\n",
    "    close = '\\033[0m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7341,
     "status": "ok",
     "timestamp": 1630824570690,
     "user": {
      "displayName": "박아정",
      "photoUrl": "",
      "userId": "15223679537180029561"
     },
     "user_tz": -540
    },
    "id": "5be_v6anHXE1",
    "outputId": "3442529f-6006-4f3a-d282-dcb3605c1e71"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get data...from txt\n",
      "Total addition questions: 50000\n"
     ]
    }
   ],
   "source": [
    "# Parameters for the model and dataset.\n",
    "TRAINING_SIZE = 50000\n",
    "DIGITS = 3\n",
    "INVERT = True\n",
    "\n",
    "# Maximum length of input is 'int + int' (e.g., '345+678'). Maximum length of\n",
    "# int is DIGITS.\n",
    "MAxLEN = DIGITS + 1 + DIGITS\n",
    "\n",
    "# All the numbers, plus sign and space for padding.\n",
    "# ctable : 문자 집합에 대해 character table 을 만든 인스턴스(?)\n",
    "chars = '0123456789+ '\n",
    "ctable = CharacterTable(chars)\n",
    "\n",
    "questions = []\n",
    "expected = []\n",
    "seen = set()\n",
    "file_path = 'dataset/addition.txt'\n",
    "\n",
    "print('Get data...from txt')\n",
    "for line in open(file_path, 'r'):\n",
    "        idx = line.find('_')\n",
    "        questions.append(line[:idx][::-1])\n",
    "        expected.append(line[idx+1:-1])\n",
    "        \n",
    "#print('Generating data...')\n",
    "# np.random.randint(1, 20) : 1~19까지 랜덤한 숫자 1개\n",
    "#while len(questions) < TRAINING_SIZE:\n",
    "#    # f : 최대 3자리까지 랜덤한 숫자를 만든다.\n",
    "#    f = lambda: int(''.join(np.random.choice(list('0123456789'))\n",
    "#                    for i in range(np.random.randint(1, DIGITS + 1))))\n",
    "#    a, b = f(), f()\n",
    "\n",
    "#    # Skip any addition questions we've already seen\n",
    "#    # Also skip any such that x+Y == Y+x (hence the sorting).\n",
    "#    key = tuple(sorted((a, b)))\n",
    "#    if key in seen:\n",
    "#        continue\n",
    "#    seen.add(key)\n",
    "\n",
    "#    # Pad the data with spaces such that it is always MAxLEN.\n",
    "#    q = '{}+{}'.format(a, b)\n",
    "#    query = q + ' ' * (MAxLEN - len(q)) # 전체 길이 - q 길이 만큼 padding 을 줘서 전체 길이가 맞춰지도록.\n",
    "#    ans = str(a + b)\n",
    "\n",
    "#    # Answers can be of maximum size DIGITS + 1.\n",
    "#    # answer 도 패딩을 맞춰준다. (answer가 될 수 있는 최대 길이에서 - 현재 나온 답의 길이 만큼)\n",
    "#    ans += ' ' * (DIGITS + 1 - len(ans))\n",
    "\n",
    "#    # Input의 Reverse 여부\n",
    "#    if INVERT:\n",
    "#        # Reverse the query, e.g., '12+345  ' becomes '  543+21'. (Note the\n",
    "#        # space used for padding.)\n",
    "#        query = query[::-1] # Reverse\n",
    "#    questions.append(query)\n",
    "#    expected.append(ans)\n",
    "print('Total addition questions:', len(questions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1630824570690,
     "user": {
      "displayName": "박아정",
      "photoUrl": "",
      "userId": "15223679537180029561"
     },
     "user_tz": -540
    },
    "id": "_ShaxkUDJ0K3",
    "outputId": "e7d5a263-e79f-43e6-88ea-4f72f0572391"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorization...\n",
      "(50000, 7, 12)\n",
      "(50000, 4, 12)\n"
     ]
    }
   ],
   "source": [
    "print('Vectorization...')\n",
    "# np.zeros(shape, dtype, order)\n",
    "x = np.zeros((len(questions), MAxLEN, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(questions), DIGITS + 1, len(chars)), dtype=np.bool)\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  57+61\n",
      "91  \n"
     ]
    }
   ],
   "source": [
    "print(questions[0])\n",
    "print(expected[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 585,
     "status": "ok",
     "timestamp": 1630824571266,
     "user": {
      "displayName": "박아정",
      "photoUrl": "",
      "userId": "15223679537180029561"
     },
     "user_tz": -540
    },
    "id": "TR73ZQDHJwv-",
    "outputId": "6c7ede23-04c7-43c6-e81c-a28726e20e02"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorization...\n",
      "Training Data:\n",
      "(45000, 7, 12)\n",
      "(45000, 4, 12)\n",
      "Validation Data:\n",
      "(5000, 7, 12)\n",
      "(5000, 4, 12)\n"
     ]
    }
   ],
   "source": [
    "print('Vectorization...')\n",
    "# np.zeros(shape, dtype, order)\n",
    "# x : (50000, 7, 12), y : (50000, 4, 12)\n",
    "# 입력데이터를 Encode\n",
    "x = np.zeros((len(questions), MAxLEN, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(questions), DIGITS + 1, len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(questions):\n",
    "    x[i] = ctable.encode(sentence, MAxLEN)\n",
    "for i, sentence in enumerate(expected):\n",
    "    y[i] = ctable.encode(sentence, DIGITS + 1)\n",
    "\n",
    "# Shuffle (x, y) in unison as the later parts of x will almost all be larger\n",
    "# digits.\n",
    "# x의 뒷부분이 더 커지기 때문에 (x, y) 를 섞는다. (???) -> 어쨋든 셔플\n",
    "indices = np.arange(len(y))\n",
    "np.random.shuffle(indices)\n",
    "x = x[indices]\n",
    "y = y[indices]\n",
    "\n",
    "# Explicitly set apart 10% for validation data that we never train over.\n",
    "# Test Set : 0~45000, Validation Set : 45000~50000\n",
    "split_at = len(x) - len(x) // 10\n",
    "(x_train, x_val) = x[:split_at], x[split_at:]\n",
    "(y_train, y_val) = y[:split_at], y[split_at:]\n",
    "\n",
    "print('Training Data:')\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print('Validation Data:')\n",
    "print(x_val.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2211,
     "status": "ok",
     "timestamp": 1630824573472,
     "user": {
      "displayName": "박아정",
      "photoUrl": "",
      "userId": "15223679537180029561"
     },
     "user_tz": -540
    },
    "id": "T2ZFo7R_TC2U",
    "outputId": "334d27d2-94e0-4d6e-961f-c6cca19ef462"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 128)               72192     \n",
      "_________________________________________________________________\n",
      "repeat_vector (RepeatVector) (None, 4, 128)            0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 4, 128)            131584    \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, 4, 12)             1548      \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 4, 12)             0         \n",
      "=================================================================\n",
      "Total params: 205,324\n",
      "Trainable params: 205,324\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Try replacing GRU, or SimpleRNN.\n",
    "RNN = layers.LSTM\n",
    "HIDDEN_SIZE = 128\n",
    "BATCH_SIZE = 128\n",
    "LAYERS = 1\n",
    "\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "\n",
    "# \"Encode\" the input sequence using an RNN, producing an output of HIDDEN_SIZE.\n",
    "# Note: In a situation where your input sequences have a variable length,\n",
    "# use input_shape=(None, num_feature).\n",
    "model.add(RNN(HIDDEN_SIZE, input_shape=(MAxLEN, len(chars))))\n",
    "\n",
    "# As the decoder RNN's input, repeatedly provide with the last hidden state of\n",
    "# RNN for each time step. Repeat 'DIGITS + 1' times as that's the maximum\n",
    "# length of output, e.g., when DIGITS=3, max output is 999+999=1998.\n",
    "model.add(layers.RepeatVector(DIGITS + 1))\n",
    "\n",
    "# The decoder RNN could be multiple layers stacked or a single layer.\n",
    "for _ in range(LAYERS):\n",
    "    # By setting return_sequences to True, return not only the last output but\n",
    "    # all the outputs so far in the form of (num_samples, timesteps,\n",
    "    # output_dim). This is necessary as TimeDistributed in the below expects\n",
    "    # the first dimension to be the timesteps.\n",
    "    # return_sequences(시퀀스 출력 여부): True(각 시퀀스에서 출력, many-to-many 일 때)\n",
    "    model.add(RNN(HIDDEN_SIZE, return_sequences=True))\n",
    "\n",
    "# Apply a dense layer to the every temporal slice of an input. For each of step\n",
    "# of the output sequence, decide which character should be chosen.\n",
    "# TimeDistributed :7개의 시간 단계 각각에 독립적으로 Dense 레이어를 적용\n",
    "model.add(layers.TimeDistributed(layers.Dense(len(chars))))\n",
    "model.add(layers.Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 23470,
     "status": "error",
     "timestamp": 1630824596933,
     "user": {
      "displayName": "박아정",
      "photoUrl": "",
      "userId": "15223679537180029561"
     },
     "user_tz": -540
    },
    "id": "27aLlS854fJa",
    "outputId": "918a660d-c8c5-4cdd-c5f3-54ed3a8f4771"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1\n",
      "352/352 - 2s - loss: 1.0149 - accuracy: 0.6287 - val_loss: 0.9855 - val_accuracy: 0.6381\n",
      "검증 정확도 4.840%\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2\n",
      "352/352 - 2s - loss: 0.9434 - accuracy: 0.6587 - val_loss: 0.9202 - val_accuracy: 0.6635\n",
      "검증 정확도 5.640%\n"
     ]
    }
   ],
   "source": [
    "# Train the model each generation and show predictions against the validation\n",
    "# dataset.\n",
    "acc_list = []\n",
    "history_list = []\n",
    "\n",
    "for iteration in range(1, 200):\n",
    "    print()\n",
    "    print('-' * 50)\n",
    "    print('Iteration', iteration)\n",
    "    history = model.fit(x_train, y_train, batch_size=BATCH_SIZE, verbose = 2, epochs=1,\n",
    "              validation_data=(x_val, y_val))\n",
    "    # Select 10 samples from the validation set at random so we can visualize\n",
    "    # errors.\n",
    "    history_list.append(history.history.get('val_accuracy')[0])\n",
    "    \n",
    "    correct_num = 0\n",
    "    for i in range(len(x_val)):\n",
    "        rowx, rowy = x_val[np.array([i])], y_val[np.array([i])]\n",
    "        # predict_classes : 0 or 1로 출력 (predict 와 약간 다름) --> 2.6버전에서 삭제됨\n",
    "        preds = model.predict_classes(rowx, verbose=0)\n",
    "        q = ctable.decode(rowx[0])\n",
    "        correct = ctable.decode(rowy[0])\n",
    "        guess = ctable.decode(preds[0], calc_argmax=False)\n",
    "        \n",
    "        if guess == correct:\n",
    "          correct_num += 1\n",
    "        else:\n",
    "          correct_num += 0\n",
    "        \n",
    "#        if correct == guess:\n",
    "#            print(colors.ok + '☑' + colors.close, end=\" \")\n",
    "#        else:\n",
    "#            print(colors.fail + '☒' + colors.close, end=\" \")\n",
    "#        print(guess)\n",
    "#        print('---')\n",
    "    acc = float(correct_num) / len(x_val)\n",
    "    acc_list.append(acc)\n",
    "    print('검증 정확도 %.3f%%' % (acc * 100))\n",
    "    if iteration == 100:\n",
    "      print('100번째 정확도 : ', acc)\n",
    "    \n",
    "model.save('addition.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tako/.local/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:238: RuntimeWarning: Glyph 50640 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/home/tako/.local/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:238: RuntimeWarning: Glyph 54253 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/home/tako/.local/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:238: RuntimeWarning: Glyph 51221 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/home/tako/.local/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:238: RuntimeWarning: Glyph 54869 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/home/tako/.local/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:238: RuntimeWarning: Glyph 46020 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/home/tako/.local/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:201: RuntimeWarning: Glyph 50640 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/home/tako/.local/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:201: RuntimeWarning: Glyph 54253 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/home/tako/.local/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:201: RuntimeWarning: Glyph 51221 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/home/tako/.local/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:201: RuntimeWarning: Glyph 54869 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/home/tako/.local/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:201: RuntimeWarning: Glyph 46020 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 그래프 그리기\n",
    "x = np.arange(len(acc_list))\n",
    "plt.plot(x, acc_list, marker='o')\n",
    "plt.xlabel('에폭')\n",
    "plt.ylabel('정확도')\n",
    "plt.ylim(0, 1.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tako/.local/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:238: RuntimeWarning: Glyph 50640 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/home/tako/.local/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:238: RuntimeWarning: Glyph 54253 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/home/tako/.local/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:238: RuntimeWarning: Glyph 51221 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/home/tako/.local/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:238: RuntimeWarning: Glyph 54869 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/home/tako/.local/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:238: RuntimeWarning: Glyph 46020 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/home/tako/.local/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:201: RuntimeWarning: Glyph 50640 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/home/tako/.local/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:201: RuntimeWarning: Glyph 54253 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/home/tako/.local/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:201: RuntimeWarning: Glyph 51221 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/home/tako/.local/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:201: RuntimeWarning: Glyph 54869 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/home/tako/.local/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:201: RuntimeWarning: Glyph 46020 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEKCAYAAAAfGVI8AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAARgUlEQVR4nO3df4hld3nH8fdnZjYaf6Y0K+gmmpSuP7a2kHSIKUK1aGuSPzYFiyQgVgkGbCNaJRCxRBv/qYbaIqTVlYo/QNMoEhaMLq1GBDGSkWg0kbXbaM2ulqwaU4rR7M48/ePemb1z597dm9059+7M9/2CZe895zvnPmdm9/mc7zn3nklVIUlq19ysC5AkzZZBIEmNMwgkqXEGgSQ1ziCQpMYZBJLUuM6CIMnHkjyS5Htj1ifJh5IcSnJ/kku7qkWSNF6XM4KPA1ecZP2VwO7+n+uBf+mwFknSGJ0FQVV9DfjFSYZcDXyyeu4Bzkvy3K7qkSSNtjDD194FPDzw/HB/2U+HBya5nt6sgac//el/+OIXv3gqBUrSdvGtb33rZ1W1c9S6WQbBxKpqH7APYHFxsZaWlmZckSRtLUn+e9y6Wb5r6Ahw4cDzC/rLJElTNMsg2A+8of/uocuBx6pqw2khSVK3Ojs1lOQzwCuB85McBt4D7ACoqg8DdwFXAYeAXwFv6qoWSdJ4nQVBVV17ivUF/HVXry9JmoyfLJakxhkEktQ4g0CSGmcQSFLjDAJJapxBIEmNMwgkqXEGgSQ1ziCQpMYZBJLUOINAkhpnEEhS4wwCSWqcQSBJjTMIJKlxBoEkNc4gkKTGGQSS1DiDQJIaZxBIUuMMAklqnEEgSY0zCCSpcQaBJDXOIJCkxhkEktQ4g0CSGmcQSFLjDAJJapxBIEmNMwgkqXEGgSQ1ziCQpMYZBJLUOINAkhrXaRAkuSLJwSSHktw0Yv3zk9yd5L4k9ye5qst6JEkbdRYESeaB24ArgT3AtUn2DA37W+COqroEuAb4567qkSSN1uWM4DLgUFU9VFVPALcDVw+NKeBZ/cfPBn7SYT2SpBG6DIJdwMMDzw/3lw16L/D6JIeBu4C3jtpQkuuTLCVZOnr0aBe1SlKzZn2x+Frg41V1AXAV8KkkG2qqqn1VtVhVizt37px6kZK0nXUZBEeACweeX9BfNug64A6AqvoG8FTg/A5rkiQN6TII7gV2J7k4yTn0LgbvHxrzY+BVAEleQi8IPPcjSVPUWRBU1XHgBuAA8H167w56IMktSfb2h70TeHOS7wCfAd5YVdVVTZKkjRa63HhV3UXvIvDgspsHHj8IvLzLGiRJJzfri8WSpBkzCCSpcQaBJDXOIJCkxhkEktQ4g0CSGmcQSFLjDAJJapxBIEmNMwgkqXEGgSQ1ziCQpMYZBJLUOINAkhpnEEhS4wwCSWqcQSBJjTMIJKlxBoEkNc4gkKTGGQSS1LiFWRcgSTq5O+87wq0HDvKTXz7O8847lxtf8yL+/JJdm7Z9g0CSZmR5pTi+ssLx5er9WVnh+Er1/iyvcGy5+PcH/4d/+o//5DfHVwA48svHedfnvwuwaWFgEEg6a1VVv1meaI69v4tjyysnGunQsmPL65evfd1q0x3e1soKy8vFsf7y1W0sr6ysLVvb1sA21moYeL3Vrxu13dVtLK/01lWd3vfl8WPL3HrgoEEgqaeq15SW+41prdGdrOkNjF17PKLZntjGSr/B9Y9UB15vrfGuPl63jaFtbWjiG5v38roaT7NTnoGFuTA/F3bMz7EwHxbmwsLcwOP5uf7f/eX9x0/fscB8f+yO+RPb6P3dW772eHUbY7a7oz92YT687fZvj6zzJ798fPP2edO2JJ3FqmqtkR0baG4bpuRjm95Kv9md+Lr129rY9NaOKFe3NfB4dMMe38THbWO1mU7bWqPrN7L5fvMbbI6jmulTd5xoejtWv64/9sSy/tfNDTTIDQ15fQPdMfR665rwSZr4cMNemAtJpv79PJkPfOkgR0Y0/eedd+6mvUYTQdD1hZbtYmVl/ZHY6CO80Y1rw1Hd4NR63dR89JR8sPkNT8nXTfXXxva3M6KJrztF0D9yXZ5ys0xYd1R3oimtb0ZrDbTf5M5ZmONpA01wrUFtaHonGu9qM13f5MY1vbl1R5zrGu+YZrtjbo75tXW98Wdbs9zObnzNi3jX57/L48eW15adu2OeG1/zok17jW0fBHfed2TdN/FML7SsOxIbMc2e5DzkqKO6DU1vknOaw+dFh6bkJz9XuvH85rQPLOfCwBR5cBo9cFQ3dDQ3PxeeumNu3ZR8cJq94QhvqOktDB9pnmSqP3paf6pt9V5vbs5Gqc2x2qe6PJhNne7VihlZXFyspaWlice//O+/MnJadc78HL+361kjjn6HGu9gc1+p0764c7pWp6vrp9Mbm97gkeGpzm8ObmN42eqU/FRHicNT8uFtjJySD25rLjZLaYqSfKuqFket2/YzgnEXVJ5YXuEZT1noN725kx7hDU/Je0eLg9P6wan+wPnN+Y0NdNyUfH3jPNE0nYJL6tq2D4LnnXfuyBnBrvPO5VPXvWwGFUnS2WXb32Lixte8iHN3zK9bttkXWiRpK9v2M4JpXGiRpK1s2wcB9MLAxi9Jo3V6aijJFUkOJjmU5KYxY16X5MEkDyT5dJf1SJI26mxGkGQeuA34U+AwcG+S/VX14MCY3cC7gJdX1aNJntNVPZKk0bqcEVwGHKqqh6rqCeB24OqhMW8GbquqRwGq6pEO65EkjdBlEOwCHh54fri/bNALgRcm+XqSe5JcMWpDSa5PspRk6ejRox2VK0ltmvXbRxeA3cArgWuBjyY5b3hQVe2rqsWqWty5c+d0K5Skba7LIDgCXDjw/IL+skGHgf1Vdayqfgj8gF4wSJKmpMsguBfYneTiJOcA1wD7h8bcSW82QJLz6Z0qeqjDmiRJQzoLgqo6DtwAHAC+D9xRVQ8kuSXJ3v6wA8DPkzwI3A3cWFU/76omSdJG2/7uo5Kkk999dNYXiyVJM2YQSFLjDAJJapxBIEmNMwgkqXEGgSQ1ziCQpMYZBJLUOINAkhpnEEhS4yb6DWVJbj7FkEeq6sObUI8kacom/VWVl9O7e2jGrP8EYBBI0hY0aRAsV9X/jluZZGvduU6StGbSawSnavQGgSRtUZPOCHYkedaYdQHmN6keSdKUTRoE9wBvP8n6L555KZKkWZg0CGD8hWJJ0hY2aRC8DN81JEnbku8akqTG+a4hSWqc7xqSpMZtxruGgu8akqQty4vFktQ4LxZLUuO8WCxJjfNisSQ17sleLB53jeBLm1KNJGnqJgqCqvq7rguRJM2Gv6pSkhpnEEhS4wwCSWqcQSBJjTMIJKlxBoEkNc4gkKTGdRoESa5IcjDJoSQ3nWTca5NUksUu65EkbdRZECSZB24DrgT2ANcm2TNi3DOBtwHf7KoWSdJ4Xc4ILgMOVdVDVfUEcDtw9Yhx7wPeD/y6w1okSWN0GQS7gIcHnh/uL1uT5FLgwqr6wsk2lOT6JEtJlo4ePbr5lUpSw2Z2sTjJHPBB4J2nGltV+6pqsaoWd+7c2X1xktSQLoPgCHDhwPML+stWPRN4KfDVJD8CLgf2e8FYkqaryyC4F9id5OIk59D7VZf7V1dW1WNVdX5VXVRVF9G71fXeqlrqsCZJ0pDOgqCqjgM3AAeA7wN3VNUDSW5Jsrer15UkPTmT/mKa01JVdwF3DS27eczYV3ZZiyRpND9ZLEmNMwgkqXEGgSQ1ziCQpMYZBJLUOINAkhpnEEhS4wwCSWqcQSBJjTMIJKlxBoEkNc4gkKTGGQSS1DiDQJIaZxBIUuMMAklqnEEgSY0zCCSpcQaBJDXOIJCkxhkEktQ4g0CSGmcQSFLjDAJJapxBIEmNMwgkqXEGgSQ1ziCQpMYZBJLUOINAkhpnEEhS4wwCSWqcQSBJjTMIJKlxnQZBkiuSHExyKMlNI9a/I8mDSe5P8uUkL+iyHknSRp0FQZJ54DbgSmAPcG2SPUPD7gMWq+oPgM8BH+iqHknSaF3OCC4DDlXVQ1X1BHA7cPXggKq6u6p+1X96D3BBh/VIkkboMgh2AQ8PPD/cXzbOdcAXR61Icn2SpSRLR48e3cQSJUlnxcXiJK8HFoFbR62vqn1VtVhVizt37pxucZK0zS10uO0jwIUDzy/oL1snyauBdwOvqKrfdFiPJGmELmcE9wK7k1yc5BzgGmD/4IAklwAfAfZW1SMd1iJJGqOzIKiq48ANwAHg+8AdVfVAkluS7O0PuxV4BvDZJN9Osn/M5iRJHeny1BBVdRdw19Cymwcev7rL15ckndpZcbFYkjQ7BoEkNc4gkKTGGQSS1DiDQJIaZxBIUuMMAklqnEEgSY0zCCSpcQaBJDXOIJCkxhkEktQ4g0CSGmcQSFLjDAJJapxBIEmNMwgkqXEGgSQ1ziCQpMYZBJLUOINAkhpnEEhS4wwCSWqcQSBJjTMIJKlxBoEkNc4gkKTGGQSS1DiDQJIaZxBIUuMMAklqnEEgSY0zCCSpcQaBJDXOIJCkxnUaBEmuSHIwyaEkN41Y/5Qk/9Zf/80kF3VZjyRpo86CIMk8cBtwJbAHuDbJnqFh1wGPVtXvAv8IvL+reiRJo3U5I7gMOFRVD1XVE8DtwNVDY64GPtF//DngVUnSYU2SpCELHW57F/DwwPPDwMvGjamq40keA34b+NngoCTXA9f3n/5fkoOnWdP5w9tugPvcBve5DWeyzy8Yt6LLINg0VbUP2Hem20myVFWLm1DSluE+t8F9bkNX+9zlqaEjwIUDzy/oLxs5JskC8Gzg5x3WJEka0mUQ3AvsTnJxknOAa4D9Q2P2A3/Zf/wXwFeqqjqsSZI0pLNTQ/1z/jcAB4B54GNV9UCSW4ClqtoP/CvwqSSHgF/QC4sunfHppS3IfW6D+9yGTvY5HoBLUtv8ZLEkNc4gkKTGbcsgaPHWFhPs8zuSPJjk/iRfTjL2PcVbxan2eWDca5NUki3/VsNJ9jnJ6/o/6weSfHraNW62Cf5tPz/J3Unu6//7vmoWdW6WJB9L8kiS741ZnyQf6n8/7k9y6Rm/aFVtqz/0Lkz/F/A7wDnAd4A9Q2P+Cvhw//E1wL/Nuu4p7POfAE/rP35LC/vcH/dM4GvAPcDirOuews95N3Af8Fv958+Zdd1T2Od9wFv6j/cAP5p13We4z38MXAp8b8z6q4AvAgEuB755pq+5HWcELd7a4pT7XFV3V9Wv+k/vofe5jq1skp8zwPvo3cPq19MsriOT7PObgduq6lGAqnpkyjVutkn2uYBn9R8/G/jJFOvbdFX1NXrvohznauCT1XMPcF6S557Ja27HIBh1a4td48ZU1XFg9dYWW9Uk+zzoOnpHFFvZKfe5P2W+sKq+MM3COjTJz/mFwAuTfD3JPUmumFp13Zhkn98LvD7JYeAu4K3TKW1mnuz/91PaEreY0OZJ8npgEXjFrGvpUpI54IPAG2dcyrQt0Ds99Ep6s76vJfn9qvrlLIvq2LXAx6vqH5L8Eb3PJr20qlZmXdhWsR1nBC3e2mKSfSbJq4F3A3ur6jdTqq0rp9rnZwIvBb6a5Ef0zqXu3+IXjCf5OR8G9lfVsar6IfADesGwVU2yz9cBdwBU1TeAp9K7Odt2NdH/9ydjOwZBi7e2OOU+J7kE+Ai9ENjq543hFPtcVY9V1flVdVFVXUTvusjeqlqaTbmbYpJ/23fSmw2Q5Hx6p4oemmKNm22Sff4x8CqAJC+hFwRHp1rldO0H3tB/99DlwGNV9dMz2eC2OzVUZ+etLTo14T7fCjwD+Gz/uviPq2rvzIo+QxPu87Yy4T4fAP4syYPAMnBjVW3Z2e6E+/xO4KNJ/obeheM3buUDuySfoRfm5/eve7wH2AFQVR+mdx3kKuAQ8CvgTWf8mlv4+yVJ2gTb8dSQJOlJMAgkqXEGgSQ1ziCQpMYZBJLUOINAkhq37T5HIE1DkvfS+7Ty8f6iBXofWtuwrKreO+36pCfDIJBO3zWr9/BJch7w9jHLpLOap4YkqXEGgSQ1ziCQpMYZBJLUOINAkhpnEEhS43z7qHR6HgE+mWT11yHOAV8as0w6q/n7CCSpcZ4akqTGGQSS1DiDQJIaZxBIUuMMAklq3P8DX02xyfSvdGMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 그래프 그리기\n",
    "v = np.arange(len(history_list))\n",
    "plt.plot(v, history_list, marker='o')\n",
    "plt.xlabel('에폭')\n",
    "plt.ylabel('정확도')\n",
    "plt.ylim(0, 1.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "## summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPu6zVPEeBQCRO6+m0CicPX",
   "collapsed_sections": [],
   "name": "addition_rnn.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
