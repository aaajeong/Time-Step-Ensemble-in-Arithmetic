{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"addition_rnn.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPu6zVPEeBQCRO6+m0CicPX"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"gZI5NIQA4jPH"},"source":["# **Keras 예제 - Seq2Seq 로 덧셈 구현**\n","\n","출처 : https://github.com/keras-team/keras/blob/2.0.0/examples/addition_rnn.py\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":170},"id":"P5N5RDNI5Gpr","executionInfo":{"status":"ok","timestamp":1630824563355,"user_tz":-540,"elapsed":527,"user":{"displayName":"박아정","photoUrl":"","userId":"15223679537180029561"}},"outputId":"3f503f2c-c7a9-4663-991a-9035d3cc2914"},"source":["# -*- coding: utf-8 -*-\n","'''An implementation of sequence to sequence learning for performing addition\n","Input: \"535+61\"\n","Output: \"596\"\n","Padding is handled by using a repeated sentinel character (space)\n","Input may optionally be inverted, shown to increase performance in many tasks in:\n","\"Learning to Execute\"\n","http://arxiv.org/abs/1410.4615\n","and\n","\"Sequence to Sequence Learning with Neural Networks\"\n","http://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf\n","Theoretically it introduces shorter term dependencies between source and target.\n","Two digits inverted:\n","+ One layer LSTM (128 HN), 5k training examples = 99% train/test accuracy in 55 epochs\n","Three digits inverted:\n","+ One layer LSTM (128 HN), 50k training examples = 99% train/test accuracy in 100 epochs\n","Four digits inverted:\n","+ One layer LSTM (128 HN), 400k training examples = 99% train/test accuracy in 20 epochs\n","Five digits inverted:\n","+ One layer LSTM (128 HN), 550k training examples = 99% train/test accuracy in 30 epochs\n","'''"],"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'An implementation of sequence to sequence learning for performing addition\\nInput: \"535+61\"\\nOutput: \"596\"\\nPadding is handled by using a repeated sentinel character (space)\\nInput may optionally be inverted, shown to increase performance in many tasks in:\\n\"Learning to Execute\"\\nhttp://arxiv.org/abs/1410.4615\\nand\\n\"Sequence to Sequence Learning with Neural Networks\"\\nhttp://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf\\nTheoretically it introduces shorter term dependencies between source and target.\\nTwo digits inverted:\\n+ One layer LSTM (128 HN), 5k training examples = 99% train/test accuracy in 55 epochs\\nThree digits inverted:\\n+ One layer LSTM (128 HN), 50k training examples = 99% train/test accuracy in 100 epochs\\nFour digits inverted:\\n+ One layer LSTM (128 HN), 400k training examples = 99% train/test accuracy in 20 epochs\\nFive digits inverted:\\n+ One layer LSTM (128 HN), 550k training examples = 99% train/test accuracy in 30 epochs\\n'"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"UalzhCNK5M8Q","executionInfo":{"status":"ok","timestamp":1630824563356,"user_tz":-540,"elapsed":9,"user":{"displayName":"박아정","photoUrl":"","userId":"15223679537180029561"}}},"source":["from __future__ import print_function\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras import layers\n","import numpy as np\n","from six.moves import range"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"21In4rWv5QdY","executionInfo":{"status":"ok","timestamp":1630824563357,"user_tz":-540,"elapsed":10,"user":{"displayName":"박아정","photoUrl":"","userId":"15223679537180029561"}}},"source":["class CharacterTable(object):\n","    \"\"\"Given a set of characters:\n","    + Encode them to a one hot integer representation\n","    + Decode the one hot integer representation to their character output\n","    + Decode a vector of probabilities to their character output\n","    \"\"\"\n","    # 초기화 : 사용되는 문자 집합이 주어지면 caharacter table 을 초기화한다.\n","    def __init__(self, chars):\n","        \"\"\"Initialize character table.\n","        # Arguments\n","            chars: Characters that can appear in the input.\n","        \"\"\"\n","        # 문자 집합이 주어지면 각 문자에 대한 인덱스를 매긴다.\n","        # char_indices : (문자, 인덱스), indices_char : (인덱스, 문자)\n","        self.chars = sorted(set(chars))\n","        self.char_indices = dict((c, i) for i, c in enumerate(self.chars))\n","        self.indices_char = dict((i, c) for i, c in enumerate(self.chars))\n","\n","    def encode(self, C, num_rows):\n","        \"\"\"One hot encode given string C.\n","        # Arguments\n","            num_rows: Number of rows in the returned one hot encoding. This is\n","                used to keep the # of rows for each data the same.\n","        \"\"\"\n","        x = np.zeros((num_rows, len(self.chars)))\n","        # 문장(C)의 문자에 해당하는 행렬 위치를 0->1 로 바꾼다.\n","        for i, c in enumerate(C):\n","            x[i, self.char_indices[c]] = 1    # 순서대로 i번째 행에 char_indices[c] 열에 1 대입\n","        return x\n","\n","    def decode(self, x, calc_argmax=True):\n","        if calc_argmax:\n","            x = x.argmax(axis=-1)\n","        return ''.join(self.indices_char[x] for x in x)"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"3qsppJcZ5TEb","executionInfo":{"status":"ok","timestamp":1630824563357,"user_tz":-540,"elapsed":9,"user":{"displayName":"박아정","photoUrl":"","userId":"15223679537180029561"}}},"source":["class colors:\n","    ok = '\\033[92m'\n","    fail = '\\033[91m'\n","    close = '\\033[0m'"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5be_v6anHXE1","executionInfo":{"status":"ok","timestamp":1630824570690,"user_tz":-540,"elapsed":7341,"user":{"displayName":"박아정","photoUrl":"","userId":"15223679537180029561"}},"outputId":"3442529f-6006-4f3a-d282-dcb3605c1e71"},"source":["# Parameters for the model and dataset.\n","TRAINING_SIZE = 50000\n","DIGITS = 3\n","INVERT = True\n","\n","# Maximum length of input is 'int + int' (e.g., '345+678'). Maximum length of\n","# int is DIGITS.\n","MAxLEN = DIGITS + 1 + DIGITS\n","\n","# All the numbers, plus sign and space for padding.\n","# ctable : 문자 집합에 대해 character table 을 만든 인스턴스(?)\n","chars = '0123456789+ '\n","ctable = CharacterTable(chars)\n","\n","questions = []\n","expected = []\n","seen = set()\n","\n","print('Generating data...')\n","# np.random.randint(1, 20) : 1~19까지 랜덤한 숫자 1개\n","while len(questions) < TRAINING_SIZE:\n","    # f : 최대 3자리까지 랜덤한 숫자를 만든다.\n","    f = lambda: int(''.join(np.random.choice(list('0123456789'))\n","                    for i in range(np.random.randint(1, DIGITS + 1))))\n","    a, b = f(), f()\n","\n","    # Skip any addition questions we've already seen\n","    # Also skip any such that x+Y == Y+x (hence the sorting).\n","    key = tuple(sorted((a, b)))\n","    if key in seen:\n","        continue\n","    seen.add(key)\n","\n","    # Pad the data with spaces such that it is always MAxLEN.\n","    q = '{}+{}'.format(a, b)\n","    query = q + ' ' * (MAxLEN - len(q)) # 전체 길이 - q 길이 만큼 padding 을 줘서 전체 길이가 맞춰지도록.\n","    ans = str(a + b)\n","\n","    # Answers can be of maximum size DIGITS + 1.\n","    # answer 도 패딩을 맞춰준다. (answer가 될 수 있는 최대 길이에서 - 현재 나온 답의 길이 만큼)\n","    ans += ' ' * (DIGITS + 1 - len(ans))\n","\n","    # Input의 Reverse 여부\n","    if INVERT:\n","        # Reverse the query, e.g., '12+345  ' becomes '  543+21'. (Note the\n","        # space used for padding.)\n","        query = query[::-1] # Reverse\n","    questions.append(query)\n","    expected.append(ans)\n","print('Total addition questions:', len(questions))"],"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Generating data...\n","Total addition questions: 50000\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_ShaxkUDJ0K3","executionInfo":{"status":"ok","timestamp":1630824570690,"user_tz":-540,"elapsed":12,"user":{"displayName":"박아정","photoUrl":"","userId":"15223679537180029561"}},"outputId":"e7d5a263-e79f-43e6-88ea-4f72f0572391"},"source":["print('Vectorization...')\n","# np.zeros(shape, dtype, order)\n","x = np.zeros((len(questions), MAxLEN, len(chars)), dtype=np.bool)\n","y = np.zeros((len(questions), DIGITS + 1, len(chars)), dtype=np.bool)\n","print(x.shape)\n","print(y.shape)"],"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Vectorization...\n","(50000, 7, 12)\n","(50000, 4, 12)\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TR73ZQDHJwv-","executionInfo":{"status":"ok","timestamp":1630824571266,"user_tz":-540,"elapsed":585,"user":{"displayName":"박아정","photoUrl":"","userId":"15223679537180029561"}},"outputId":"6c7ede23-04c7-43c6-e81c-a28726e20e02"},"source":["print('Vectorization...')\n","# np.zeros(shape, dtype, order)\n","# x : (50000, 7, 12), y : (50000, 4, 12)\n","# 입력데이터를 Encode\n","x = np.zeros((len(questions), MAxLEN, len(chars)), dtype=np.bool)\n","y = np.zeros((len(questions), DIGITS + 1, len(chars)), dtype=np.bool)\n","for i, sentence in enumerate(questions):\n","    x[i] = ctable.encode(sentence, MAxLEN)\n","for i, sentence in enumerate(expected):\n","    y[i] = ctable.encode(sentence, DIGITS + 1)\n","\n","# Shuffle (x, y) in unison as the later parts of x will almost all be larger\n","# digits.\n","# x의 뒷부분이 더 커지기 때문에 (x, y) 를 섞는다. (???) -> 어쨋든 셔플\n","indices = np.arange(len(y))\n","np.random.shuffle(indices)\n","x = x[indices]\n","y = y[indices]\n","\n","# Explicitly set apart 10% for validation data that we never train over.\n","# Test Set : 0~45000, Validation Set : 45000~50000\n","split_at = len(x) - len(x) // 10\n","(x_train, x_val) = x[:split_at], x[split_at:]\n","(y_train, y_val) = y[:split_at], y[split_at:]\n","\n","print('Training Data:')\n","print(x_train.shape)\n","print(y_train.shape)\n","\n","print('Validation Data:')\n","print(x_val.shape)\n","print(y_val.shape)"],"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Vectorization...\n","Training Data:\n","(45000, 7, 12)\n","(45000, 4, 12)\n","Validation Data:\n","(5000, 7, 12)\n","(5000, 4, 12)\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T2ZFo7R_TC2U","executionInfo":{"status":"ok","timestamp":1630824573472,"user_tz":-540,"elapsed":2211,"user":{"displayName":"박아정","photoUrl":"","userId":"15223679537180029561"}},"outputId":"334d27d2-94e0-4d6e-961f-c6cca19ef462"},"source":["# Try replacing GRU, or SimpleRNN.\n","RNN = layers.LSTM\n","HIDDEN_SIZE = 128\n","BATCH_SIZE = 128\n","LAYERS = 1\n","\n","print('Build model...')\n","model = Sequential()\n","\n","# \"Encode\" the input sequence using an RNN, producing an output of HIDDEN_SIZE.\n","# Note: In a situation where your input sequences have a variable length,\n","# use input_shape=(None, num_feature).\n","model.add(RNN(HIDDEN_SIZE, input_shape=(MAxLEN, len(chars))))\n","\n","# As the decoder RNN's input, repeatedly provide with the last hidden state of\n","# RNN for each time step. Repeat 'DIGITS + 1' times as that's the maximum\n","# length of output, e.g., when DIGITS=3, max output is 999+999=1998.\n","model.add(layers.RepeatVector(DIGITS + 1))\n","\n","# The decoder RNN could be multiple layers stacked or a single layer.\n","for _ in range(LAYERS):\n","    # By setting return_sequences to True, return not only the last output but\n","    # all the outputs so far in the form of (num_samples, timesteps,\n","    # output_dim). This is necessary as TimeDistributed in the below expects\n","    # the first dimension to be the timesteps.\n","    # return_sequences(시퀀스 출력 여부): True(각 시퀀스에서 출력, many-to-many 일 때)\n","    model.add(RNN(HIDDEN_SIZE, return_sequences=True))\n","\n","# Apply a dense layer to the every temporal slice of an input. For each of step\n","# of the output sequence, decide which character should be chosen.\n","# TimeDistributed :7개의 시간 단계 각각에 독립적으로 Dense 레이어를 적용\n","model.add(layers.TimeDistributed(layers.Dense(len(chars))))\n","model.add(layers.Activation('softmax'))\n","model.compile(loss='categorical_crossentropy',\n","              optimizer='adam',\n","              metrics=['accuracy'])\n","model.summary()"],"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Build model...\n","Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","lstm (LSTM)                  (None, 128)               72192     \n","_________________________________________________________________\n","repeat_vector (RepeatVector) (None, 4, 128)            0         \n","_________________________________________________________________\n","lstm_1 (LSTM)                (None, 4, 128)            131584    \n","_________________________________________________________________\n","time_distributed (TimeDistri (None, 4, 12)             1548      \n","_________________________________________________________________\n","activation (Activation)      (None, 4, 12)             0         \n","=================================================================\n","Total params: 205,324\n","Trainable params: 205,324\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"27aLlS854fJa","executionInfo":{"status":"error","timestamp":1630824596933,"user_tz":-540,"elapsed":23470,"user":{"displayName":"박아정","photoUrl":"","userId":"15223679537180029561"}},"outputId":"918a660d-c8c5-4cdd-c5f3-54ed3a8f4771"},"source":["# Train the model each generation and show predictions against the validation\n","# dataset.\n","for iteration in range(1, 200):\n","    print()\n","    print('-' * 50)\n","    print('Iteration', iteration)\n","    model.fit(x_train, y_train, batch_size=BATCH_SIZE, epochs=1,\n","              validation_data=(x_val, y_val))\n","    # Select 10 samples from the validation set at random so we can visualize\n","    # errors.\n","    for i in range(10):\n","        ind = np.random.randint(0, len(x_val))\n","        rowx, rowy = x_val[np.array([ind])], y_val[np.array([ind])]\n","        # predict_classes : 0 or 1로 출력 (predict 와 약간 다름) --> 2.6버전에서 삭제됨\n","        preds = model.predict_classes(rowx, verbose=0)\n","        # predict_x=model.predict(rowx, verbose=0) \n","        # classes_x=np.argmax(predict_x,axis=1)\n","        q = ctable.decode(rowx[0])\n","        correct = ctable.decode(rowy[0])\n","        guess = ctable.decode(preds[0], calc_argmax=False)\n","        # print('c: ', classes_x)\n","        print('guess: ', guess)\n","        print('Q', q[::-1] if INVERT else q)\n","        print('T', correct)\n","        if correct == guess:\n","            print(colors.ok + '☑' + colors.close, end=\" \")\n","        else:\n","            print(colors.fail + '☒' + colors.close, end=\" \")\n","        print(guess)\n","        print('---')"],"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","--------------------------------------------------\n","Iteration 1\n","Train on 45000 samples, validate on 5000 samples\n","45000/45000 [==============================] - 12s 269us/sample - loss: 1.8921 - accuracy: 0.3205 - val_loss: 1.7975 - val_accuracy: 0.3440\n","guess:  151 \n","Q 0+542  \n","T 542 \n","\u001b[91m☒\u001b[0m 151 \n","---\n","guess:  100 \n","Q 492+69 \n","T 561 \n","\u001b[91m☒\u001b[0m 100 \n","---\n","guess:  54  \n","Q 47+6   \n","T 53  \n","\u001b[91m☒\u001b[0m 54  \n","---\n","guess:  101 \n","Q 18+383 \n","T 401 \n","\u001b[91m☒\u001b[0m 101 \n","---\n","guess:  101 \n","Q 35+498 \n","T 533 \n","\u001b[91m☒\u001b[0m 101 \n","---\n","guess:  101 \n","Q 630+33 \n","T 663 \n","\u001b[91m☒\u001b[0m 101 \n","---\n","guess:  101 \n","Q 580+172\n","T 752 \n","\u001b[91m☒\u001b[0m 101 \n","---\n","guess:  1117\n","Q 517+297\n","T 814 \n","\u001b[91m☒\u001b[0m 1117\n","---\n","guess:  101 \n","Q 430+95 \n","T 525 \n","\u001b[91m☒\u001b[0m 101 \n","---\n","guess:  101 \n","Q 50+303 \n","T 353 \n","\u001b[91m☒\u001b[0m 101 \n","---\n","\n","--------------------------------------------------\n","Iteration 2\n","Train on 45000 samples, validate on 5000 samples\n","45000/45000 [==============================] - 4s 83us/sample - loss: 1.7406 - accuracy: 0.3580 - val_loss: 1.6805 - val_accuracy: 0.3785\n","guess:  447 \n","Q 14+643 \n","T 657 \n","\u001b[91m☒\u001b[0m 447 \n","---\n","guess:  22  \n","Q 2+415  \n","T 417 \n","\u001b[91m☒\u001b[0m 22  \n","---\n","guess:  808 \n","Q 671+142\n","T 813 \n","\u001b[91m☒\u001b[0m 808 \n","---\n","guess:  508 \n","Q 455+429\n","T 884 \n","\u001b[91m☒\u001b[0m 508 \n","---\n","guess:  220 \n","Q 2+742  \n","T 744 \n","\u001b[91m☒\u001b[0m 220 \n","---\n","guess:  118 \n","Q 71+72  \n","T 143 \n","\u001b[91m☒\u001b[0m 118 \n","---\n","guess:  566 \n","Q 545+0  \n","T 545 \n","\u001b[91m☒\u001b[0m 566 \n","---\n","guess:  22  \n","Q 2+52   \n","T 54  \n","\u001b[91m☒\u001b[0m 22  \n","---\n","guess:  100 \n","Q 69+98  \n","T 167 \n","\u001b[91m☒\u001b[0m 100 \n","---\n","guess:  587 \n","Q 27+646 \n","T 673 \n","\u001b[91m☒\u001b[0m 587 \n","---\n","\n","--------------------------------------------------\n","Iteration 3\n","Train on 45000 samples, validate on 5000 samples\n","45000/45000 [==============================] - 4s 85us/sample - loss: 1.5961 - accuracy: 0.4041 - val_loss: 1.5081 - val_accuracy: 0.4351\n","guess:  803 \n","Q 87+842 \n","T 929 \n","\u001b[91m☒\u001b[0m 803 \n","---\n","guess:  700 \n","Q 663+152\n","T 815 \n","\u001b[91m☒\u001b[0m 700 \n","---\n","guess:  500 \n","Q 591+34 \n","T 625 \n","\u001b[91m☒\u001b[0m 500 \n","---\n","guess:  1508\n","Q 942+588\n","T 1530\n","\u001b[91m☒\u001b[0m 1508\n","---\n","guess:  16  \n","Q 2+64   \n","T 66  \n","\u001b[91m☒\u001b[0m 16  \n","---\n","guess:  788 \n","Q 12+753 \n","T 765 \n","\u001b[91m☒\u001b[0m 788 \n","---\n","guess:  388 \n","Q 198+47 \n","T 245 \n","\u001b[91m☒\u001b[0m 388 \n","---\n","guess:  778 \n","Q 793+18 \n","T 811 \n","\u001b[91m☒\u001b[0m 778 \n","---\n","guess:  1588\n","Q 817+762\n","T 1579\n","\u001b[91m☒\u001b[0m 1588\n","---\n","guess:  187 \n","Q 1+862  \n","T 863 \n","\u001b[91m☒\u001b[0m 187 \n","---\n","\n","--------------------------------------------------\n","Iteration 4\n","Train on 45000 samples, validate on 5000 samples\n","18176/45000 [===========>..................] - ETA: 2s - loss: 1.4766 - accuracy: 0.4469"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-19-8da398e91a38>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Iteration'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     model.fit(x_train, y_train, batch_size=BATCH_SIZE, epochs=1,\n\u001b[0;32m----> 8\u001b[0;31m               validation_data=(x_val, y_val))\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;31m# Select 10 samples from the validation set at random so we can visualize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# errors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m   def evaluate(self,\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    127\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 98\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    570\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    570\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36m_non_none_constant_value\u001b[0;34m(v)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_non_none_constant_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m   \u001b[0mconstant_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant_value\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mconstant_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/framework/tensor_util.py\u001b[0m in \u001b[0;36mconstant_value\u001b[0;34m(tensor, partial)\u001b[0m\n\u001b[1;32m    820\u001b[0m   \"\"\"\n\u001b[1;32m    821\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 822\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    823\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    940\u001b[0m     \"\"\"\n\u001b[1;32m    941\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    906\u001b[0m     \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 908\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    909\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]}]}